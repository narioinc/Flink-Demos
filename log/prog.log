2020-01-14 16:33:22 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 16:33:23 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 16:33:23 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 16:33:23 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 16:33:23 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 16:33:23 [flink-akka.actor.default-dispatcher-4] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:33:23 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 16:33:23 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:33:23 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 16:33:23 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:43443]
2020-01-14 16:33:24 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:43443
2020-01-14 16:33:24 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 16:33:24 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 16:33:24 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-b2490b61-a054-4cd8-b5e7-dcb5e5210a25
2020-01-14 16:33:24 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:44523 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 16:33:24 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-c8e2ff1f-7b5c-4f82-a04e-69ad39119ca7
2020-01-14 16:33:24 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-ef7efbab-4753-4040-8e9e-154849fe3b67
2020-01-14 16:33:24 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 16:33:24 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: d8d3f406-91ed-4bfc-8ab9-8799f0d2050c
2020-01-14 16:33:24 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 66 GB (68.75% usable)
2020-01-14 16:33:24 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-189d3e2b-195a-465c-a5ac-917dcbeca8e2 for spill files.
2020-01-14 16:33:24 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-b929dadf-a9fb-43dd-ade1-ab8b1295d0f3 for spill files.
2020-01-14 16:33:24 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 16:33:24 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 16:33:24 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 16:33:24 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 16:33:24 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 16:33:24 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 16:33:24 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 16:33:24 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-7b970b11-6656-4b12-b455-03f88e32761e
2020-01-14 16:33:24 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 16:33:24 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 16:33:24 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 16:33:24 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 16:33:25 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:44015
2020-01-14 16:33:25 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@2b0b7e5a @ http://localhost:44015
2020-01-14 16:33:25 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 16:33:25 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:44015 was granted leadership with leaderSessionID=babeeb18-33d8-4c70-9f1f-72817232c1a1
2020-01-14 16:33:25 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:44015 , session=babeeb18-33d8-4c70-9f1f-72817232c1a1
2020-01-14 16:33:25 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@28ae85b1 @ akka://flink/user/resourcemanager
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@2d5e27e0 @ akka://flink/user/dispatcher
2020-01-14 16:33:25 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 8f1d930eb857607eba6b21c2fe234fda
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token d0ba35d1-2b5c-4d03-937f-a0c60d3a9c49
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=d0ba35d1-2b5c-4d03-937f-a0c60d3a9c49
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=ba6b21c2-fe23-4fda-8f1d-930eb857607e
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(8f1d930eb857607eba6b21c2fe234fda).
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID d8d3f406-91ed-4bfc-8ab9-8799f0d2050c (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 3686e13559bda7046192fd67e4f54199.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission b41714b64459bec0df5ba679ab6555c7 (Flink Streaming Job).
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job b41714b64459bec0df5ba679ab6555c7 (Flink Streaming Job).
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (b41714b64459bec0df5ba679ab6555c7).
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (b41714b64459bec0df5ba679ab6555c7).
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (b41714b64459bec0df5ba679ab6555c7).
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@1a288720 @ akka://flink/user/jobmanager_1
2020-01-14 16:33:25 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (b41714b64459bec0df5ba679ab6555c7) was granted leadership with session id 050a20c6-b19e-45f8-ac0f-1a0cdf2ae149 at akka://flink/user/jobmanager_1.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (b41714b64459bec0df5ba679ab6555c7) under job master id ac0f1a0cdf2ae149050a20c6b19e45f8.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (b41714b64459bec0df5ba679ab6555c7) switched from state CREATED to RUNNING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) switched from CREATED to SCHEDULED.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{0e3e9d8a823edbeb4c5f1c779fb2d0f4}]
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) switched from CREATED to SCHEDULED.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c751fd14ab44cb92b2cc9241454a82e9}]
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) switched from CREATED to SCHEDULED.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{42db0cd02fb459e2c782835503a95dd0}]
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) switched from CREATED to SCHEDULED.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ed6dabcd67d66520c79ea3e01757bb33}]
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) switched from CREATED to SCHEDULED.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4a2ff045a65e7134e476da0e834c450f}]
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) switched from CREATED to SCHEDULED.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d9e33329c4b45a462542727f26a04fd4}]
2020-01-14 16:33:25 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=050a20c6-b19e-45f8-ac0f-1a0cdf2ae149
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(8f1d930eb857607eba6b21c2fe234fda)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager ac0f1a0cdf2ae149050a20c6b19e45f8@akka://flink/user/jobmanager_1 for job b41714b64459bec0df5ba679ab6555c7.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager ac0f1a0cdf2ae149050a20c6b19e45f8@akka://flink/user/jobmanager_1 for job b41714b64459bec0df5ba679ab6555c7.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 8f1d930eb857607eba6b21c2fe234fda.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{0e3e9d8a823edbeb4c5f1c779fb2d0f4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b41714b64459bec0df5ba679ab6555c7 with allocation id 0fd32842fd9541e573e23ed2b8fa79af.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c751fd14ab44cb92b2cc9241454a82e9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{42db0cd02fb459e2c782835503a95dd0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ed6dabcd67d66520c79ea3e01757bb33}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 0fd32842fd9541e573e23ed2b8fa79af for job b41714b64459bec0df5ba679ab6555c7 from resource manager with leader id 8f1d930eb857607eba6b21c2fe234fda.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b41714b64459bec0df5ba679ab6555c7 with allocation id d3a105e9104e44972ab4e8e83c51d39f.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{4a2ff045a65e7134e476da0e834c450f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d9e33329c4b45a462542727f26a04fd4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b41714b64459bec0df5ba679ab6555c7 with allocation id e9f4c27fe7a17d220410891a1aacf21d.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b41714b64459bec0df5ba679ab6555c7 with allocation id d16f64e4b3c5df9d86df0f9bc67a5d51.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 0fd32842fd9541e573e23ed2b8fa79af.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b41714b64459bec0df5ba679ab6555c7 for job leader monitoring.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b41714b64459bec0df5ba679ab6555c7 with allocation id 6d5bfe7d63ea45a2e84a11060f04e0b6.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b41714b64459bec0df5ba679ab6555c7 with allocation id 4f63e378c92e7b453a5882339e9b6331.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d3a105e9104e44972ab4e8e83c51d39f for job b41714b64459bec0df5ba679ab6555c7 from resource manager with leader id 8f1d930eb857607eba6b21c2fe234fda.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d3a105e9104e44972ab4e8e83c51d39f.
2020-01-14 16:33:25 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 050a20c6-b19e-45f8-ac0f-1a0cdf2ae149.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b41714b64459bec0df5ba679ab6555c7 for job leader monitoring.
2020-01-14 16:33:25 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 050a20c6-b19e-45f8-ac0f-1a0cdf2ae149.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request e9f4c27fe7a17d220410891a1aacf21d for job b41714b64459bec0df5ba679ab6555c7 from resource manager with leader id 8f1d930eb857607eba6b21c2fe234fda.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for e9f4c27fe7a17d220410891a1aacf21d.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b41714b64459bec0df5ba679ab6555c7 for job leader monitoring.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d16f64e4b3c5df9d86df0f9bc67a5d51 for job b41714b64459bec0df5ba679ab6555c7 from resource manager with leader id 8f1d930eb857607eba6b21c2fe234fda.
2020-01-14 16:33:25 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 050a20c6-b19e-45f8-ac0f-1a0cdf2ae149.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d16f64e4b3c5df9d86df0f9bc67a5d51.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b41714b64459bec0df5ba679ab6555c7 for job leader monitoring.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 6d5bfe7d63ea45a2e84a11060f04e0b6 for job b41714b64459bec0df5ba679ab6555c7 from resource manager with leader id 8f1d930eb857607eba6b21c2fe234fda.
2020-01-14 16:33:25 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 050a20c6-b19e-45f8-ac0f-1a0cdf2ae149.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 6d5bfe7d63ea45a2e84a11060f04e0b6.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b41714b64459bec0df5ba679ab6555c7 for job leader monitoring.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 4f63e378c92e7b453a5882339e9b6331 for job b41714b64459bec0df5ba679ab6555c7 from resource manager with leader id 8f1d930eb857607eba6b21c2fe234fda.
2020-01-14 16:33:25 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 050a20c6-b19e-45f8-ac0f-1a0cdf2ae149.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 4f63e378c92e7b453a5882339e9b6331.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b41714b64459bec0df5ba679ab6555c7 for job leader monitoring.
2020-01-14 16:33:25 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 050a20c6-b19e-45f8-ac0f-1a0cdf2ae149.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job b41714b64459bec0df5ba679ab6555c7.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job b41714b64459bec0df5ba679ab6555c7.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b41714b64459bec0df5ba679ab6555c7.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to d8d3f406-91ed-4bfc-8ab9-8799f0d2050c @ localhost (dataPort=-1)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to d8d3f406-91ed-4bfc-8ab9-8799f0d2050c @ localhost (dataPort=-1)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to d8d3f406-91ed-4bfc-8ab9-8799f0d2050c @ localhost (dataPort=-1)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to d8d3f406-91ed-4bfc-8ab9-8799f0d2050c @ localhost (dataPort=-1)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to d8d3f406-91ed-4bfc-8ab9-8799f0d2050c @ localhost (dataPort=-1)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to d8d3f406-91ed-4bfc-8ab9-8799f0d2050c @ localhost (dataPort=-1)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) switched from CREATED to DEPLOYING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) [DEPLOYING]
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) [DEPLOYING].
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) [DEPLOYING].
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) switched from CREATED to DEPLOYING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) [DEPLOYING]
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) [DEPLOYING].
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) [DEPLOYING].
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (9fa088fe41a678cfc5157f57fec0b2de) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9b2203549a7f769b702601e9eab3b9d5) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) switched from CREATED to DEPLOYING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) [DEPLOYING]
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) [DEPLOYING].
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) [DEPLOYING].
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) switched from CREATED to DEPLOYING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) [DEPLOYING]
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) [DEPLOYING].
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (ee4631718679b3d7dc153cfc8f5e8320) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) [DEPLOYING].
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (93912475efa15b6eeecacf04b4ab2031) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) switched from CREATED to DEPLOYING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) [DEPLOYING]
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) [DEPLOYING].
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) switched from CREATED to DEPLOYING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 6d5bfe7d63ea45a2e84a11060f04e0b6.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 4f63e378c92e7b453a5882339e9b6331.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) [DEPLOYING]
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot d3a105e9104e44972ab4e8e83c51d39f.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) [DEPLOYING].
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot e9f4c27fe7a17d220410891a1aacf21d.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 0fd32842fd9541e573e23ed2b8fa79af.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot d16f64e4b3c5df9d86df0f9bc67a5d51.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) [DEPLOYING].
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) [DEPLOYING].
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (91c017591f122251f6dc88ed7d23ab87) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5bea78fa6e46a0f017a773a325cce821) switched from DEPLOYING to RUNNING.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:33:25 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 16:33:25 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 16:33:25 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 16:33:25 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 16:33:25 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 16:33:25 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 16:33:25 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-9, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:33:25 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-9, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 16:40:39 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 16:40:39 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 16:40:39 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 16:40:39 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 16:40:39 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 16:40:40 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:40:40 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 16:40:40 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:40:40 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 16:40:40 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:46587]
2020-01-14 16:40:41 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:46587
2020-01-14 16:40:41 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 16:40:41 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 16:40:41 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-8cd79447-74f8-4f1a-bb40-0d3eedcac747
2020-01-14 16:40:41 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:34725 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 16:40:41 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-4c70273f-416f-4b52-98ef-63d239504258
2020-01-14 16:40:41 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-647f26af-9ac9-4b06-bc84-7a78e83c0b8e
2020-01-14 16:40:41 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 16:40:41 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 595c8804-730a-4e9e-8a0a-b7c0d6c61547
2020-01-14 16:40:41 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 66 GB (68.75% usable)
2020-01-14 16:40:41 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-996913f3-565b-46a1-bebd-1e19fd11ed17 for spill files.
2020-01-14 16:40:41 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-69abbac4-9e5f-4890-aec0-361471f205e9 for spill files.
2020-01-14 16:40:41 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 16:40:41 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 16:40:41 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 16:40:41 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 16:40:41 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 16:40:41 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-8d76829e-d874-4255-8254-ed5c66468cbb
2020-01-14 16:40:41 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 16:40:41 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 16:40:41 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 16:40:41 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 16:40:41 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:42979
2020-01-14 16:40:41 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@161aa04a @ http://localhost:42979
2020-01-14 16:40:41 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:42979 was granted leadership with leaderSessionID=1440fd90-bfa7-42d0-bf6f-ea66c30e3498
2020-01-14 16:40:41 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:42979 , session=1440fd90-bfa7-42d0-bf6f-ea66c30e3498
2020-01-14 16:40:41 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 16:40:41 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@24aabcdc @ akka://flink/user/resourcemanager
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@468358f9 @ akka://flink/user/dispatcher
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token b1fc60c43599c2d61b9c87eb826c4aa7
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 708c8fbd-9e07-489d-968b-4973ce8798f2
2020-01-14 16:40:41 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=708c8fbd-9e07-489d-968b-4973ce8798f2
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=1b9c87eb-826c-4aa7-b1fc-60c43599c2d6
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(b1fc60c43599c2d61b9c87eb826c4aa7).
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission 40c9eff66791f553baf82d60468c6cc9 (Flink Streaming Job).
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job 40c9eff66791f553baf82d60468c6cc9 (Flink Streaming Job).
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 595c8804-730a-4e9e-8a0a-b7c0d6c61547 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id ae6db8cbd257c4887e759166d71c3ea3.
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (40c9eff66791f553baf82d60468c6cc9).
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (40c9eff66791f553baf82d60468c6cc9).
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (40c9eff66791f553baf82d60468c6cc9).
2020-01-14 16:40:41 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@499e365f @ akka://flink/user/jobmanager_1
2020-01-14 16:40:42 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (40c9eff66791f553baf82d60468c6cc9) was granted leadership with session id 12fa6983-ed5f-4e27-8bca-4cbadd94f223 at akka://flink/user/jobmanager_1.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (40c9eff66791f553baf82d60468c6cc9) under job master id 8bca4cbadd94f22312fa6983ed5f4e27.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (40c9eff66791f553baf82d60468c6cc9) switched from state CREATED to RUNNING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) switched from CREATED to SCHEDULED.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e19799e912d05d1c85ec9217edf21e62}]
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) switched from CREATED to SCHEDULED.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4e8b73c63510759ab8b49a4f2684bbfb}]
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) switched from CREATED to SCHEDULED.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6992a41d3a6f254011e56f4175009639}]
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) switched from CREATED to SCHEDULED.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b6c69d9f1514823f9eb69306f8473f5a}]
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) switched from CREATED to SCHEDULED.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{93d7d22c9fd9d6fbc79e00325f6a9e52}]
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) switched from CREATED to SCHEDULED.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a3d11f826ab16f45d6367457f4c47463}]
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(b1fc60c43599c2d61b9c87eb826c4aa7)
2020-01-14 16:40:42 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=12fa6983-ed5f-4e27-8bca-4cbadd94f223
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager 8bca4cbadd94f22312fa6983ed5f4e27@akka://flink/user/jobmanager_1 for job 40c9eff66791f553baf82d60468c6cc9.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 8bca4cbadd94f22312fa6983ed5f4e27@akka://flink/user/jobmanager_1 for job 40c9eff66791f553baf82d60468c6cc9.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: b1fc60c43599c2d61b9c87eb826c4aa7.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e19799e912d05d1c85ec9217edf21e62}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{4e8b73c63510759ab8b49a4f2684bbfb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 40c9eff66791f553baf82d60468c6cc9 with allocation id b417759fbedfede12c683ffa3d5cd9be.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{6992a41d3a6f254011e56f4175009639}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b6c69d9f1514823f9eb69306f8473f5a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request b417759fbedfede12c683ffa3d5cd9be for job 40c9eff66791f553baf82d60468c6cc9 from resource manager with leader id b1fc60c43599c2d61b9c87eb826c4aa7.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{93d7d22c9fd9d6fbc79e00325f6a9e52}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a3d11f826ab16f45d6367457f4c47463}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 40c9eff66791f553baf82d60468c6cc9 with allocation id 9d6b5c1f3665a0d6a18574df3425affa.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 40c9eff66791f553baf82d60468c6cc9 with allocation id 28872a741b4e7e838c3c6b093084b367.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 40c9eff66791f553baf82d60468c6cc9 with allocation id 73a904313ae30ee60deaf9388cf91a9f.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 40c9eff66791f553baf82d60468c6cc9 with allocation id 1f2b1077d62e2b0f17e7fa0a3d5808cc.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 40c9eff66791f553baf82d60468c6cc9 with allocation id 50c87c9badee74f3c26bc9312304fba2.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for b417759fbedfede12c683ffa3d5cd9be.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 40c9eff66791f553baf82d60468c6cc9 for job leader monitoring.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 9d6b5c1f3665a0d6a18574df3425affa for job 40c9eff66791f553baf82d60468c6cc9 from resource manager with leader id b1fc60c43599c2d61b9c87eb826c4aa7.
2020-01-14 16:40:42 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 12fa6983-ed5f-4e27-8bca-4cbadd94f223.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 9d6b5c1f3665a0d6a18574df3425affa.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 40c9eff66791f553baf82d60468c6cc9 for job leader monitoring.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 28872a741b4e7e838c3c6b093084b367 for job 40c9eff66791f553baf82d60468c6cc9 from resource manager with leader id b1fc60c43599c2d61b9c87eb826c4aa7.
2020-01-14 16:40:42 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 12fa6983-ed5f-4e27-8bca-4cbadd94f223.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 28872a741b4e7e838c3c6b093084b367.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 40c9eff66791f553baf82d60468c6cc9 for job leader monitoring.
2020-01-14 16:40:42 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 12fa6983-ed5f-4e27-8bca-4cbadd94f223.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 73a904313ae30ee60deaf9388cf91a9f for job 40c9eff66791f553baf82d60468c6cc9 from resource manager with leader id b1fc60c43599c2d61b9c87eb826c4aa7.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 73a904313ae30ee60deaf9388cf91a9f.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 40c9eff66791f553baf82d60468c6cc9 for job leader monitoring.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 1f2b1077d62e2b0f17e7fa0a3d5808cc for job 40c9eff66791f553baf82d60468c6cc9 from resource manager with leader id b1fc60c43599c2d61b9c87eb826c4aa7.
2020-01-14 16:40:42 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 12fa6983-ed5f-4e27-8bca-4cbadd94f223.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 1f2b1077d62e2b0f17e7fa0a3d5808cc.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 40c9eff66791f553baf82d60468c6cc9 for job leader monitoring.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 50c87c9badee74f3c26bc9312304fba2 for job 40c9eff66791f553baf82d60468c6cc9 from resource manager with leader id b1fc60c43599c2d61b9c87eb826c4aa7.
2020-01-14 16:40:42 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 12fa6983-ed5f-4e27-8bca-4cbadd94f223.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 50c87c9badee74f3c26bc9312304fba2.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 40c9eff66791f553baf82d60468c6cc9 for job leader monitoring.
2020-01-14 16:40:42 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 12fa6983-ed5f-4e27-8bca-4cbadd94f223.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 40c9eff66791f553baf82d60468c6cc9.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job 40c9eff66791f553baf82d60468c6cc9.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 40c9eff66791f553baf82d60468c6cc9.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 595c8804-730a-4e9e-8a0a-b7c0d6c61547 @ localhost (dataPort=-1)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 595c8804-730a-4e9e-8a0a-b7c0d6c61547 @ localhost (dataPort=-1)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 595c8804-730a-4e9e-8a0a-b7c0d6c61547 @ localhost (dataPort=-1)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 595c8804-730a-4e9e-8a0a-b7c0d6c61547 @ localhost (dataPort=-1)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 595c8804-730a-4e9e-8a0a-b7c0d6c61547 @ localhost (dataPort=-1)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 595c8804-730a-4e9e-8a0a-b7c0d6c61547 @ localhost (dataPort=-1)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) switched from CREATED to DEPLOYING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) [DEPLOYING]
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9522453f31c57ef2f50a7b511b93aaa3) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) switched from CREATED to DEPLOYING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) [DEPLOYING]
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) switched from CREATED to DEPLOYING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) [DEPLOYING]
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) [DEPLOYING].
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (d33f507142a3cd184928724660d2d2b3) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 28872a741b4e7e838c3c6b093084b367.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 73a904313ae30ee60deaf9388cf91a9f.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 9d6b5c1f3665a0d6a18574df3425affa.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 50c87c9badee74f3c26bc9312304fba2.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 1f2b1077d62e2b0f17e7fa0a3d5808cc.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot b417759fbedfede12c683ffa3d5cd9be.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) switched from CREATED to DEPLOYING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) [DEPLOYING]
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) [DEPLOYING].
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (9b071e3f39d346b572d3b2a13b79ed99) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fdc513171e7cec996222308e7e91f40f) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) switched from CREATED to DEPLOYING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) [DEPLOYING]
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (8faa74258df3c744b84d4f652550560a) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) switched from CREATED to DEPLOYING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) [DEPLOYING]
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) [DEPLOYING].
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:40:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (263d8a94b8818bc769c710af69f88b83) switched from DEPLOYING to RUNNING.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:40:42 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 16:40:42 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 16:40:42 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 16:40:42 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 16:40:42 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 16:40:42 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-11, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:40:42 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-11, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 16:41:33 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 16:41:33 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 16:41:33 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 16:41:33 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 16:41:33 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 16:41:34 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:41:34 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 16:41:34 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:41:34 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 16:41:34 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:37273]
2020-01-14 16:41:34 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:37273
2020-01-14 16:41:34 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 16:41:34 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 16:41:34 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-1abe2694-9bc3-40f6-a11a-94c88abf746b
2020-01-14 16:41:34 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:36431 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 16:41:34 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-fd6fb490-aecf-4f2f-92d1-1a0d7502f081
2020-01-14 16:41:34 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-d51af20a-2912-4955-970d-0f0e8cc72bd5
2020-01-14 16:41:34 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 16:41:34 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: df264a44-e07b-47e1-9c99-97015f3af021
2020-01-14 16:41:34 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 66 GB (68.75% usable)
2020-01-14 16:41:34 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-9a14d91d-a7c1-4b89-ae82-6653ad0a3726 for spill files.
2020-01-14 16:41:34 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-f6fe1e3a-7974-4ee8-8021-cb6273906689 for spill files.
2020-01-14 16:41:35 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 16:41:35 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 16:41:35 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 16:41:35 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 16:41:35 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 16:41:35 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 16:41:35 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 16:41:35 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-05c2c9fa-6bcc-4e27-97c8-dc2207118563
2020-01-14 16:41:35 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 16:41:35 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 16:41:35 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 16:41:35 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 16:41:36 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:32817
2020-01-14 16:41:36 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@67f77f6e @ http://localhost:32817
2020-01-14 16:41:36 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:32817 was granted leadership with leaderSessionID=3382f5bf-f363-493e-9063-52fa40c7f315
2020-01-14 16:41:36 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 16:41:36 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:32817 , session=3382f5bf-f363-493e-9063-52fa40c7f315
2020-01-14 16:41:36 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@55d5353c @ akka://flink/user/dispatcher
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@3567f2f4 @ akka://flink/user/resourcemanager
2020-01-14 16:41:36 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 6eff33e3-2b26-422c-989e-5c698e57453d
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 855918ccaa99996ac283809c373f4925
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=6eff33e3-2b26-422c-989e-5c698e57453d
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=c283809c-373f-4925-8559-18ccaa99996a
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(855918ccaa99996ac283809c373f4925).
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 9e72617488bce3f1cc657d30a00e04b9 (Flink Streaming Job).
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 9e72617488bce3f1cc657d30a00e04b9 (Flink Streaming Job).
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID df264a44-e07b-47e1-9c99-97015f3af021 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 73fcc4a44a842b7193f6a8be9f961910.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (9e72617488bce3f1cc657d30a00e04b9).
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (9e72617488bce3f1cc657d30a00e04b9).
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (9e72617488bce3f1cc657d30a00e04b9).
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 24 ms.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@37c033da @ akka://flink/user/jobmanager_1
2020-01-14 16:41:36 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (9e72617488bce3f1cc657d30a00e04b9) was granted leadership with session id 48231378-a426-4d9f-b66f-edd8acbcf4dd at akka://flink/user/jobmanager_1.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (9e72617488bce3f1cc657d30a00e04b9) under job master id b66fedd8acbcf4dd48231378a4264d9f.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (9e72617488bce3f1cc657d30a00e04b9) switched from state CREATED to RUNNING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) switched from CREATED to SCHEDULED.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1650cbefebcb85a5b87a30318d2ab16b}]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) switched from CREATED to SCHEDULED.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5ba15bc3ddceccb5201b7fbedf881037}]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) switched from CREATED to SCHEDULED.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6502bcdcf8cac891bc38ec7cef7d4b88}]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) switched from CREATED to SCHEDULED.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2a5ec01530179674ad2e26ef7be527e6}]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) switched from CREATED to SCHEDULED.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d9885cf4e836594951d28b8e0b1eac0c}]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) switched from CREATED to SCHEDULED.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f57e865e87e84ee966b115577ad92e85}]
2020-01-14 16:41:36 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=48231378-a426-4d9f-b66f-edd8acbcf4dd
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(855918ccaa99996ac283809c373f4925)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:302 - Registering job manager b66fedd8acbcf4dd48231378a4264d9f@akka://flink/user/jobmanager_1 for job 9e72617488bce3f1cc657d30a00e04b9.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager b66fedd8acbcf4dd48231378a4264d9f@akka://flink/user/jobmanager_1 for job 9e72617488bce3f1cc657d30a00e04b9.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 855918ccaa99996ac283809c373f4925.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1650cbefebcb85a5b87a30318d2ab16b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9e72617488bce3f1cc657d30a00e04b9 with allocation id 121887702ad88dcd55eb813270ae33bf.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5ba15bc3ddceccb5201b7fbedf881037}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{6502bcdcf8cac891bc38ec7cef7d4b88}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{2a5ec01530179674ad2e26ef7be527e6}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d9885cf4e836594951d28b8e0b1eac0c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 121887702ad88dcd55eb813270ae33bf for job 9e72617488bce3f1cc657d30a00e04b9 from resource manager with leader id 855918ccaa99996ac283809c373f4925.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f57e865e87e84ee966b115577ad92e85}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9e72617488bce3f1cc657d30a00e04b9 with allocation id c4a29f7cc3faa097236f8a996b51b086.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9e72617488bce3f1cc657d30a00e04b9 with allocation id 7c3da83636343edbd0aa60a7fade98dc.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9e72617488bce3f1cc657d30a00e04b9 with allocation id d78a4b270dbdcb2f9d9e7cd901bebbb2.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9e72617488bce3f1cc657d30a00e04b9 with allocation id dbc49ce975ce0aba1c93cffda004020b.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9e72617488bce3f1cc657d30a00e04b9 with allocation id d16817c7c4cb350966a3f7849da634f3.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 121887702ad88dcd55eb813270ae33bf.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 9e72617488bce3f1cc657d30a00e04b9 for job leader monitoring.
2020-01-14 16:41:36 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 48231378-a426-4d9f-b66f-edd8acbcf4dd.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request c4a29f7cc3faa097236f8a996b51b086 for job 9e72617488bce3f1cc657d30a00e04b9 from resource manager with leader id 855918ccaa99996ac283809c373f4925.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for c4a29f7cc3faa097236f8a996b51b086.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 9e72617488bce3f1cc657d30a00e04b9 for job leader monitoring.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 7c3da83636343edbd0aa60a7fade98dc for job 9e72617488bce3f1cc657d30a00e04b9 from resource manager with leader id 855918ccaa99996ac283809c373f4925.
2020-01-14 16:41:36 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 48231378-a426-4d9f-b66f-edd8acbcf4dd.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 7c3da83636343edbd0aa60a7fade98dc.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 9e72617488bce3f1cc657d30a00e04b9 for job leader monitoring.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request d78a4b270dbdcb2f9d9e7cd901bebbb2 for job 9e72617488bce3f1cc657d30a00e04b9 from resource manager with leader id 855918ccaa99996ac283809c373f4925.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for d78a4b270dbdcb2f9d9e7cd901bebbb2.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 9e72617488bce3f1cc657d30a00e04b9 for job leader monitoring.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request dbc49ce975ce0aba1c93cffda004020b for job 9e72617488bce3f1cc657d30a00e04b9 from resource manager with leader id 855918ccaa99996ac283809c373f4925.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for dbc49ce975ce0aba1c93cffda004020b.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 9e72617488bce3f1cc657d30a00e04b9 for job leader monitoring.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request d16817c7c4cb350966a3f7849da634f3 for job 9e72617488bce3f1cc657d30a00e04b9 from resource manager with leader id 855918ccaa99996ac283809c373f4925.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for d16817c7c4cb350966a3f7849da634f3.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 9e72617488bce3f1cc657d30a00e04b9 for job leader monitoring.
2020-01-14 16:41:36 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 48231378-a426-4d9f-b66f-edd8acbcf4dd.
2020-01-14 16:41:36 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 48231378-a426-4d9f-b66f-edd8acbcf4dd.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 9e72617488bce3f1cc657d30a00e04b9.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job 9e72617488bce3f1cc657d30a00e04b9.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 9e72617488bce3f1cc657d30a00e04b9.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to df264a44-e07b-47e1-9c99-97015f3af021 @ localhost (dataPort=-1)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to df264a44-e07b-47e1-9c99-97015f3af021 @ localhost (dataPort=-1)
2020-01-14 16:41:36 [mini-cluster-io-thread-2] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to df264a44-e07b-47e1-9c99-97015f3af021 @ localhost (dataPort=-1)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to df264a44-e07b-47e1-9c99-97015f3af021 @ localhost (dataPort=-1)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to df264a44-e07b-47e1-9c99-97015f3af021 @ localhost (dataPort=-1)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to df264a44-e07b-47e1-9c99-97015f3af021 @ localhost (dataPort=-1)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) switched from CREATED to DEPLOYING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) [DEPLOYING]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) switched from CREATED to DEPLOYING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) [DEPLOYING]
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) [DEPLOYING].
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) switched from CREATED to DEPLOYING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) [DEPLOYING]
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) [DEPLOYING].
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) switched from CREATED to DEPLOYING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) [DEPLOYING]
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) switched from CREATED to DEPLOYING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) [DEPLOYING]
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) [DEPLOYING].
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot dbc49ce975ce0aba1c93cffda004020b.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot c4a29f7cc3faa097236f8a996b51b086.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 7c3da83636343edbd0aa60a7fade98dc.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot d78a4b270dbdcb2f9d9e7cd901bebbb2.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 121887702ad88dcd55eb813270ae33bf.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) [DEPLOYING].
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot d16817c7c4cb350966a3f7849da634f3.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) switched from CREATED to DEPLOYING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) [DEPLOYING]
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) [DEPLOYING].
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (67f1752b8ad1e6c1f309664a752c9948) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (a6d562c8bd81a5dd18bd9503ceccb074) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (3f035c8076a764c29411f9660fa06c68) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (6f8ce3cd1ff0bcd1cee14afca9b7ed5d) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (1e47a32405273812045f920273f92d38) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (9e2f18a2777262d981f7dd3a25e4bc66) switched from DEPLOYING to RUNNING.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 16:41:36 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 16:41:36 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 16:41:36 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 16:41:36 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 16:41:36 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 16:41:36 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:41:36 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 16:41:39 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 16:41:39 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 16:41:39 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 16:43:25 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-14 16:43:25 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 16:43:26 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 16:43:26 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 16:43:26 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 16:43:26 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 16:43:26 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:43:26 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 16:43:26 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 16:43:26 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 16:43:27 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:39573]
2020-01-14 16:43:27 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:39573
2020-01-14 16:43:27 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 16:43:27 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 16:43:27 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-0315023d-f3c0-4d79-957c-54e0ddf9f2c5
2020-01-14 16:43:27 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:43967 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 16:43:27 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-9b4cf4d9-5278-45db-9c59-85727e80d788
2020-01-14 16:43:27 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-91001185-1a40-4bc8-a136-cdff5ad531c3
2020-01-14 16:43:27 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 16:43:27 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 2b26b801-953b-49b6-bd10-2d3e33776237
2020-01-14 16:43:27 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 66 GB (68.75% usable)
2020-01-14 16:43:27 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-bdaa007f-040d-4a55-b0c3-950c127a2851 for spill files.
2020-01-14 16:43:27 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-80e10f97-e355-42ec-9058-97a9bdbfdbb8 for spill files.
2020-01-14 16:43:27 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 16:43:27 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 16:43:27 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 16:43:27 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 16:43:27 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 16:43:27 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 16:43:27 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 16:43:27 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-c92f6834-812c-4172-9701-452559178a3d
2020-01-14 16:43:27 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 16:43:28 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 16:43:28 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 16:43:28 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 16:43:28 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:42567
2020-01-14 16:43:28 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@3c854752 @ http://localhost:42567
2020-01-14 16:43:28 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:42567 was granted leadership with leaderSessionID=44dd4eae-063f-4dc9-b6ab-a2a96c8d7873
2020-01-14 16:43:28 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:42567 , session=44dd4eae-063f-4dc9-b6ab-a2a96c8d7873
2020-01-14 16:43:28 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 16:43:28 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6c234f35 @ akka://flink/user/resourcemanager
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@401631e6 @ akka://flink/user/dispatcher
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 24fe6a55-de86-48a3-a4cf-b9f2e0251682
2020-01-14 16:43:28 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=24fe6a55-de86-48a3-a4cf-b9f2e0251682
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token a98f4bd56175ceee242383d2c0c348ab
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=242383d2-c0c3-48ab-a98f-4bd56175ceee
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(a98f4bd56175ceee242383d2c0c348ab).
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 2b26b801-953b-49b6-bd10-2d3e33776237 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id c8205d40faf6087a3b720209c3257dbc.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission 6172829016964e6a6db3816ec9839992 (Flink Streaming Job).
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job 6172829016964e6a6db3816ec9839992 (Flink Streaming Job).
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (6172829016964e6a6db3816ec9839992).
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (6172829016964e6a6db3816ec9839992).
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (6172829016964e6a6db3816ec9839992).
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@2ae67554 @ akka://flink/user/jobmanager_1
2020-01-14 16:43:28 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (6172829016964e6a6db3816ec9839992) was granted leadership with session id 9a213a3c-1617-4a8f-b82e-32824fc3d9e2 at akka://flink/user/jobmanager_1.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (6172829016964e6a6db3816ec9839992) under job master id b82e32824fc3d9e29a213a3c16174a8f.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (6172829016964e6a6db3816ec9839992) switched from state CREATED to RUNNING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) switched from CREATED to SCHEDULED.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1c182d51d5a22788b49a9ae406c5f809}]
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) switched from CREATED to SCHEDULED.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) switched from CREATED to SCHEDULED.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) switched from CREATED to SCHEDULED.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) switched from CREATED to SCHEDULED.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) switched from CREATED to SCHEDULED.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) switched from CREATED to SCHEDULED.
2020-01-14 16:43:28 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=9a213a3c-1617-4a8f-b82e-32824fc3d9e2
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(a98f4bd56175ceee242383d2c0c348ab)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager b82e32824fc3d9e29a213a3c16174a8f@akka://flink/user/jobmanager_1 for job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager b82e32824fc3d9e29a213a3c16174a8f@akka://flink/user/jobmanager_1 for job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: a98f4bd56175ceee242383d2c0c348ab.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1c182d51d5a22788b49a9ae406c5f809}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6172829016964e6a6db3816ec9839992 with allocation id 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 52fbfb6cd3b1cf089b35bb5d9f864d4c for job 6172829016964e6a6db3816ec9839992 from resource manager with leader id a98f4bd56175ceee242383d2c0c348ab.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 6172829016964e6a6db3816ec9839992 for job leader monitoring.
2020-01-14 16:43:28 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9a213a3c-1617-4a8f-b82e-32824fc3d9e2.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{967fe85582b4413e4adc1c07d35317b0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{bbd9b68953f7b99cda26e8d7e8692c11}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6172829016964e6a6db3816ec9839992 with allocation id 72bd738129c41bf44caf81ac7cd7516e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 72bd738129c41bf44caf81ac7cd7516e for job 6172829016964e6a6db3816ec9839992 from resource manager with leader id a98f4bd56175ceee242383d2c0c348ab.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{90ddc1c3848bbd3079e99f99e4e339ed}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 72bd738129c41bf44caf81ac7cd7516e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6172829016964e6a6db3816ec9839992 with allocation id 8afe0b8a5e2e9f00b4040885259ee49e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a5996adcf60f92b99d65dc605d5b2551}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e6e760b11ae9571c74767a4d5cce45b9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 8afe0b8a5e2e9f00b4040885259ee49e for job 6172829016964e6a6db3816ec9839992 from resource manager with leader id a98f4bd56175ceee242383d2c0c348ab.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6172829016964e6a6db3816ec9839992 with allocation id df6d560bd1c4eec2f776072eb4e640cc.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 8afe0b8a5e2e9f00b4040885259ee49e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request df6d560bd1c4eec2f776072eb4e640cc for job 6172829016964e6a6db3816ec9839992 from resource manager with leader id a98f4bd56175ceee242383d2c0c348ab.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6172829016964e6a6db3816ec9839992 with allocation id 18a9b368ecee42359acb71c3947b4f11.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for df6d560bd1c4eec2f776072eb4e640cc.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [52fbfb6cd3b1cf089b35bb5d9f864d4c]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [52fbfb6cd3b1cf089b35bb5d9f864d4c]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 18a9b368ecee42359acb71c3947b4f11 for job 6172829016964e6a6db3816ec9839992 from resource manager with leader id a98f4bd56175ceee242383d2c0c348ab.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [72bd738129c41bf44caf81ac7cd7516e]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6172829016964e6a6db3816ec9839992 with allocation id 81e5b494d36d4a69d4cfb53780edb61b.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 18a9b368ecee42359acb71c3947b4f11.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [8afe0b8a5e2e9f00b4040885259ee49e]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [52fbfb6cd3b1cf089b35bb5d9f864d4c]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 81e5b494d36d4a69d4cfb53780edb61b for job 6172829016964e6a6db3816ec9839992 from resource manager with leader id a98f4bd56175ceee242383d2c0c348ab.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [72bd738129c41bf44caf81ac7cd7516e]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 81e5b494d36d4a69d4cfb53780edb61b.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 6172829016964e6a6db3816ec9839992.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [df6d560bd1c4eec2f776072eb4e640cc]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [8afe0b8a5e2e9f00b4040885259ee49e]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [52fbfb6cd3b1cf089b35bb5d9f864d4c]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [72bd738129c41bf44caf81ac7cd7516e]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 72bd738129c41bf44caf81ac7cd7516e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [18a9b368ecee42359acb71c3947b4f11]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [df6d560bd1c4eec2f776072eb4e640cc]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [8afe0b8a5e2e9f00b4040885259ee49e]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 72bd738129c41bf44caf81ac7cd7516e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 8afe0b8a5e2e9f00b4040885259ee49e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot df6d560bd1c4eec2f776072eb4e640cc.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to 2b26b801-953b-49b6-bd10-2d3e33776237 @ localhost (dataPort=-1)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 8afe0b8a5e2e9f00b4040885259ee49e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 72bd738129c41bf44caf81ac7cd7516e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 18a9b368ecee42359acb71c3947b4f11.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot df6d560bd1c4eec2f776072eb4e640cc.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 8afe0b8a5e2e9f00b4040885259ee49e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 72bd738129c41bf44caf81ac7cd7516e.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to 2b26b801-953b-49b6-bd10-2d3e33776237 @ localhost (dataPort=-1)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to 2b26b801-953b-49b6-bd10-2d3e33776237 @ localhost (dataPort=-1)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to 2b26b801-953b-49b6-bd10-2d3e33776237 @ localhost (dataPort=-1)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to 2b26b801-953b-49b6-bd10-2d3e33776237 @ localhost (dataPort=-1)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to 2b26b801-953b-49b6-bd10-2d3e33776237 @ localhost (dataPort=-1)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) switched from SCHEDULED to DEPLOYING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to 2b26b801-953b-49b6-bd10-2d3e33776237 @ localhost (dataPort=-1)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [52fbfb6cd3b1cf089b35bb5d9f864d4c]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [72bd738129c41bf44caf81ac7cd7516e]. Ignoring.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-14 16:43:28 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) switched from CREATED to DEPLOYING.
2020-01-14 16:43:28 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) [DEPLOYING]
2020-01-14 16:43:28 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) [DEPLOYING].
2020-01-14 16:43:28 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) [DEPLOYING].
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) switched from CREATED to DEPLOYING.
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) [DEPLOYING]
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) switched from CREATED to DEPLOYING.
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) switched from CREATED to DEPLOYING.
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) [DEPLOYING]
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) [DEPLOYING]
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) [DEPLOYING].
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) switched from CREATED to DEPLOYING.
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) [DEPLOYING]
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) [DEPLOYING].
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) switched from CREATED to DEPLOYING.
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) [DEPLOYING]
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (55de19043984da01288405e4e35a1e1d) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (594d00b25d001e961d9e7f4eaa2b44af) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (faaecdf3234b9f14707dc1d0b43dea1a) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) [DEPLOYING].
2020-01-14 16:43:28 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (64987d1ba38d748faff7b884f1145975) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (3bd77959d2fa9052739526d2a03097e6) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 18a9b368ecee42359acb71c3947b4f11.
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot df6d560bd1c4eec2f776072eb4e640cc.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 8afe0b8a5e2e9f00b4040885259ee49e.
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (68016e18cd389caba2a4a9a5f85884a9) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 81e5b494d36d4a69d4cfb53780edb61b.
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) switched from CREATED to DEPLOYING.
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) [DEPLOYING]
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) [DEPLOYING].
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) [DEPLOYING].
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 52fbfb6cd3b1cf089b35bb5d9f864d4c.
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 72bd738129c41bf44caf81ac7cd7516e.
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 16:43:28 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (2a228d5a587c9a9075e313a13c30c7d2) switched from DEPLOYING to RUNNING.
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:43:28 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:43:28 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:43:28 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:43:28 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-14 16:43:28 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 16:43:28 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-14 16:43:28 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:43:29 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:43:29 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:43:29 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:43:29 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:43:29 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 16:43:41 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:44523
2020-01-14 16:43:41 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 16:43:41 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-7b970b11-6656-4b12-b455-03f88e32761e
2020-01-14 16:43:41 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 16:43:41 [IOManagerAsync shutdown hook] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-189d3e2b-195a-465c-a5ac-917dcbeca8e2
2020-01-14 16:43:41 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 16:43:48 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 19:43:50 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-14 19:43:51 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 19:43:51 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 19:43:51 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 19:43:51 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 19:43:51 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 19:43:51 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:43:52 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 19:43:52 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:43:52 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 19:43:52 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:44253]
2020-01-14 19:43:52 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:44253
2020-01-14 19:43:52 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 19:43:52 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 19:43:52 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-633d3f7a-4567-4741-a587-786a20461361
2020-01-14 19:43:52 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:45483 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 19:43:52 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-bf7cc8eb-7fba-400a-9d44-a3e657cfa1f5
2020-01-14 19:43:52 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-42fbd8e8-5f6a-437b-97e8-bf3a14fe9aac
2020-01-14 19:43:52 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 19:43:52 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 9baae044-3ddf-48da-8cc9-80cef8d33b5f
2020-01-14 19:43:52 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 19:43:52 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-6797cdf3-e714-421b-bd16-fdf12dca3334 for spill files.
2020-01-14 19:43:52 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-1eeaa62f-cb2e-4fda-9643-712467b3438b for spill files.
2020-01-14 19:43:52 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 19:43:52 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 19:43:52 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 19:43:52 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 19:43:52 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 19:43:52 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 19:43:52 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 19:43:52 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-9d26d9de-98fb-4679-8ad2-1ef56213105b
2020-01-14 19:43:52 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 19:43:53 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 19:43:53 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 19:43:53 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 19:43:53 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:33735
2020-01-14 19:43:53 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@3c854752 @ http://localhost:33735
2020-01-14 19:43:53 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:33735 was granted leadership with leaderSessionID=40c98273-41a6-416c-bd29-93da33ba2815
2020-01-14 19:43:53 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:33735 , session=40c98273-41a6-416c-bd29-93da33ba2815
2020-01-14 19:43:53 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 19:43:53 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@2d9b9bde @ akka://flink/user/dispatcher
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 61b8f25a-ce0d-48a5-92f1-d456809b1728
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@3dbca13f @ akka://flink/user/resourcemanager
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 19:43:53 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=61b8f25a-ce0d-48a5-92f1-d456809b1728
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 91c12175375d92f8f508395fdf354151
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=f508395f-df35-4151-91c1-2175375d92f8
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(91c12175375d92f8f508395fdf354151).
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission 17406acf89d1e339e50d9eb14169e857 (Flink Streaming Job).
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job 17406acf89d1e339e50d9eb14169e857 (Flink Streaming Job).
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 9baae044-3ddf-48da-8cc9-80cef8d33b5f (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 6849c9c99c238a60710f3cddec6be6db.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:241 - Initializing job Flink Streaming Job (17406acf89d1e339e50d9eb14169e857).
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (17406acf89d1e339e50d9eb14169e857).
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (17406acf89d1e339e50d9eb14169e857).
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@37ac5e29 @ akka://flink/user/jobmanager_1
2020-01-14 19:43:53 [mini-cluster-io-thread-1] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (17406acf89d1e339e50d9eb14169e857) was granted leadership with session id 1ba3c72d-3bb3-4bef-8afb-2430d06e02a1 at akka://flink/user/jobmanager_1.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (17406acf89d1e339e50d9eb14169e857) under job master id 8afb2430d06e02a11ba3c72d3bb34bef.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (17406acf89d1e339e50d9eb14169e857) switched from state CREATED to RUNNING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) switched from CREATED to SCHEDULED.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ad2d572fa4b61dffeb7d07b16abe2930}]
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) switched from CREATED to SCHEDULED.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) switched from CREATED to SCHEDULED.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) switched from CREATED to SCHEDULED.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) switched from CREATED to SCHEDULED.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) switched from CREATED to SCHEDULED.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) switched from CREATED to SCHEDULED.
2020-01-14 19:43:53 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=1ba3c72d-3bb3-4bef-8afb-2430d06e02a1
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(91c12175375d92f8f508395fdf354151)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 8afb2430d06e02a11ba3c72d3bb34bef@akka://flink/user/jobmanager_1 for job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 8afb2430d06e02a11ba3c72d3bb34bef@akka://flink/user/jobmanager_1 for job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 91c12175375d92f8f508395fdf354151.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ad2d572fa4b61dffeb7d07b16abe2930}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 17406acf89d1e339e50d9eb14169e857 with allocation id c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request c0cc7b225786840d4146c69b522428ee for job 17406acf89d1e339e50d9eb14169e857 from resource manager with leader id 91c12175375d92f8f508395fdf354151.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 17406acf89d1e339e50d9eb14169e857 for job leader monitoring.
2020-01-14 19:43:53 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 1ba3c72d-3bb3-4bef-8afb-2430d06e02a1.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{22a894fa1a6e39d6de86311269e1ad6a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 17406acf89d1e339e50d9eb14169e857 with allocation id 170859e2c4c8a6d8bce42fd99ebc58ae.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7edcb066f38d414e1288308ab2acb325}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 170859e2c4c8a6d8bce42fd99ebc58ae for job 17406acf89d1e339e50d9eb14169e857 from resource manager with leader id 91c12175375d92f8f508395fdf354151.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 170859e2c4c8a6d8bce42fd99ebc58ae.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 17406acf89d1e339e50d9eb14169e857 with allocation id 135eaefe1d3e2e5acc97365a1f0d9fc3.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d932d92557d542a860055dfed9ffd034}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 135eaefe1d3e2e5acc97365a1f0d9fc3 for job 17406acf89d1e339e50d9eb14169e857 from resource manager with leader id 91c12175375d92f8f508395fdf354151.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 135eaefe1d3e2e5acc97365a1f0d9fc3.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 17406acf89d1e339e50d9eb14169e857 with allocation id 0991cb4daf434ea2b8d99447fb5203b4.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 0991cb4daf434ea2b8d99447fb5203b4 for job 17406acf89d1e339e50d9eb14169e857 from resource manager with leader id 91c12175375d92f8f508395fdf354151.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c44d7fa6980d1ee90f3ee94fa9f9eb5c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 0991cb4daf434ea2b8d99447fb5203b4.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 17406acf89d1e339e50d9eb14169e857 with allocation id f000349496499bb285f63d4c8e79d10f.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request f000349496499bb285f63d4c8e79d10f for job 17406acf89d1e339e50d9eb14169e857 from resource manager with leader id 91c12175375d92f8f508395fdf354151.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for f000349496499bb285f63d4c8e79d10f.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c2cfb008a9d85a5c2222580be611c0eb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 17406acf89d1e339e50d9eb14169e857 with allocation id ce9002c34ff474bf0ae0e88a3f499818.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request ce9002c34ff474bf0ae0e88a3f499818 for job 17406acf89d1e339e50d9eb14169e857 from resource manager with leader id 91c12175375d92f8f508395fdf354151.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for ce9002c34ff474bf0ae0e88a3f499818.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 17406acf89d1e339e50d9eb14169e857.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [c0cc7b225786840d4146c69b522428ee]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 170859e2c4c8a6d8bce42fd99ebc58ae.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [170859e2c4c8a6d8bce42fd99ebc58ae]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [c0cc7b225786840d4146c69b522428ee]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 170859e2c4c8a6d8bce42fd99ebc58ae.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 135eaefe1d3e2e5acc97365a1f0d9fc3.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [c0cc7b225786840d4146c69b522428ee]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [170859e2c4c8a6d8bce42fd99ebc58ae]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [135eaefe1d3e2e5acc97365a1f0d9fc3]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 170859e2c4c8a6d8bce42fd99ebc58ae.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 0991cb4daf434ea2b8d99447fb5203b4.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 135eaefe1d3e2e5acc97365a1f0d9fc3.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [c0cc7b225786840d4146c69b522428ee]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [170859e2c4c8a6d8bce42fd99ebc58ae]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [0991cb4daf434ea2b8d99447fb5203b4]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [135eaefe1d3e2e5acc97365a1f0d9fc3]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [c0cc7b225786840d4146c69b522428ee]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [f000349496499bb285f63d4c8e79d10f]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot f000349496499bb285f63d4c8e79d10f.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 170859e2c4c8a6d8bce42fd99ebc58ae.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 0991cb4daf434ea2b8d99447fb5203b4.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to 9baae044-3ddf-48da-8cc9-80cef8d33b5f @ localhost (dataPort=-1)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 135eaefe1d3e2e5acc97365a1f0d9fc3.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to 9baae044-3ddf-48da-8cc9-80cef8d33b5f @ localhost (dataPort=-1)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to 9baae044-3ddf-48da-8cc9-80cef8d33b5f @ localhost (dataPort=-1)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to 9baae044-3ddf-48da-8cc9-80cef8d33b5f @ localhost (dataPort=-1)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to 9baae044-3ddf-48da-8cc9-80cef8d33b5f @ localhost (dataPort=-1)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to 9baae044-3ddf-48da-8cc9-80cef8d33b5f @ localhost (dataPort=-1)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to 9baae044-3ddf-48da-8cc9-80cef8d33b5f @ localhost (dataPort=-1)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [170859e2c4c8a6d8bce42fd99ebc58ae]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [0991cb4daf434ea2b8d99447fb5203b4]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [135eaefe1d3e2e5acc97365a1f0d9fc3]. Ignoring.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-14 19:43:53 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) switched from CREATED to DEPLOYING.
2020-01-14 19:43:53 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) [DEPLOYING]
2020-01-14 19:43:53 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) [DEPLOYING].
2020-01-14 19:43:53 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) [DEPLOYING].
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) switched from CREATED to DEPLOYING.
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) [DEPLOYING]
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) [DEPLOYING].
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot c0cc7b225786840d4146c69b522428ee.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot f000349496499bb285f63d4c8e79d10f.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot ce9002c34ff474bf0ae0e88a3f499818.
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 170859e2c4c8a6d8bce42fd99ebc58ae.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 0991cb4daf434ea2b8d99447fb5203b4.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 135eaefe1d3e2e5acc97365a1f0d9fc3.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (de72ce7029f55a8ff04a0573d1b08a77) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) switched from CREATED to DEPLOYING.
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) [DEPLOYING]
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) [DEPLOYING].
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-14 19:43:53 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (88508e9fc07dee49ad329dd3f6e3dc62) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (7220a170741173b15e2503b1317236a4) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) switched from CREATED to DEPLOYING.
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) [DEPLOYING]
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (67e17cf8fec8ea32c5d5bab7c35be2da) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) switched from CREATED to DEPLOYING.
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) [DEPLOYING]
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) [DEPLOYING].
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (d3e49fdc7806737081768cb6485f0aa5) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) switched from CREATED to DEPLOYING.
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) [DEPLOYING]
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (50538b82daccb5f21439339b51a2d9a0) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) switched from CREATED to DEPLOYING.
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) [DEPLOYING]
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) [DEPLOYING].
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:43:53 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (21f06b555fbc270474e911204993d52b) switched from DEPLOYING to RUNNING.
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:43:53 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:43:53 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:43:53 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:43:53 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:43:53 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:43:53 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:43:53 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-14 19:43:53 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-14 19:43:54 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:43:54 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:43:54 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:43:54 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:43:54 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:43:54 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:43:56 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 19:43:56 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:45483
2020-01-14 19:43:56 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 19:57:02 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-14 19:57:03 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 19:57:03 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 19:57:03 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 19:57:03 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 19:57:03 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 19:57:04 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:57:04 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 19:57:04 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:57:04 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 19:57:04 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:38541]
2020-01-14 19:57:04 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:38541
2020-01-14 19:57:04 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 19:57:04 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 19:57:04 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-429b13a6-ec58-4f48-b119-c8b8d272e95c
2020-01-14 19:57:04 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:36113 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 19:57:04 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-2230104f-3beb-46a7-ab9c-90d8ca02cf8f
2020-01-14 19:57:04 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-8028886d-bada-4cf7-a5d2-e89c448e188e
2020-01-14 19:57:04 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 19:57:04 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 6a8023e8-667c-4ab5-adb1-de54e5c7cbea
2020-01-14 19:57:04 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 19:57:04 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-cbaedf06-363b-41ca-97c7-06cfed68f746 for spill files.
2020-01-14 19:57:04 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-fd33afe4-8b15-4e08-b2e2-d2f59883d403 for spill files.
2020-01-14 19:57:04 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 19:57:04 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 19:57:04 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 19:57:04 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 19:57:04 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 19:57:04 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 19:57:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 19:57:04 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-27a10774-0694-4187-af60-d89f9dee17ee
2020-01-14 19:57:04 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 19:57:05 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 19:57:05 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 19:57:05 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 19:57:05 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:40683
2020-01-14 19:57:05 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@3c854752 @ http://localhost:40683
2020-01-14 19:57:05 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:40683 was granted leadership with leaderSessionID=bab968f1-de3e-4a03-8ebf-0df7b53ad3d1
2020-01-14 19:57:05 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:40683 , session=bab968f1-de3e-4a03-8ebf-0df7b53ad3d1
2020-01-14 19:57:05 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 19:57:05 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@5363b904 @ akka://flink/user/resourcemanager
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@7ca59da9 @ akka://flink/user/dispatcher
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token baa705e4a27bd9457f2e067dc5084c4d
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 19:57:05 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=7f2e067d-c508-4c4d-baa7-05e4a27bd945
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 73d443ca-2461-4a35-ad6f-d108b0550a9d
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=73d443ca-2461-4a35-ad6f-d108b0550a9d
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(baa705e4a27bd9457f2e067dc5084c4d).
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 6a8023e8-667c-4ab5-adb1-de54e5c7cbea (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 20ce5d0272ebc5f849378f90654d348c (Flink Streaming Job).
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 20ce5d0272ebc5f849378f90654d348c (Flink Streaming Job).
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 7e3f4fadb1b371aa5abd4814a008d319.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (20ce5d0272ebc5f849378f90654d348c).
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (20ce5d0272ebc5f849378f90654d348c).
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (20ce5d0272ebc5f849378f90654d348c).
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@c7ce54e @ akka://flink/user/jobmanager_1
2020-01-14 19:57:05 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (20ce5d0272ebc5f849378f90654d348c) was granted leadership with session id 4b21844f-bb3f-4e1b-9ea8-3519863db607 at akka://flink/user/jobmanager_1.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (20ce5d0272ebc5f849378f90654d348c) under job master id 9ea83519863db6074b21844fbb3f4e1b.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (20ce5d0272ebc5f849378f90654d348c) switched from state CREATED to RUNNING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) switched from CREATED to SCHEDULED.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a2bb37b3058e031ebe2ae6d5cc9a75fa}]
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) switched from CREATED to SCHEDULED.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) switched from CREATED to SCHEDULED.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) switched from CREATED to SCHEDULED.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) switched from CREATED to SCHEDULED.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) switched from CREATED to SCHEDULED.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) switched from CREATED to SCHEDULED.
2020-01-14 19:57:05 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=4b21844f-bb3f-4e1b-9ea8-3519863db607
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(baa705e4a27bd9457f2e067dc5084c4d)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 9ea83519863db6074b21844fbb3f4e1b@akka://flink/user/jobmanager_1 for job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager 9ea83519863db6074b21844fbb3f4e1b@akka://flink/user/jobmanager_1 for job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: baa705e4a27bd9457f2e067dc5084c4d.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a2bb37b3058e031ebe2ae6d5cc9a75fa}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 20ce5d0272ebc5f849378f90654d348c with allocation id 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 3752ca7ef0b96848a667bd61e25cd464 for job 20ce5d0272ebc5f849378f90654d348c from resource manager with leader id baa705e4a27bd9457f2e067dc5084c4d.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 20ce5d0272ebc5f849378f90654d348c for job leader monitoring.
2020-01-14 19:57:05 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 4b21844f-bb3f-4e1b-9ea8-3519863db607.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{4c44c841b50f8ff0b0625d911a426185}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 20ce5d0272ebc5f849378f90654d348c with allocation id 083c6f58ae339a9bcbc03443a34bf4f2.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{118941459ae679b3b8266d56e51604c3}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 083c6f58ae339a9bcbc03443a34bf4f2 for job 20ce5d0272ebc5f849378f90654d348c from resource manager with leader id baa705e4a27bd9457f2e067dc5084c4d.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 083c6f58ae339a9bcbc03443a34bf4f2.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 20ce5d0272ebc5f849378f90654d348c with allocation id 5bd7c1c278cb32f1f53579cb8c63c7f1.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 5bd7c1c278cb32f1f53579cb8c63c7f1 for job 20ce5d0272ebc5f849378f90654d348c from resource manager with leader id baa705e4a27bd9457f2e067dc5084c4d.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 5bd7c1c278cb32f1f53579cb8c63c7f1.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f791be4ea2ffbd67a9ed29ac9d73f827}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{4ba6089052363c317b6ca0172e6c7616}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 20ce5d0272ebc5f849378f90654d348c with allocation id 43a0d9c3aa120a0379608f82d1a6aa2b.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 20ce5d0272ebc5f849378f90654d348c with allocation id ffe502a2c8391b6946de8b1968ce3264.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 43a0d9c3aa120a0379608f82d1a6aa2b for job 20ce5d0272ebc5f849378f90654d348c from resource manager with leader id baa705e4a27bd9457f2e067dc5084c4d.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5af972b9803f029b38ed1c8fe3f58ecf}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 43a0d9c3aa120a0379608f82d1a6aa2b.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 20ce5d0272ebc5f849378f90654d348c with allocation id 2367ac67ef325bc982c9413f5c2cb722.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request ffe502a2c8391b6946de8b1968ce3264 for job 20ce5d0272ebc5f849378f90654d348c from resource manager with leader id baa705e4a27bd9457f2e067dc5084c4d.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for ffe502a2c8391b6946de8b1968ce3264.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [3752ca7ef0b96848a667bd61e25cd464]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [083c6f58ae339a9bcbc03443a34bf4f2]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [3752ca7ef0b96848a667bd61e25cd464]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 2367ac67ef325bc982c9413f5c2cb722 for job 20ce5d0272ebc5f849378f90654d348c from resource manager with leader id baa705e4a27bd9457f2e067dc5084c4d.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 2367ac67ef325bc982c9413f5c2cb722.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [3752ca7ef0b96848a667bd61e25cd464]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 20ce5d0272ebc5f849378f90654d348c.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5bd7c1c278cb32f1f53579cb8c63c7f1]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [083c6f58ae339a9bcbc03443a34bf4f2]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [3752ca7ef0b96848a667bd61e25cd464]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 083c6f58ae339a9bcbc03443a34bf4f2.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5bd7c1c278cb32f1f53579cb8c63c7f1]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [43a0d9c3aa120a0379608f82d1a6aa2b]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [083c6f58ae339a9bcbc03443a34bf4f2]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 083c6f58ae339a9bcbc03443a34bf4f2.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [ffe502a2c8391b6946de8b1968ce3264]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [3752ca7ef0b96848a667bd61e25cd464]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5bd7c1c278cb32f1f53579cb8c63c7f1.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5bd7c1c278cb32f1f53579cb8c63c7f1]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5bd7c1c278cb32f1f53579cb8c63c7f1.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 43a0d9c3aa120a0379608f82d1a6aa2b.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to 6a8023e8-667c-4ab5-adb1-de54e5c7cbea @ localhost (dataPort=-1)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 083c6f58ae339a9bcbc03443a34bf4f2.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot ffe502a2c8391b6946de8b1968ce3264.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5bd7c1c278cb32f1f53579cb8c63c7f1.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 43a0d9c3aa120a0379608f82d1a6aa2b.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 083c6f58ae339a9bcbc03443a34bf4f2.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to 6a8023e8-667c-4ab5-adb1-de54e5c7cbea @ localhost (dataPort=-1)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to 6a8023e8-667c-4ab5-adb1-de54e5c7cbea @ localhost (dataPort=-1)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to 6a8023e8-667c-4ab5-adb1-de54e5c7cbea @ localhost (dataPort=-1)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to 6a8023e8-667c-4ab5-adb1-de54e5c7cbea @ localhost (dataPort=-1)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to 6a8023e8-667c-4ab5-adb1-de54e5c7cbea @ localhost (dataPort=-1)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to 6a8023e8-667c-4ab5-adb1-de54e5c7cbea @ localhost (dataPort=-1)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [43a0d9c3aa120a0379608f82d1a6aa2b]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [083c6f58ae339a9bcbc03443a34bf4f2]. Ignoring.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-14 19:57:05 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) switched from CREATED to DEPLOYING.
2020-01-14 19:57:05 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) [DEPLOYING]
2020-01-14 19:57:05 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) [DEPLOYING].
2020-01-14 19:57:05 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) [DEPLOYING].
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) switched from CREATED to DEPLOYING.
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) [DEPLOYING]
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) [DEPLOYING].
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) [DEPLOYING].
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) switched from CREATED to DEPLOYING.
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) [DEPLOYING]
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) [DEPLOYING].
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (bf2e4706ea09763abbeb3053a86b1036) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) [DEPLOYING].
2020-01-14 19:57:05 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (e4b4e0177f94bfcb811537a0e8885ccb) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (4dac4054ff7b2fea4bdd766762395227) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) switched from CREATED to DEPLOYING.
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) [DEPLOYING]
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) [DEPLOYING].
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) [DEPLOYING].
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (7d1e1665e13b0b7524aaff71abfe3b19) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) switched from CREATED to DEPLOYING.
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) [DEPLOYING]
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) [DEPLOYING].
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) switched from CREATED to DEPLOYING.
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) [DEPLOYING]
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) [DEPLOYING].
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) [DEPLOYING].
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) [DEPLOYING].
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot ffe502a2c8391b6946de8b1968ce3264.
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) switched from CREATED to DEPLOYING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3752ca7ef0b96848a667bd61e25cd464.
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) [DEPLOYING]
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5bd7c1c278cb32f1f53579cb8c63c7f1.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 2367ac67ef325bc982c9413f5c2cb722.
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) [DEPLOYING].
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 43a0d9c3aa120a0379608f82d1a6aa2b.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 083c6f58ae339a9bcbc03443a34bf4f2.
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) [DEPLOYING].
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (5f2898e70448570d6473f84b9e95c252) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (6f1c5e6d97d0c0b56c229b77f317c12f) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:57:05 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (403be66c484a69ec1b453150fb60cef1) switched from DEPLOYING to RUNNING.
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:57:05 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-14 19:57:05 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:57:05 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-14 19:57:05 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:57:05 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-14 19:57:05 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-14 19:57:06 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:57:06 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:57:06 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:57:06 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:57:06 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:57:06 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:57:06 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 19:57:06 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 19:57:06 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 19:57:07 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-27a10774-0694-4187-af60-d89f9dee17ee
2020-01-14 19:58:19 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-14 19:58:19 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 19:58:19 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 19:58:19 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 19:58:19 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 19:58:19 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 19:58:20 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:58:20 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 19:58:20 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:58:20 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 19:58:20 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:34191]
2020-01-14 19:58:20 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:34191
2020-01-14 19:58:20 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 19:58:21 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 19:58:21 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-7fb42b85-c4de-4eb0-8c44-2b2b50ac9c6f
2020-01-14 19:58:21 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:34067 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 19:58:21 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-9147cd8e-c275-4064-8766-12502d70b9c5
2020-01-14 19:58:21 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-c8a61d45-0fef-49c5-b365-a13853c87297
2020-01-14 19:58:21 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 19:58:21 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: c03cbd9f-95ca-4d0e-9b72-e03c4e996161
2020-01-14 19:58:21 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 19:58:21 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-a9c266b2-cb97-4d21-9aa4-86e2c9323577 for spill files.
2020-01-14 19:58:21 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-c3f51246-3f15-408b-9c25-5a6021345436 for spill files.
2020-01-14 19:58:21 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 19:58:21 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 19:58:21 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 19:58:21 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 19:58:21 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 19:58:21 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-e94efc3b-a102-4db2-930a-e383afce07bf
2020-01-14 19:58:21 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 19:58:21 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 19:58:21 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 19:58:21 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 19:58:21 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:38029
2020-01-14 19:58:21 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@3c854752 @ http://localhost:38029
2020-01-14 19:58:21 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:38029 was granted leadership with leaderSessionID=1bf3d741-8400-4ebf-a993-de54ea6b58cb
2020-01-14 19:58:21 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:38029 , session=1bf3d741-8400-4ebf-a993-de54ea6b58cb
2020-01-14 19:58:21 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 19:58:21 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6ca1bf48 @ akka://flink/user/resourcemanager
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@30818f58 @ akka://flink/user/dispatcher
2020-01-14 19:58:21 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9b481854518f8efb6e4373f12ca84c0d
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 214e3d75-2d73-4580-8e1d-3b4d14c495e9
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=214e3d75-2d73-4580-8e1d-3b4d14c495e9
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=6e4373f1-2ca8-4c0d-9b48-1854518f8efb
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(9b481854518f8efb6e4373f12ca84c0d).
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission b927e34d439b7e140ffda490acda8f9b (Flink Streaming Job).
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job b927e34d439b7e140ffda490acda8f9b (Flink Streaming Job).
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID c03cbd9f-95ca-4d0e-9b72-e03c4e996161 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 3e3d5a0fa1c9bcda4104cab4b6562a8a.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (b927e34d439b7e140ffda490acda8f9b).
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (b927e34d439b7e140ffda490acda8f9b).
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (b927e34d439b7e140ffda490acda8f9b).
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@f4bd2c @ akka://flink/user/jobmanager_1
2020-01-14 19:58:21 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (b927e34d439b7e140ffda490acda8f9b) was granted leadership with session id a559567f-a542-4b0e-8872-d8a7b648d721 at akka://flink/user/jobmanager_1.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (b927e34d439b7e140ffda490acda8f9b) under job master id 8872d8a7b648d721a559567fa5424b0e.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (b927e34d439b7e140ffda490acda8f9b) switched from state CREATED to RUNNING.
2020-01-14 19:58:21 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) switched from CREATED to SCHEDULED.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{121bc8ab27db99dbee42c4448018f305}]
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) switched from CREATED to SCHEDULED.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) switched from CREATED to SCHEDULED.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) switched from CREATED to SCHEDULED.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) switched from CREATED to SCHEDULED.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) switched from CREATED to SCHEDULED.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) switched from CREATED to SCHEDULED.
2020-01-14 19:58:22 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=a559567f-a542-4b0e-8872-d8a7b648d721
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(9b481854518f8efb6e4373f12ca84c0d)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager 8872d8a7b648d721a559567fa5424b0e@akka://flink/user/jobmanager_1 for job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager 8872d8a7b648d721a559567fa5424b0e@akka://flink/user/jobmanager_1 for job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 9b481854518f8efb6e4373f12ca84c0d.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{121bc8ab27db99dbee42c4448018f305}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b927e34d439b7e140ffda490acda8f9b with allocation id ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request ac5c7e65f37f72952b4504ec170015f3 for job b927e34d439b7e140ffda490acda8f9b from resource manager with leader id 9b481854518f8efb6e4373f12ca84c0d.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b927e34d439b7e140ffda490acda8f9b for job leader monitoring.
2020-01-14 19:58:22 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id a559567f-a542-4b0e-8872-d8a7b648d721.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a5264b34dc262a9fa3780f2f940e0f4c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b927e34d439b7e140ffda490acda8f9b with allocation id 04cf3ccbe8d7110ed718ac36d9a1e822.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{6ca31ab82e0ec989d8781a93f8f57c7d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 04cf3ccbe8d7110ed718ac36d9a1e822 for job b927e34d439b7e140ffda490acda8f9b from resource manager with leader id 9b481854518f8efb6e4373f12ca84c0d.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e990969c9b0706c73348fb07ac2f8f20}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b927e34d439b7e140ffda490acda8f9b with allocation id 5caf96421b7b87c2394ccfc31a228a82.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 04cf3ccbe8d7110ed718ac36d9a1e822.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b927e34d439b7e140ffda490acda8f9b with allocation id 73228b6ffe4c893f20095e95d2065f56.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{056ff0a1f08abbe9270a1f4b00aeb01e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 5caf96421b7b87c2394ccfc31a228a82 for job b927e34d439b7e140ffda490acda8f9b from resource manager with leader id 9b481854518f8efb6e4373f12ca84c0d.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b927e34d439b7e140ffda490acda8f9b with allocation id db630cff80a40180a2a23434635d90a0.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{422dda6b10f9ae7c7f092b95e950e2ee}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 5caf96421b7b87c2394ccfc31a228a82.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b927e34d439b7e140ffda490acda8f9b with allocation id 561d0f45fade94a692023ea333bf2f57.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 73228b6ffe4c893f20095e95d2065f56 for job b927e34d439b7e140ffda490acda8f9b from resource manager with leader id 9b481854518f8efb6e4373f12ca84c0d.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 73228b6ffe4c893f20095e95d2065f56.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request db630cff80a40180a2a23434635d90a0 for job b927e34d439b7e140ffda490acda8f9b from resource manager with leader id 9b481854518f8efb6e4373f12ca84c0d.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for db630cff80a40180a2a23434635d90a0.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 561d0f45fade94a692023ea333bf2f57 for job b927e34d439b7e140ffda490acda8f9b from resource manager with leader id 9b481854518f8efb6e4373f12ca84c0d.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [ac5c7e65f37f72952b4504ec170015f3]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 561d0f45fade94a692023ea333bf2f57.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [04cf3ccbe8d7110ed718ac36d9a1e822]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b927e34d439b7e140ffda490acda8f9b.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [ac5c7e65f37f72952b4504ec170015f3]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 04cf3ccbe8d7110ed718ac36d9a1e822.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [04cf3ccbe8d7110ed718ac36d9a1e822]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [ac5c7e65f37f72952b4504ec170015f3]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 04cf3ccbe8d7110ed718ac36d9a1e822.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5caf96421b7b87c2394ccfc31a228a82]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5caf96421b7b87c2394ccfc31a228a82.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [04cf3ccbe8d7110ed718ac36d9a1e822]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 04cf3ccbe8d7110ed718ac36d9a1e822.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [ac5c7e65f37f72952b4504ec170015f3]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [73228b6ffe4c893f20095e95d2065f56]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 73228b6ffe4c893f20095e95d2065f56.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5caf96421b7b87c2394ccfc31a228a82]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5caf96421b7b87c2394ccfc31a228a82.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [04cf3ccbe8d7110ed718ac36d9a1e822]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [ac5c7e65f37f72952b4504ec170015f3]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 04cf3ccbe8d7110ed718ac36d9a1e822.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 73228b6ffe4c893f20095e95d2065f56.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5caf96421b7b87c2394ccfc31a228a82.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot db630cff80a40180a2a23434635d90a0.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to c03cbd9f-95ca-4d0e-9b72-e03c4e996161 @ localhost (dataPort=-1)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to c03cbd9f-95ca-4d0e-9b72-e03c4e996161 @ localhost (dataPort=-1)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to c03cbd9f-95ca-4d0e-9b72-e03c4e996161 @ localhost (dataPort=-1)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to c03cbd9f-95ca-4d0e-9b72-e03c4e996161 @ localhost (dataPort=-1)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to c03cbd9f-95ca-4d0e-9b72-e03c4e996161 @ localhost (dataPort=-1)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to c03cbd9f-95ca-4d0e-9b72-e03c4e996161 @ localhost (dataPort=-1)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to c03cbd9f-95ca-4d0e-9b72-e03c4e996161 @ localhost (dataPort=-1)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [73228b6ffe4c893f20095e95d2065f56]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5caf96421b7b87c2394ccfc31a228a82]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [db630cff80a40180a2a23434635d90a0]. Ignoring.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-14 19:58:22 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) switched from CREATED to DEPLOYING.
2020-01-14 19:58:22 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) [DEPLOYING]
2020-01-14 19:58:22 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) [DEPLOYING].
2020-01-14 19:58:22 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) [DEPLOYING].
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) switched from CREATED to DEPLOYING.
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) [DEPLOYING]
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) [DEPLOYING].
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) switched from CREATED to DEPLOYING.
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) [DEPLOYING]
2020-01-14 19:58:22 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) [DEPLOYING].
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (b05a834a07655b6d988f12c5119b0f4e) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) switched from CREATED to DEPLOYING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (bf853bfdca4e65c0240b18da59ac044c) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) [DEPLOYING]
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (6bcc7373d8b565364551ac2c69ee8b5c) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (a34e26cbc40e752be6a8c7489b3d3a38) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 04cf3ccbe8d7110ed718ac36d9a1e822.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot ac5c7e65f37f72952b4504ec170015f3.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 561d0f45fade94a692023ea333bf2f57.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 73228b6ffe4c893f20095e95d2065f56.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 5caf96421b7b87c2394ccfc31a228a82.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot db630cff80a40180a2a23434635d90a0.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) switched from CREATED to DEPLOYING.
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) [DEPLOYING]
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (4ebdf7e3f9922d75d7df61e7ac92c321) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) switched from CREATED to DEPLOYING.
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) [DEPLOYING]
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) [DEPLOYING].
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) switched from CREATED to DEPLOYING.
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) [DEPLOYING]
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) [DEPLOYING].
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (97a87b00313bcef90d2ee190819f8aa0) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (ea7e67a67c372509e12c178d68d70a79) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:22 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:22 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:22 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:22 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:22 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:22 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-14 19:58:22 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:22 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:22 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:22 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:22 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:22 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:26 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 19:58:26 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 19:58:26 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 19:58:26 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 19:58:26 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 19:58:27 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:58:27 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 19:58:27 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 19:58:27 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 19:58:28 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:34685]
2020-01-14 19:58:28 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:34685
2020-01-14 19:58:28 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 19:58:28 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 19:58:28 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-03e72d95-6fc5-4c20-81c5-20b0b1eca80e
2020-01-14 19:58:28 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:41187 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 19:58:28 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-47dd189d-eb62-4aaa-852b-3173f5b9cfa3
2020-01-14 19:58:28 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-1acee499-dbba-48e5-b618-55b539b02716
2020-01-14 19:58:28 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 19:58:28 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 623eac29-92d1-4f1b-903c-cf1479aada32
2020-01-14 19:58:28 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 19:58:28 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-59aa4109-8be0-4b75-b761-8774c5319e3d for spill files.
2020-01-14 19:58:28 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-7afe53ec-ac9e-44a8-9607-d4b0150351f9 for spill files.
2020-01-14 19:58:28 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 19:58:28 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 19:58:28 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 19:58:28 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 19:58:28 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 19:58:28 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 19:58:28 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 19:58:28 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-79f6903d-78b6-4796-a66f-9d7f79785220
2020-01-14 19:58:28 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 19:58:28 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 19:58:28 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 19:58:28 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 19:58:29 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:42803
2020-01-14 19:58:29 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@67f77f6e @ http://localhost:42803
2020-01-14 19:58:29 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:42803 was granted leadership with leaderSessionID=0a5e11f2-9f5b-4c18-80e6-fcfba1a7e24c
2020-01-14 19:58:29 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:42803 , session=0a5e11f2-9f5b-4c18-80e6-fcfba1a7e24c
2020-01-14 19:58:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 19:58:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@c0873d6 @ akka://flink/user/resourcemanager
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@5631a406 @ akka://flink/user/dispatcher
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9516423d2b4bb02bc71548ed9ba04df7
2020-01-14 19:58:29 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token bb6f8708-e350-4f60-b602-8e1cd2c026e9
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=bb6f8708-e350-4f60-b602-8e1cd2c026e9
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=c71548ed-9ba0-4df7-9516-423d2b4bb02b
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(9516423d2b4bb02bc71548ed9ba04df7).
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission 2eb6ac40a2384f8f1d49d74708f3cd43 (Flink Streaming Job).
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job 2eb6ac40a2384f8f1d49d74708f3cd43 (Flink Streaming Job).
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 623eac29-92d1-4f1b-903c-cf1479aada32 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id cc7f0deac383ffeca0a93c6aa1605e16.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (2eb6ac40a2384f8f1d49d74708f3cd43).
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (2eb6ac40a2384f8f1d49d74708f3cd43).
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (2eb6ac40a2384f8f1d49d74708f3cd43).
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@2e4742f @ akka://flink/user/jobmanager_1
2020-01-14 19:58:29 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (2eb6ac40a2384f8f1d49d74708f3cd43) was granted leadership with session id 8a19af16-a00f-432d-b6bf-72063aee6e74 at akka://flink/user/jobmanager_1.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (2eb6ac40a2384f8f1d49d74708f3cd43) under job master id b6bf72063aee6e748a19af16a00f432d.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (2eb6ac40a2384f8f1d49d74708f3cd43) switched from state CREATED to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) switched from CREATED to SCHEDULED.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f19f8ca473e82debee6e3ecb22419535}]
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) switched from CREATED to SCHEDULED.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{329ca79187628e4f8e211cfe4e91f583}]
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) switched from CREATED to SCHEDULED.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a6e4eadbee0d98cfdbcd1ff82773d87b}]
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) switched from CREATED to SCHEDULED.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ea871aa83f95e85d2208a7888a7cb2db}]
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) switched from CREATED to SCHEDULED.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4ecf86afa3356ad11ad43d07b6cdf84e}]
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) switched from CREATED to SCHEDULED.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{76531aa40dec00133147e112a9061c7d}]
2020-01-14 19:58:29 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=8a19af16-a00f-432d-b6bf-72063aee6e74
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(9516423d2b4bb02bc71548ed9ba04df7)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:302 - Registering job manager b6bf72063aee6e748a19af16a00f432d@akka://flink/user/jobmanager_1 for job 2eb6ac40a2384f8f1d49d74708f3cd43.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager b6bf72063aee6e748a19af16a00f432d@akka://flink/user/jobmanager_1 for job 2eb6ac40a2384f8f1d49d74708f3cd43.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 9516423d2b4bb02bc71548ed9ba04df7.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f19f8ca473e82debee6e3ecb22419535}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 2eb6ac40a2384f8f1d49d74708f3cd43 with allocation id f182038c6f21544ed2414ff02be2e547.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request f182038c6f21544ed2414ff02be2e547 for job 2eb6ac40a2384f8f1d49d74708f3cd43 from resource manager with leader id 9516423d2b4bb02bc71548ed9ba04df7.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{329ca79187628e4f8e211cfe4e91f583}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a6e4eadbee0d98cfdbcd1ff82773d87b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for f182038c6f21544ed2414ff02be2e547.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ea871aa83f95e85d2208a7888a7cb2db}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 2eb6ac40a2384f8f1d49d74708f3cd43 for job leader monitoring.
2020-01-14 19:58:29 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 8a19af16-a00f-432d-b6bf-72063aee6e74.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{4ecf86afa3356ad11ad43d07b6cdf84e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 2eb6ac40a2384f8f1d49d74708f3cd43 with allocation id e4783fc29e49b18b0407ac885fdb8657.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{76531aa40dec00133147e112a9061c7d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request e4783fc29e49b18b0407ac885fdb8657 for job 2eb6ac40a2384f8f1d49d74708f3cd43 from resource manager with leader id 9516423d2b4bb02bc71548ed9ba04df7.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 2eb6ac40a2384f8f1d49d74708f3cd43 with allocation id 9e801e414aaa5c24110517853a63d01d.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for e4783fc29e49b18b0407ac885fdb8657.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 2eb6ac40a2384f8f1d49d74708f3cd43 with allocation id 3f6c4710f9e46e604bc46851db63cbfb.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 2eb6ac40a2384f8f1d49d74708f3cd43 for job leader monitoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 9e801e414aaa5c24110517853a63d01d for job 2eb6ac40a2384f8f1d49d74708f3cd43 from resource manager with leader id 9516423d2b4bb02bc71548ed9ba04df7.
2020-01-14 19:58:29 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 8a19af16-a00f-432d-b6bf-72063aee6e74.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 9e801e414aaa5c24110517853a63d01d.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 2eb6ac40a2384f8f1d49d74708f3cd43 with allocation id 2818cbb53acb0dcb778360c3bc12e1a1.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 2eb6ac40a2384f8f1d49d74708f3cd43 for job leader monitoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 3f6c4710f9e46e604bc46851db63cbfb for job 2eb6ac40a2384f8f1d49d74708f3cd43 from resource manager with leader id 9516423d2b4bb02bc71548ed9ba04df7.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 3f6c4710f9e46e604bc46851db63cbfb.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 2eb6ac40a2384f8f1d49d74708f3cd43 for job leader monitoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 2818cbb53acb0dcb778360c3bc12e1a1 for job 2eb6ac40a2384f8f1d49d74708f3cd43 from resource manager with leader id 9516423d2b4bb02bc71548ed9ba04df7.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 2818cbb53acb0dcb778360c3bc12e1a1.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 2eb6ac40a2384f8f1d49d74708f3cd43 for job leader monitoring.
2020-01-14 19:58:29 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 8a19af16-a00f-432d-b6bf-72063aee6e74.
2020-01-14 19:58:29 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 8a19af16-a00f-432d-b6bf-72063aee6e74.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 2eb6ac40a2384f8f1d49d74708f3cd43.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job 2eb6ac40a2384f8f1d49d74708f3cd43.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 2eb6ac40a2384f8f1d49d74708f3cd43 with allocation id d863ff592286315c2f35626cfb7883d6.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 2eb6ac40a2384f8f1d49d74708f3cd43.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d863ff592286315c2f35626cfb7883d6 for job 2eb6ac40a2384f8f1d49d74708f3cd43 from resource manager with leader id 9516423d2b4bb02bc71548ed9ba04df7.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d863ff592286315c2f35626cfb7883d6.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 2eb6ac40a2384f8f1d49d74708f3cd43.
2020-01-14 19:58:29 [mini-cluster-io-thread-3] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 9e801e414aaa5c24110517853a63d01d.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot e4783fc29e49b18b0407ac885fdb8657.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot f182038c6f21544ed2414ff02be2e547.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [9e801e414aaa5c24110517853a63d01d]. Ignoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 3f6c4710f9e46e604bc46851db63cbfb.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e4783fc29e49b18b0407ac885fdb8657]. Ignoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 2818cbb53acb0dcb778360c3bc12e1a1.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [f182038c6f21544ed2414ff02be2e547]. Ignoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [3f6c4710f9e46e604bc46851db63cbfb]. Ignoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [2818cbb53acb0dcb778360c3bc12e1a1]. Ignoring.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 623eac29-92d1-4f1b-903c-cf1479aada32 @ localhost (dataPort=-1)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 623eac29-92d1-4f1b-903c-cf1479aada32 @ localhost (dataPort=-1)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 623eac29-92d1-4f1b-903c-cf1479aada32 @ localhost (dataPort=-1)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 623eac29-92d1-4f1b-903c-cf1479aada32 @ localhost (dataPort=-1)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 623eac29-92d1-4f1b-903c-cf1479aada32 @ localhost (dataPort=-1)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) switched from SCHEDULED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 623eac29-92d1-4f1b-903c-cf1479aada32 @ localhost (dataPort=-1)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) switched from CREATED to DEPLOYING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) [DEPLOYING]
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (c742c60c629e890922b16a544d703430) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) switched from CREATED to DEPLOYING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) [DEPLOYING]
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) [DEPLOYING].
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (5a312fd8cd6cecf174b31588561dfdd8) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) switched from CREATED to DEPLOYING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) [DEPLOYING]
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (3355180bbb00e7c9e80644ba350a6202) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) switched from CREATED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) [DEPLOYING]
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) [DEPLOYING].
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 9e801e414aaa5c24110517853a63d01d.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot e4783fc29e49b18b0407ac885fdb8657.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot f182038c6f21544ed2414ff02be2e547.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 3f6c4710f9e46e604bc46851db63cbfb.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) switched from CREATED to DEPLOYING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 2818cbb53acb0dcb778360c3bc12e1a1.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot d863ff592286315c2f35626cfb7883d6.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) [DEPLOYING]
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (e97b966f9cdd7570b50b39ea7e52f63a) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (16f32669db05dcaf43cff89edef906fc) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) switched from CREATED to DEPLOYING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) [DEPLOYING]
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) [DEPLOYING].
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (c25601297f20cf5672154d3c0b0b2e77) switched from DEPLOYING to RUNNING.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:29 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 19:58:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 19:58:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 19:58:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 19:58:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 19:58:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 19:58:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-10, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 19:58:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-10, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 19:58:36 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:41187
2020-01-14 19:58:36 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:00:27 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 20:00:28 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 20:00:28 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 20:00:28 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 20:00:28 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 20:00:28 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:00:28 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 20:00:28 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:00:28 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 20:00:29 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:44483]
2020-01-14 20:00:29 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:44483
2020-01-14 20:00:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 20:00:29 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 20:00:29 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-bf1efced-9e68-4006-87e4-e4dd35dab8b7
2020-01-14 20:00:29 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:36127 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 20:00:29 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-34ad10a8-cfe2-4340-b12e-1a83bb7605c9
2020-01-14 20:00:29 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-aaaf41cc-a13d-4e63-a230-9c9f143d353f
2020-01-14 20:00:29 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 20:00:29 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: d2a11d80-c59f-459a-81ae-2ffdeb6c02bb
2020-01-14 20:00:29 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 20:00:29 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-f4e0f035-ab1b-478e-91bf-dffec55ecd1e for spill files.
2020-01-14 20:00:29 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-5ba99627-f35d-4d6b-84f0-cc44ca268206 for spill files.
2020-01-14 20:00:29 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 20:00:29 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 20:00:29 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 20:00:29 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 20:00:29 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 20:00:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 20:00:29 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 20:00:29 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-a6a22cc9-7354-4147-90ed-566ef74a21da
2020-01-14 20:00:29 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 20:00:29 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 20:00:29 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 20:00:29 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 20:00:30 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:34203
2020-01-14 20:00:30 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@67f77f6e @ http://localhost:34203
2020-01-14 20:00:30 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:34203 was granted leadership with leaderSessionID=a6329d53-833b-44ce-b7af-e62ad65e5590
2020-01-14 20:00:30 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:34203 , session=a6329d53-833b-44ce-b7af-e62ad65e5590
2020-01-14 20:00:30 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 20:00:30 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6fa9cc45 @ akka://flink/user/resourcemanager
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@7684759e @ akka://flink/user/dispatcher
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token a0f00a9f-0416-4401-b246-ea1e62f3cca3
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token a41e7e78b2e9fb15b6a0c0694fe34517
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=a0f00a9f-0416-4401-b246-ea1e62f3cca3
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 20:00:30 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=b6a0c069-4fe3-4517-a41e-7e78b2e9fb15
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(a41e7e78b2e9fb15b6a0c0694fe34517).
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission 72b8614ff4485e4c3da80d84cfc47861 (Flink Streaming Job).
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job 72b8614ff4485e4c3da80d84cfc47861 (Flink Streaming Job).
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID d2a11d80-c59f-459a-81ae-2ffdeb6c02bb (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 0ce115a570513aec361980ffdb509a9c.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (72b8614ff4485e4c3da80d84cfc47861).
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (72b8614ff4485e4c3da80d84cfc47861).
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (72b8614ff4485e4c3da80d84cfc47861).
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@15395efe @ akka://flink/user/jobmanager_1
2020-01-14 20:00:30 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (72b8614ff4485e4c3da80d84cfc47861) was granted leadership with session id c1ca163d-9466-489a-817c-89fe8331f966 at akka://flink/user/jobmanager_1.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (72b8614ff4485e4c3da80d84cfc47861) under job master id 817c89fe8331f966c1ca163d9466489a.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (72b8614ff4485e4c3da80d84cfc47861) switched from state CREATED to RUNNING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) switched from CREATED to SCHEDULED.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7b22916d4e51e7829aa4dc4398b276af}]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) switched from CREATED to SCHEDULED.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{87e1bcacb9b983e19c2e1fc828d718d9}]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) switched from CREATED to SCHEDULED.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{18e8dc5ca313e6a8051039c902cbfd94}]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) switched from CREATED to SCHEDULED.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f333f68fedf7878e6420f1a016ddee88}]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) switched from CREATED to SCHEDULED.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5a76abe0a75260881085a3cae8ec7a93}]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) switched from CREATED to SCHEDULED.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f43b74688ad14d1298651d4c7e0903f5}]
2020-01-14 20:00:30 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=c1ca163d-9466-489a-817c-89fe8331f966
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(a41e7e78b2e9fb15b6a0c0694fe34517)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager 817c89fe8331f966c1ca163d9466489a@akka://flink/user/jobmanager_1 for job 72b8614ff4485e4c3da80d84cfc47861.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager 817c89fe8331f966c1ca163d9466489a@akka://flink/user/jobmanager_1 for job 72b8614ff4485e4c3da80d84cfc47861.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: a41e7e78b2e9fb15b6a0c0694fe34517.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7b22916d4e51e7829aa4dc4398b276af}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 72b8614ff4485e4c3da80d84cfc47861 with allocation id 92fe0674fe021cd1eab0417263726901.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 92fe0674fe021cd1eab0417263726901 for job 72b8614ff4485e4c3da80d84cfc47861 from resource manager with leader id a41e7e78b2e9fb15b6a0c0694fe34517.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{87e1bcacb9b983e19c2e1fc828d718d9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{18e8dc5ca313e6a8051039c902cbfd94}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f333f68fedf7878e6420f1a016ddee88}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5a76abe0a75260881085a3cae8ec7a93}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 72b8614ff4485e4c3da80d84cfc47861 with allocation id 198b0c0101b707bc8f4d5843cd0c36bc.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f43b74688ad14d1298651d4c7e0903f5}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 72b8614ff4485e4c3da80d84cfc47861 with allocation id 9caa7defb87794200992b7a0f08c8ff7.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 92fe0674fe021cd1eab0417263726901.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 72b8614ff4485e4c3da80d84cfc47861 for job leader monitoring.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 198b0c0101b707bc8f4d5843cd0c36bc for job 72b8614ff4485e4c3da80d84cfc47861 from resource manager with leader id a41e7e78b2e9fb15b6a0c0694fe34517.
2020-01-14 20:00:30 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c1ca163d-9466-489a-817c-89fe8331f966.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 198b0c0101b707bc8f4d5843cd0c36bc.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 72b8614ff4485e4c3da80d84cfc47861 for job leader monitoring.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 9caa7defb87794200992b7a0f08c8ff7 for job 72b8614ff4485e4c3da80d84cfc47861 from resource manager with leader id a41e7e78b2e9fb15b6a0c0694fe34517.
2020-01-14 20:00:30 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c1ca163d-9466-489a-817c-89fe8331f966.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 9caa7defb87794200992b7a0f08c8ff7.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 72b8614ff4485e4c3da80d84cfc47861 for job leader monitoring.
2020-01-14 20:00:30 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c1ca163d-9466-489a-817c-89fe8331f966.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 72b8614ff4485e4c3da80d84cfc47861 with allocation id b3dfd3989d8ab13f75fd3e3ac6f5aaee.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request b3dfd3989d8ab13f75fd3e3ac6f5aaee for job 72b8614ff4485e4c3da80d84cfc47861 from resource manager with leader id a41e7e78b2e9fb15b6a0c0694fe34517.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for b3dfd3989d8ab13f75fd3e3ac6f5aaee.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 72b8614ff4485e4c3da80d84cfc47861 for job leader monitoring.
2020-01-14 20:00:30 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c1ca163d-9466-489a-817c-89fe8331f966.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 72b8614ff4485e4c3da80d84cfc47861 with allocation id 4d08e9b9aea471f81b0b55d043097373.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 4d08e9b9aea471f81b0b55d043097373 for job 72b8614ff4485e4c3da80d84cfc47861 from resource manager with leader id a41e7e78b2e9fb15b6a0c0694fe34517.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 4d08e9b9aea471f81b0b55d043097373.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 72b8614ff4485e4c3da80d84cfc47861 for job leader monitoring.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:00:30 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c1ca163d-9466-489a-817c-89fe8331f966.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 72b8614ff4485e4c3da80d84cfc47861 with allocation id dbcbeb86938a42489fec5452df3aa611.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 72b8614ff4485e4c3da80d84cfc47861.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request dbcbeb86938a42489fec5452df3aa611 for job 72b8614ff4485e4c3da80d84cfc47861 from resource manager with leader id a41e7e78b2e9fb15b6a0c0694fe34517.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for dbcbeb86938a42489fec5452df3aa611.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 72b8614ff4485e4c3da80d84cfc47861 for job leader monitoring.
2020-01-14 20:00:30 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c1ca163d-9466-489a-817c-89fe8331f966.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job 72b8614ff4485e4c3da80d84cfc47861.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 72b8614ff4485e4c3da80d84cfc47861.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 72b8614ff4485e4c3da80d84cfc47861.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to d2a11d80-c59f-459a-81ae-2ffdeb6c02bb @ localhost (dataPort=-1)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to d2a11d80-c59f-459a-81ae-2ffdeb6c02bb @ localhost (dataPort=-1)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to d2a11d80-c59f-459a-81ae-2ffdeb6c02bb @ localhost (dataPort=-1)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to d2a11d80-c59f-459a-81ae-2ffdeb6c02bb @ localhost (dataPort=-1)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to d2a11d80-c59f-459a-81ae-2ffdeb6c02bb @ localhost (dataPort=-1)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to d2a11d80-c59f-459a-81ae-2ffdeb6c02bb @ localhost (dataPort=-1)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) switched from CREATED to DEPLOYING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) [DEPLOYING]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) switched from CREATED to DEPLOYING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) [DEPLOYING]
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) [DEPLOYING].
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) switched from CREATED to DEPLOYING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) [DEPLOYING]
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) [DEPLOYING].
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) switched from CREATED to DEPLOYING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) [DEPLOYING]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4e94415dde24a63f5c0f09b2d84f1237) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) [DEPLOYING].
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (611363a3cda1b9d7e2a26a986a155554) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (85040fae69b352fedab0ae157d57649d) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (6c9045521a68ef02d1c146f10b9220b9) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 92fe0674fe021cd1eab0417263726901.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot dbcbeb86938a42489fec5452df3aa611.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 9caa7defb87794200992b7a0f08c8ff7.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) switched from CREATED to DEPLOYING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 4d08e9b9aea471f81b0b55d043097373.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot b3dfd3989d8ab13f75fd3e3ac6f5aaee.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 198b0c0101b707bc8f4d5843cd0c36bc.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) [DEPLOYING]
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) switched from CREATED to DEPLOYING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) [DEPLOYING]
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) [DEPLOYING].
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (7ca06cb56e5b6f8e47a93e66134db1c1) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (c1c1a8427e2e7ec3714636e1c458a3ad) switched from DEPLOYING to RUNNING.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:00:30 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 20:00:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 20:00:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 20:00:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 20:00:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 20:00:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:30 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 20:00:30 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-11, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:00:31 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-11, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 20:00:57 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:00:57 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:04:01 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 20:04:01 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 20:04:01 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 20:04:01 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 20:04:01 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 20:04:02 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:04:02 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 20:04:02 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:04:02 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 20:04:02 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:36749]
2020-01-14 20:04:02 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:36749
2020-01-14 20:04:02 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 20:04:02 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 20:04:02 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-ef1d550d-1172-4e97-a2e9-88b14141e192
2020-01-14 20:04:03 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:42145 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 20:04:03 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-3e4caf78-8c8b-4781-961d-06f90d17a859
2020-01-14 20:04:03 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-245446d9-51cf-4614-9293-4ca88b4c5ab6
2020-01-14 20:04:03 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 20:04:03 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: dfde0142-de9c-4456-9de4-53533dfa448e
2020-01-14 20:04:03 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 20:04:03 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-de23cadc-19ba-4161-afe3-3ca8c6b77579 for spill files.
2020-01-14 20:04:03 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-a924091b-6fea-450a-bfc6-d4cbef64617c for spill files.
2020-01-14 20:04:03 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 20:04:03 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 20:04:03 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 20:04:03 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 20:04:03 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 20:04:03 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 20:04:03 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 20:04:03 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-f69a38aa-ce42-44eb-8420-6a82979ab18c
2020-01-14 20:04:03 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 20:04:03 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 20:04:03 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 20:04:03 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 20:04:04 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:35983
2020-01-14 20:04:04 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@67f77f6e @ http://localhost:35983
2020-01-14 20:04:04 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:35983 was granted leadership with leaderSessionID=7c265f76-e2ee-4d51-95d6-7f3ea8fa16ff
2020-01-14 20:04:04 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:35983 , session=7c265f76-e2ee-4d51-95d6-7f3ea8fa16ff
2020-01-14 20:04:04 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 20:04:04 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@f02d2a6 @ akka://flink/user/resourcemanager
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 8d6d798ea70e296750403517bb2b4c17
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@6599c2a9 @ akka://flink/user/dispatcher
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=50403517-bb2b-4c17-8d6d-798ea70e2967
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token b7bbc42a-bf93-4fab-a217-5beeeaf17aea
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(8d6d798ea70e296750403517bb2b4c17).
2020-01-14 20:04:04 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=b7bbc42a-bf93-4fab-a217-5beeeaf17aea
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID dfde0142-de9c-4456-9de4-53533dfa448e (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 12a8efd31ce2030bfb57bcf0afd0673c (Flink Streaming Job).
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 12a8efd31ce2030bfb57bcf0afd0673c (Flink Streaming Job).
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id f9030991af3e04cc4e872addcf264afe.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (12a8efd31ce2030bfb57bcf0afd0673c).
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (12a8efd31ce2030bfb57bcf0afd0673c).
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (12a8efd31ce2030bfb57bcf0afd0673c).
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 2 ms.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@347fbcd4 @ akka://flink/user/jobmanager_1
2020-01-14 20:04:04 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (12a8efd31ce2030bfb57bcf0afd0673c) was granted leadership with session id 1e12f1ff-6683-487a-8601-312651bae486 at akka://flink/user/jobmanager_1.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (12a8efd31ce2030bfb57bcf0afd0673c) under job master id 8601312651bae4861e12f1ff6683487a.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (12a8efd31ce2030bfb57bcf0afd0673c) switched from state CREATED to RUNNING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) switched from CREATED to SCHEDULED.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e59c95776e867988c24a05bc664783d8}]
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) switched from CREATED to SCHEDULED.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{439718f06f0123f4d291eb6428b5ad89}]
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) switched from CREATED to SCHEDULED.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{be08eac63b1fc323111ddca8bebba202}]
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) switched from CREATED to SCHEDULED.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7b13cfcc9811b9b07df248d167cb7f41}]
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) switched from CREATED to SCHEDULED.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4b2f4afbb234d798cea410e9653fd89a}]
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) switched from CREATED to SCHEDULED.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{01e0886b48d2cf7b4f75c11fbe25cae4}]
2020-01-14 20:04:04 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=1e12f1ff-6683-487a-8601-312651bae486
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(8d6d798ea70e296750403517bb2b4c17)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 8601312651bae4861e12f1ff6683487a@akka://flink/user/jobmanager_1 for job 12a8efd31ce2030bfb57bcf0afd0673c.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 8601312651bae4861e12f1ff6683487a@akka://flink/user/jobmanager_1 for job 12a8efd31ce2030bfb57bcf0afd0673c.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 8d6d798ea70e296750403517bb2b4c17.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e59c95776e867988c24a05bc664783d8}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 12a8efd31ce2030bfb57bcf0afd0673c with allocation id 34d5a3b01882fe1ba866eb11ab9b61c9.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{439718f06f0123f4d291eb6428b5ad89}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 34d5a3b01882fe1ba866eb11ab9b61c9 for job 12a8efd31ce2030bfb57bcf0afd0673c from resource manager with leader id 8d6d798ea70e296750403517bb2b4c17.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 12a8efd31ce2030bfb57bcf0afd0673c with allocation id 66fb179045526a3164aa4b65f2ee98e2.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 34d5a3b01882fe1ba866eb11ab9b61c9.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 12a8efd31ce2030bfb57bcf0afd0673c for job leader monitoring.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{be08eac63b1fc323111ddca8bebba202}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7b13cfcc9811b9b07df248d167cb7f41}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 12a8efd31ce2030bfb57bcf0afd0673c with allocation id ccb58abb4b899e2093bd41858f9fcfc0.
2020-01-14 20:04:04 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 1e12f1ff-6683-487a-8601-312651bae486.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{4b2f4afbb234d798cea410e9653fd89a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 12a8efd31ce2030bfb57bcf0afd0673c with allocation id 2d6517626ea8bbfaebb7fb8e8ce348bf.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{01e0886b48d2cf7b4f75c11fbe25cae4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 12a8efd31ce2030bfb57bcf0afd0673c with allocation id d87550ba8c24249175197f4589265bf5.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 66fb179045526a3164aa4b65f2ee98e2 for job 12a8efd31ce2030bfb57bcf0afd0673c from resource manager with leader id 8d6d798ea70e296750403517bb2b4c17.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 66fb179045526a3164aa4b65f2ee98e2.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 12a8efd31ce2030bfb57bcf0afd0673c with allocation id 65a4c617680b3ef46abb354b4bc2744e.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 12a8efd31ce2030bfb57bcf0afd0673c for job leader monitoring.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request ccb58abb4b899e2093bd41858f9fcfc0 for job 12a8efd31ce2030bfb57bcf0afd0673c from resource manager with leader id 8d6d798ea70e296750403517bb2b4c17.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for ccb58abb4b899e2093bd41858f9fcfc0.
2020-01-14 20:04:04 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 1e12f1ff-6683-487a-8601-312651bae486.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 12a8efd31ce2030bfb57bcf0afd0673c for job leader monitoring.
2020-01-14 20:04:04 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 1e12f1ff-6683-487a-8601-312651bae486.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 2d6517626ea8bbfaebb7fb8e8ce348bf for job 12a8efd31ce2030bfb57bcf0afd0673c from resource manager with leader id 8d6d798ea70e296750403517bb2b4c17.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 2d6517626ea8bbfaebb7fb8e8ce348bf.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 12a8efd31ce2030bfb57bcf0afd0673c for job leader monitoring.
2020-01-14 20:04:04 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 1e12f1ff-6683-487a-8601-312651bae486.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d87550ba8c24249175197f4589265bf5 for job 12a8efd31ce2030bfb57bcf0afd0673c from resource manager with leader id 8d6d798ea70e296750403517bb2b4c17.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d87550ba8c24249175197f4589265bf5.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 12a8efd31ce2030bfb57bcf0afd0673c for job leader monitoring.
2020-01-14 20:04:04 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 1e12f1ff-6683-487a-8601-312651bae486.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 65a4c617680b3ef46abb354b4bc2744e for job 12a8efd31ce2030bfb57bcf0afd0673c from resource manager with leader id 8d6d798ea70e296750403517bb2b4c17.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 65a4c617680b3ef46abb354b4bc2744e.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 12a8efd31ce2030bfb57bcf0afd0673c for job leader monitoring.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:04:04 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 1e12f1ff-6683-487a-8601-312651bae486.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 12a8efd31ce2030bfb57bcf0afd0673c.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job 12a8efd31ce2030bfb57bcf0afd0673c.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 12a8efd31ce2030bfb57bcf0afd0673c.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to dfde0142-de9c-4456-9de4-53533dfa448e @ localhost (dataPort=-1)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to dfde0142-de9c-4456-9de4-53533dfa448e @ localhost (dataPort=-1)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to dfde0142-de9c-4456-9de4-53533dfa448e @ localhost (dataPort=-1)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to dfde0142-de9c-4456-9de4-53533dfa448e @ localhost (dataPort=-1)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to dfde0142-de9c-4456-9de4-53533dfa448e @ localhost (dataPort=-1)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to dfde0142-de9c-4456-9de4-53533dfa448e @ localhost (dataPort=-1)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) switched from CREATED to DEPLOYING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) [DEPLOYING]
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) switched from CREATED to DEPLOYING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) [DEPLOYING]
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) [DEPLOYING].
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) switched from CREATED to DEPLOYING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) [DEPLOYING]
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) [DEPLOYING].
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot ccb58abb4b899e2093bd41858f9fcfc0.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 2d6517626ea8bbfaebb7fb8e8ce348bf.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 65a4c617680b3ef46abb354b4bc2744e.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 34d5a3b01882fe1ba866eb11ab9b61c9.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 66fb179045526a3164aa4b65f2ee98e2.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (cec5a5eb201def4192b969aa74c4843e) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot d87550ba8c24249175197f4589265bf5.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (3ff0d9264421a6a83bf6df60068a04d1) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) switched from CREATED to DEPLOYING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (25c4a5dbd2eed94ce0709c55bcfe4e1c) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) [DEPLOYING]
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (a4733c1c029601e83a1904c18c157fe1) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) switched from CREATED to DEPLOYING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) switched from CREATED to DEPLOYING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) [DEPLOYING]
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) [DEPLOYING]
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) [DEPLOYING].
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (9260a1f4ef81ab8fc20d7a170385a45b) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:04:04 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (25621be77a4f4f9b884baa7611648ad3) switched from DEPLOYING to RUNNING.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:04:04 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 20:04:04 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 20:04:04 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 20:04:04 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 20:04:04 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 20:04:04 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 20:04:04 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-10, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:04:04 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-10, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 20:04:26 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:04:26 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 20:04:26 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-c92f6834-812c-4172-9701-452559178a3d
2020-01-14 20:04:26 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:43967
2020-01-14 20:04:26 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:04:27 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:04:27 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 20:04:27 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:04:27 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:34067
2020-01-14 20:04:27 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-e94efc3b-a102-4db2-930a-e383afce07bf
2020-01-14 20:05:51 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 20:05:52 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 20:05:52 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 20:05:52 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 20:05:52 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 20:05:52 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:05:52 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 20:05:52 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:05:52 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 20:05:52 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:46233]
2020-01-14 20:05:53 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:46233
2020-01-14 20:05:53 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 20:05:53 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 20:05:53 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-3987a95c-0b6a-492f-91e8-9f7ef6379a3c
2020-01-14 20:05:53 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:42743 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 20:05:53 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-03d718e2-17d3-4cf3-bfe3-9488c76aada2
2020-01-14 20:05:53 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-f27286f3-2a71-4371-b2cd-9d804658bfdf
2020-01-14 20:05:53 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 20:05:53 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 894fb786-0bb5-4b0d-b82d-9316fc3bbef6
2020-01-14 20:05:53 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 20:05:53 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-b074d29b-fe56-4a04-8e29-bbd92b681d63 for spill files.
2020-01-14 20:05:53 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-ac7dd1b6-7e31-49d2-9daa-bea991b4b681 for spill files.
2020-01-14 20:05:53 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 20:05:53 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 20:05:53 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 20:05:53 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 20:05:53 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 20:05:53 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-885a189d-f855-45fc-adf5-ff3c0486c3fd
2020-01-14 20:05:53 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 20:05:53 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 20:05:53 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 20:05:53 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 20:05:53 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:36539
2020-01-14 20:05:53 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@67f77f6e @ http://localhost:36539
2020-01-14 20:05:53 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:36539 was granted leadership with leaderSessionID=8e820be6-6669-4d4b-b10b-4f66a85417d1
2020-01-14 20:05:53 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:36539 , session=8e820be6-6669-4d4b-b10b-4f66a85417d1
2020-01-14 20:05:53 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 20:05:53 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@3f6d01f @ akka://flink/user/resourcemanager
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@100d31d @ akka://flink/user/dispatcher
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9c383d357b4167549784004d7de14b67
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token cdc74e97-0a4b-41d1-836a-c5e934994023
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=cdc74e97-0a4b-41d1-836a-c5e934994023
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=9784004d-7de1-4b67-9c38-3d357b416754
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(9c383d357b4167549784004d7de14b67).
2020-01-14 20:05:53 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 894fb786-0bb5-4b0d-b82d-9316fc3bbef6 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 20:05:53 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 3babcb009b92c64fa7f4f115a444bc6c.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 0c91d3fd51c5a21051bb57fd41f2d98b (Flink Streaming Job).
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 0c91d3fd51c5a21051bb57fd41f2d98b (Flink Streaming Job).
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:241 - Initializing job Flink Streaming Job (0c91d3fd51c5a21051bb57fd41f2d98b).
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (0c91d3fd51c5a21051bb57fd41f2d98b).
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (0c91d3fd51c5a21051bb57fd41f2d98b).
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:222 - Successfully ran initialization on master in 1 ms.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@64f1cf83 @ akka://flink/user/jobmanager_1
2020-01-14 20:05:54 [mini-cluster-io-thread-2] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (0c91d3fd51c5a21051bb57fd41f2d98b) was granted leadership with session id 5cf5ac99-8804-4034-a051-b8a062c4e141 at akka://flink/user/jobmanager_1.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (0c91d3fd51c5a21051bb57fd41f2d98b) under job master id a051b8a062c4e1415cf5ac9988044034.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (0c91d3fd51c5a21051bb57fd41f2d98b) switched from state CREATED to RUNNING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) switched from CREATED to SCHEDULED.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{30a14b16089223ad79e1cd3b44501edb}]
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) switched from CREATED to SCHEDULED.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{380c5508a22b302fef27dfbde7b5bf30}]
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) switched from CREATED to SCHEDULED.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c4f3e6177ce5217298994fc28384b5df}]
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) switched from CREATED to SCHEDULED.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{49e68de3e46c29703af3d9e9840fc113}]
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) switched from CREATED to SCHEDULED.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2fecfa2e4f03ada99fd0aeec216909f2}]
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) switched from CREATED to SCHEDULED.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{0a14901a0f53d4810ffa4bc306b6b755}]
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(9c383d357b4167549784004d7de14b67)
2020-01-14 20:05:54 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=5cf5ac99-8804-4034-a051-b8a062c4e141
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager a051b8a062c4e1415cf5ac9988044034@akka://flink/user/jobmanager_1 for job 0c91d3fd51c5a21051bb57fd41f2d98b.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager a051b8a062c4e1415cf5ac9988044034@akka://flink/user/jobmanager_1 for job 0c91d3fd51c5a21051bb57fd41f2d98b.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 9c383d357b4167549784004d7de14b67.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{30a14b16089223ad79e1cd3b44501edb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0c91d3fd51c5a21051bb57fd41f2d98b with allocation id bfefd0ae444e4a8c9d4ecb4fa9f5afed.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{380c5508a22b302fef27dfbde7b5bf30}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c4f3e6177ce5217298994fc28384b5df}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request bfefd0ae444e4a8c9d4ecb4fa9f5afed for job 0c91d3fd51c5a21051bb57fd41f2d98b from resource manager with leader id 9c383d357b4167549784004d7de14b67.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0c91d3fd51c5a21051bb57fd41f2d98b with allocation id 382483c46bbc53dc671e9a1849bbc3c9.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0c91d3fd51c5a21051bb57fd41f2d98b with allocation id 79a33bd9e45199d156c315da2f96e1f0.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{49e68de3e46c29703af3d9e9840fc113}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{2fecfa2e4f03ada99fd0aeec216909f2}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0c91d3fd51c5a21051bb57fd41f2d98b with allocation id 6f030cd1f638866501cba5a16d43c2d6.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0c91d3fd51c5a21051bb57fd41f2d98b with allocation id f5091a05af2cbcf84adee4ece905b2c6.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{0a14901a0f53d4810ffa4bc306b6b755}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0c91d3fd51c5a21051bb57fd41f2d98b with allocation id 4063a9d3bc5b01878bb8ccd6bd046e3a.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for bfefd0ae444e4a8c9d4ecb4fa9f5afed.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 0c91d3fd51c5a21051bb57fd41f2d98b for job leader monitoring.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 382483c46bbc53dc671e9a1849bbc3c9 for job 0c91d3fd51c5a21051bb57fd41f2d98b from resource manager with leader id 9c383d357b4167549784004d7de14b67.
2020-01-14 20:05:54 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5cf5ac99-8804-4034-a051-b8a062c4e141.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 382483c46bbc53dc671e9a1849bbc3c9.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 0c91d3fd51c5a21051bb57fd41f2d98b for job leader monitoring.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 79a33bd9e45199d156c315da2f96e1f0 for job 0c91d3fd51c5a21051bb57fd41f2d98b from resource manager with leader id 9c383d357b4167549784004d7de14b67.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 79a33bd9e45199d156c315da2f96e1f0.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 0c91d3fd51c5a21051bb57fd41f2d98b for job leader monitoring.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 6f030cd1f638866501cba5a16d43c2d6 for job 0c91d3fd51c5a21051bb57fd41f2d98b from resource manager with leader id 9c383d357b4167549784004d7de14b67.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 6f030cd1f638866501cba5a16d43c2d6.
2020-01-14 20:05:54 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5cf5ac99-8804-4034-a051-b8a062c4e141.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 0c91d3fd51c5a21051bb57fd41f2d98b for job leader monitoring.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request f5091a05af2cbcf84adee4ece905b2c6 for job 0c91d3fd51c5a21051bb57fd41f2d98b from resource manager with leader id 9c383d357b4167549784004d7de14b67.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for f5091a05af2cbcf84adee4ece905b2c6.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 0c91d3fd51c5a21051bb57fd41f2d98b for job leader monitoring.
2020-01-14 20:05:54 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5cf5ac99-8804-4034-a051-b8a062c4e141.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 4063a9d3bc5b01878bb8ccd6bd046e3a for job 0c91d3fd51c5a21051bb57fd41f2d98b from resource manager with leader id 9c383d357b4167549784004d7de14b67.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 4063a9d3bc5b01878bb8ccd6bd046e3a.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 0c91d3fd51c5a21051bb57fd41f2d98b for job leader monitoring.
2020-01-14 20:05:54 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5cf5ac99-8804-4034-a051-b8a062c4e141.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 0c91d3fd51c5a21051bb57fd41f2d98b.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job 0c91d3fd51c5a21051bb57fd41f2d98b.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0c91d3fd51c5a21051bb57fd41f2d98b.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 894fb786-0bb5-4b0d-b82d-9316fc3bbef6 @ localhost (dataPort=-1)
2020-01-14 20:05:54 [mini-cluster-io-thread-5] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 894fb786-0bb5-4b0d-b82d-9316fc3bbef6 @ localhost (dataPort=-1)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 894fb786-0bb5-4b0d-b82d-9316fc3bbef6 @ localhost (dataPort=-1)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 894fb786-0bb5-4b0d-b82d-9316fc3bbef6 @ localhost (dataPort=-1)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 894fb786-0bb5-4b0d-b82d-9316fc3bbef6 @ localhost (dataPort=-1)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 894fb786-0bb5-4b0d-b82d-9316fc3bbef6 @ localhost (dataPort=-1)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) switched from CREATED to DEPLOYING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) [DEPLOYING]
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) [DEPLOYING].
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) [DEPLOYING].
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) switched from CREATED to DEPLOYING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) [DEPLOYING]
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) [DEPLOYING].
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) switched from CREATED to DEPLOYING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) [DEPLOYING]
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (587ca7ad283cd4976ff2edcd5489044c) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (3cafe08376a4cb421284db574dcfc5c4) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (f42cbc8bf69246a654db38219e3cb8b4) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 6f030cd1f638866501cba5a16d43c2d6.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot f5091a05af2cbcf84adee4ece905b2c6.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot bfefd0ae444e4a8c9d4ecb4fa9f5afed.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 382483c46bbc53dc671e9a1849bbc3c9.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 4063a9d3bc5b01878bb8ccd6bd046e3a.
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 79a33bd9e45199d156c315da2f96e1f0.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) switched from CREATED to DEPLOYING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) switched from CREATED to DEPLOYING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) [DEPLOYING]
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) [DEPLOYING]
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (5cd6cfae5eabb55dea47f3c0ecd0d630) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (6b2a8dd4f0102189afb4f966ac9f85ba) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) switched from CREATED to DEPLOYING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) [DEPLOYING]
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) [DEPLOYING].
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:54 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:05:54 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (dbbe5de2a760dd2dbe79f7b7e96c06fa) switched from DEPLOYING to RUNNING.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:05:55 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 20:05:55 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 20:05:55 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 20:05:55 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 20:05:55 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 20:05:55 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:05:55 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 20:06:19 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-885a189d-f855-45fc-adf5-ff3c0486c3fd
2020-01-14 20:06:19 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:06:19 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:16:04 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 20:16:04 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 20:16:04 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 20:16:04 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 20:16:04 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 20:16:05 [flink-akka.actor.default-dispatcher-4] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:16:05 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 20:16:05 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 20:16:05 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 20:16:05 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:40143]
2020-01-14 20:16:05 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:40143
2020-01-14 20:16:05 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 20:16:05 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 20:16:05 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-df041faf-1bdb-42e4-98fc-dcfb59914580
2020-01-14 20:16:05 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:40131 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 20:16:05 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-a6f10f20-f5bf-4659-b979-5c125b291319
2020-01-14 20:16:05 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-cc933b55-5f76-43ce-9427-0557b0d07452
2020-01-14 20:16:05 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 20:16:05 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 76ac451e-21e5-4ff1-9623-db83e94f31ca
2020-01-14 20:16:05 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 20:16:05 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-a24babe7-8efd-432f-a885-f31a25947b09 for spill files.
2020-01-14 20:16:05 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-7e85ba25-53d3-456b-a1ff-df5c5031dc80 for spill files.
2020-01-14 20:16:05 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 20:16:05 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 20:16:05 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 20:16:05 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 20:16:05 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 20:16:05 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-0aed929b-6ae8-4733-af9e-804818fa9c0e
2020-01-14 20:16:06 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 20:16:06 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 20:16:06 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 20:16:06 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 20:16:06 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:33761
2020-01-14 20:16:06 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@30c4e352 @ http://localhost:33761
2020-01-14 20:16:06 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:33761 was granted leadership with leaderSessionID=a9090022-9336-4800-a06b-17cec99bd8a0
2020-01-14 20:16:06 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:33761 , session=a9090022-9336-4800-a06b-17cec99bd8a0
2020-01-14 20:16:06 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 20:16:06 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@64b52b5 @ akka://flink/user/resourcemanager
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@3d114cd0 @ akka://flink/user/dispatcher
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 8933e82802962aac9e0b49395e954f4a
2020-01-14 20:16:06 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 84147de9-e6e4-4b25-adce-7bb8a759a8d4
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=9e0b4939-5e95-4f4a-8933-e82802962aac
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(8933e82802962aac9e0b49395e954f4a).
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=84147de9-e6e4-4b25-adce-7bb8a759a8d4
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 76ac451e-21e5-4ff1-9623-db83e94f31ca (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 82815cdb9300656a6049c9752636c29b (Flink Streaming Job).
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 82815cdb9300656a6049c9752636c29b (Flink Streaming Job).
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id eb092d7cdca54f6968f9df6e9f8ac1e0.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (82815cdb9300656a6049c9752636c29b).
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (82815cdb9300656a6049c9752636c29b).
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (82815cdb9300656a6049c9752636c29b).
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@7b5643fe @ akka://flink/user/jobmanager_1
2020-01-14 20:16:06 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (82815cdb9300656a6049c9752636c29b) was granted leadership with session id 95460a99-e01e-43f9-8acc-f502d734057a at akka://flink/user/jobmanager_1.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (82815cdb9300656a6049c9752636c29b) under job master id 8accf502d734057a95460a99e01e43f9.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (82815cdb9300656a6049c9752636c29b) switched from state CREATED to RUNNING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) switched from CREATED to SCHEDULED.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{0ea530b8854590d09730bc3d213a1805}]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) switched from CREATED to SCHEDULED.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{368d5400e3a41206aaf2a254482f21c0}]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) switched from CREATED to SCHEDULED.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6789d198a2863e19037941a55eb69b65}]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) switched from CREATED to SCHEDULED.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{838646c6dfa49de374e96a9acb3ba8e7}]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) switched from CREATED to SCHEDULED.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a4bac409e24a85d8409b4d5fd7caec96}]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) switched from CREATED to SCHEDULED.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{db7b7b433bcec6be4c96a1eb30fa5c36}]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(8933e82802962aac9e0b49395e954f4a)
2020-01-14 20:16:06 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=95460a99-e01e-43f9-8acc-f502d734057a
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 8accf502d734057a95460a99e01e43f9@akka://flink/user/jobmanager_1 for job 82815cdb9300656a6049c9752636c29b.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 8accf502d734057a95460a99e01e43f9@akka://flink/user/jobmanager_1 for job 82815cdb9300656a6049c9752636c29b.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 8933e82802962aac9e0b49395e954f4a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{0ea530b8854590d09730bc3d213a1805}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 82815cdb9300656a6049c9752636c29b with allocation id 6bf566707c78593fdf0087b96c36ae63.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{368d5400e3a41206aaf2a254482f21c0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{6789d198a2863e19037941a55eb69b65}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 82815cdb9300656a6049c9752636c29b with allocation id fa1cd61ed76641b10580124d4b8fcb61.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{838646c6dfa49de374e96a9acb3ba8e7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 6bf566707c78593fdf0087b96c36ae63 for job 82815cdb9300656a6049c9752636c29b from resource manager with leader id 8933e82802962aac9e0b49395e954f4a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a4bac409e24a85d8409b4d5fd7caec96}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 82815cdb9300656a6049c9752636c29b with allocation id 64554fbd7180b6b4c7f054b9f431ab65.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{db7b7b433bcec6be4c96a1eb30fa5c36}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 82815cdb9300656a6049c9752636c29b with allocation id 681bc264d17f8c635993f5be25aaee87.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 6bf566707c78593fdf0087b96c36ae63.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 82815cdb9300656a6049c9752636c29b for job leader monitoring.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 82815cdb9300656a6049c9752636c29b with allocation id 757380c798cefb57640853378dec2720.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 82815cdb9300656a6049c9752636c29b with allocation id 6bd43c5281b5e6f04e30ebe9f539fa33.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request fa1cd61ed76641b10580124d4b8fcb61 for job 82815cdb9300656a6049c9752636c29b from resource manager with leader id 8933e82802962aac9e0b49395e954f4a.
2020-01-14 20:16:06 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 95460a99-e01e-43f9-8acc-f502d734057a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for fa1cd61ed76641b10580124d4b8fcb61.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 82815cdb9300656a6049c9752636c29b for job leader monitoring.
2020-01-14 20:16:06 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 95460a99-e01e-43f9-8acc-f502d734057a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 64554fbd7180b6b4c7f054b9f431ab65 for job 82815cdb9300656a6049c9752636c29b from resource manager with leader id 8933e82802962aac9e0b49395e954f4a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 64554fbd7180b6b4c7f054b9f431ab65.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 82815cdb9300656a6049c9752636c29b for job leader monitoring.
2020-01-14 20:16:06 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 95460a99-e01e-43f9-8acc-f502d734057a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 681bc264d17f8c635993f5be25aaee87 for job 82815cdb9300656a6049c9752636c29b from resource manager with leader id 8933e82802962aac9e0b49395e954f4a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 681bc264d17f8c635993f5be25aaee87.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 82815cdb9300656a6049c9752636c29b for job leader monitoring.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:16:06 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 95460a99-e01e-43f9-8acc-f502d734057a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 757380c798cefb57640853378dec2720 for job 82815cdb9300656a6049c9752636c29b from resource manager with leader id 8933e82802962aac9e0b49395e954f4a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 757380c798cefb57640853378dec2720.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 82815cdb9300656a6049c9752636c29b for job leader monitoring.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:16:06 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 95460a99-e01e-43f9-8acc-f502d734057a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 6bd43c5281b5e6f04e30ebe9f539fa33 for job 82815cdb9300656a6049c9752636c29b from resource manager with leader id 8933e82802962aac9e0b49395e954f4a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 6bd43c5281b5e6f04e30ebe9f539fa33.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 82815cdb9300656a6049c9752636c29b for job leader monitoring.
2020-01-14 20:16:06 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 95460a99-e01e-43f9-8acc-f502d734057a.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 82815cdb9300656a6049c9752636c29b.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job 82815cdb9300656a6049c9752636c29b.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 82815cdb9300656a6049c9752636c29b.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 76ac451e-21e5-4ff1-9623-db83e94f31ca @ localhost (dataPort=-1)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 76ac451e-21e5-4ff1-9623-db83e94f31ca @ localhost (dataPort=-1)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 76ac451e-21e5-4ff1-9623-db83e94f31ca @ localhost (dataPort=-1)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 76ac451e-21e5-4ff1-9623-db83e94f31ca @ localhost (dataPort=-1)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 76ac451e-21e5-4ff1-9623-db83e94f31ca @ localhost (dataPort=-1)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) switched from SCHEDULED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 76ac451e-21e5-4ff1-9623-db83e94f31ca @ localhost (dataPort=-1)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6).
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) switched from CREATED to DEPLOYING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) [DEPLOYING]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6).
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) switched from CREATED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6).
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) [DEPLOYING]
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6).
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) [DEPLOYING].
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6) (55433cfdc7e11a13dd1d71e71a3b39a1) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6) (4b5a68bd370ad7ea9353784b201b9262) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) switched from CREATED to DEPLOYING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) [DEPLOYING]
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) switched from CREATED to DEPLOYING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) [DEPLOYING]
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6).
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6) (fd5ac54e64a949c39ac8de84386cc048) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6) (a6c189c669d72a155456535bfba77c70) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) switched from CREATED to DEPLOYING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) [DEPLOYING]
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) [DEPLOYING].
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) [DEPLOYING].
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6).
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6) (0f6dabc278e8d3bb946f0ce93f21fcc1) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) switched from CREATED to DEPLOYING.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 6bd43c5281b5e6f04e30ebe9f539fa33.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) [DEPLOYING]
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 64554fbd7180b6b4c7f054b9f431ab65.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) [DEPLOYING].
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 681bc264d17f8c635993f5be25aaee87.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 6bf566707c78593fdf0087b96c36ae63.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) [DEPLOYING].
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot fa1cd61ed76641b10580124d4b8fcb61.
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 757380c798cefb57640853378dec2720.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 20:16:06 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6) (75da0de6d154e0b2cedabd3a522ee983) switched from DEPLOYING to RUNNING.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:16:06 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:16:07 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 20:16:07 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 20:16:07 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 20:16:07 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 20:16:07 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 20:16:07 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-10, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 20:16:07 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-10, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 20:26:02 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 20:26:02 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 20:26:02 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:40131
2020-01-14 20:26:02 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-0aed929b-6ae8-4733-af9e-804818fa9c0e
2020-01-14 20:26:02 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 22:31:19 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 22:31:19 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 22:31:19 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 22:31:19 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 22:31:19 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 22:31:20 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 22:31:20 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 22:31:20 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 22:31:20 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 22:31:20 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:41181]
2020-01-14 22:31:20 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:41181
2020-01-14 22:31:20 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 22:31:20 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 22:31:20 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-724e7e42-5d6e-4509-bad0-b215c5366d7f
2020-01-14 22:31:20 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:36155 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 22:31:20 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-881a3afe-9278-4bde-b060-08c8fce09ad0
2020-01-14 22:31:20 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-f26e7b15-6830-4154-b2ce-7fddaba2f1e6
2020-01-14 22:31:20 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 22:31:20 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: e91a1b08-fd96-42c3-b04b-f4f3b81aac87
2020-01-14 22:31:20 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 22:31:20 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-9f569c27-d801-4378-b991-d84a71b352ff for spill files.
2020-01-14 22:31:20 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-2519e8d6-83d9-4d17-9ab6-bba6f160fc69 for spill files.
2020-01-14 22:31:21 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 22:31:21 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 22:31:21 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 22:31:21 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 22:31:21 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 22:31:21 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 22:31:21 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 22:31:21 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-4d87b813-fd47-40ae-ab5b-59be885634a5
2020-01-14 22:31:21 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 22:31:21 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 22:31:21 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 22:31:21 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 22:31:21 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:41505
2020-01-14 22:31:21 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@732f6050 @ http://localhost:41505
2020-01-14 22:31:21 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:41505 was granted leadership with leaderSessionID=8a1b9857-d67d-49cd-b738-7c8daa318d8e
2020-01-14 22:31:21 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:41505 , session=8a1b9857-d67d-49cd-b738-7c8daa318d8e
2020-01-14 22:31:21 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 22:31:21 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 22:31:21 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@7940e2e2 @ akka://flink/user/resourcemanager
2020-01-14 22:31:21 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@59619e4b @ akka://flink/user/dispatcher
2020-01-14 22:31:21 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token bf0b75843eeb269c9434c81ba82a41e1
2020-01-14 22:31:21 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 22:31:21 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=9434c81b-a82a-41e1-bf0b-75843eeb269c
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token dd3c1e0e-1088-499a-834b-c54d29727e27
2020-01-14 22:31:22 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(bf0b75843eeb269c9434c81ba82a41e1).
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=dd3c1e0e-1088-499a-834b-c54d29727e27
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 3c684e0f28c4917c420f5e250259e0ba (Flink Streaming Job).
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 3c684e0f28c4917c420f5e250259e0ba (Flink Streaming Job).
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID e91a1b08-fd96-42c3-b04b-f4f3b81aac87 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 858ab180139abd72219b5060b3d7a5c1.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (3c684e0f28c4917c420f5e250259e0ba).
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (3c684e0f28c4917c420f5e250259e0ba).
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (3c684e0f28c4917c420f5e250259e0ba).
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@30b3a42a @ akka://flink/user/jobmanager_1
2020-01-14 22:31:22 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (3c684e0f28c4917c420f5e250259e0ba) was granted leadership with session id 2cecfbf6-ebb1-47ee-b862-716b78e3bc82 at akka://flink/user/jobmanager_1.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (3c684e0f28c4917c420f5e250259e0ba) under job master id b862716b78e3bc822cecfbf6ebb147ee.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (3c684e0f28c4917c420f5e250259e0ba) switched from state CREATED to RUNNING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) switched from CREATED to SCHEDULED.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{eb0e80b108ce210145f7c0a5ec8374bf}]
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) switched from CREATED to SCHEDULED.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{507ed42e6fb73dc25d997832f7464492}]
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) switched from CREATED to SCHEDULED.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{62c019dd624d26902b8a41846e40a294}]
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) switched from CREATED to SCHEDULED.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7621a24b100644fd5a0a0cf19284070b}]
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) switched from CREATED to SCHEDULED.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{11a662b26db46191c6ee440753699089}]
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) switched from CREATED to SCHEDULED.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3349da3a881e265b5b58271c93220764}]
2020-01-14 22:31:22 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=2cecfbf6-ebb1-47ee-b862-716b78e3bc82
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(bf0b75843eeb269c9434c81ba82a41e1)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager b862716b78e3bc822cecfbf6ebb147ee@akka://flink/user/jobmanager_1 for job 3c684e0f28c4917c420f5e250259e0ba.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager b862716b78e3bc822cecfbf6ebb147ee@akka://flink/user/jobmanager_1 for job 3c684e0f28c4917c420f5e250259e0ba.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: bf0b75843eeb269c9434c81ba82a41e1.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{eb0e80b108ce210145f7c0a5ec8374bf}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{507ed42e6fb73dc25d997832f7464492}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3c684e0f28c4917c420f5e250259e0ba with allocation id a02e4bc0685d29f5ca24391181cf94f0.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{62c019dd624d26902b8a41846e40a294}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7621a24b100644fd5a0a0cf19284070b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{11a662b26db46191c6ee440753699089}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request a02e4bc0685d29f5ca24391181cf94f0 for job 3c684e0f28c4917c420f5e250259e0ba from resource manager with leader id bf0b75843eeb269c9434c81ba82a41e1.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{3349da3a881e265b5b58271c93220764}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3c684e0f28c4917c420f5e250259e0ba with allocation id a090b2793c12dbb81bcb7839a8ae4559.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3c684e0f28c4917c420f5e250259e0ba with allocation id 9bd6ceaa9a3c55b7e45d52868fb57d45.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3c684e0f28c4917c420f5e250259e0ba with allocation id bf6543dc224b579af5f3995bcb82fafd.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3c684e0f28c4917c420f5e250259e0ba with allocation id 0fbc372368374b632777ef2a6246cd7c.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3c684e0f28c4917c420f5e250259e0ba with allocation id 98fb4efce3f9aab36245fd6dab3d8555.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for a02e4bc0685d29f5ca24391181cf94f0.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 3c684e0f28c4917c420f5e250259e0ba for job leader monitoring.
2020-01-14 22:31:22 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2cecfbf6-ebb1-47ee-b862-716b78e3bc82.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request a090b2793c12dbb81bcb7839a8ae4559 for job 3c684e0f28c4917c420f5e250259e0ba from resource manager with leader id bf0b75843eeb269c9434c81ba82a41e1.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for a090b2793c12dbb81bcb7839a8ae4559.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 3c684e0f28c4917c420f5e250259e0ba for job leader monitoring.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 9bd6ceaa9a3c55b7e45d52868fb57d45 for job 3c684e0f28c4917c420f5e250259e0ba from resource manager with leader id bf0b75843eeb269c9434c81ba82a41e1.
2020-01-14 22:31:22 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2cecfbf6-ebb1-47ee-b862-716b78e3bc82.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 9bd6ceaa9a3c55b7e45d52868fb57d45.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 3c684e0f28c4917c420f5e250259e0ba for job leader monitoring.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request bf6543dc224b579af5f3995bcb82fafd for job 3c684e0f28c4917c420f5e250259e0ba from resource manager with leader id bf0b75843eeb269c9434c81ba82a41e1.
2020-01-14 22:31:22 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2cecfbf6-ebb1-47ee-b862-716b78e3bc82.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for bf6543dc224b579af5f3995bcb82fafd.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 3c684e0f28c4917c420f5e250259e0ba for job leader monitoring.
2020-01-14 22:31:22 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2cecfbf6-ebb1-47ee-b862-716b78e3bc82.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 0fbc372368374b632777ef2a6246cd7c for job 3c684e0f28c4917c420f5e250259e0ba from resource manager with leader id bf0b75843eeb269c9434c81ba82a41e1.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 0fbc372368374b632777ef2a6246cd7c.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 3c684e0f28c4917c420f5e250259e0ba for job leader monitoring.
2020-01-14 22:31:22 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2cecfbf6-ebb1-47ee-b862-716b78e3bc82.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 98fb4efce3f9aab36245fd6dab3d8555 for job 3c684e0f28c4917c420f5e250259e0ba from resource manager with leader id bf0b75843eeb269c9434c81ba82a41e1.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 98fb4efce3f9aab36245fd6dab3d8555.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 3c684e0f28c4917c420f5e250259e0ba for job leader monitoring.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:31:22 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2cecfbf6-ebb1-47ee-b862-716b78e3bc82.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 3c684e0f28c4917c420f5e250259e0ba.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 3c684e0f28c4917c420f5e250259e0ba.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 3c684e0f28c4917c420f5e250259e0ba.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to e91a1b08-fd96-42c3-b04b-f4f3b81aac87 @ localhost (dataPort=-1)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to e91a1b08-fd96-42c3-b04b-f4f3b81aac87 @ localhost (dataPort=-1)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to e91a1b08-fd96-42c3-b04b-f4f3b81aac87 @ localhost (dataPort=-1)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to e91a1b08-fd96-42c3-b04b-f4f3b81aac87 @ localhost (dataPort=-1)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to e91a1b08-fd96-42c3-b04b-f4f3b81aac87 @ localhost (dataPort=-1)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to e91a1b08-fd96-42c3-b04b-f4f3b81aac87 @ localhost (dataPort=-1)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) switched from CREATED to DEPLOYING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) [DEPLOYING]
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) switched from CREATED to DEPLOYING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) [DEPLOYING]
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) [DEPLOYING].
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) switched from CREATED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) [DEPLOYING]
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (d8aba5b96da8801cf9ed8e22af23ab2c) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) switched from CREATED to DEPLOYING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (d448c4f7d56ee8b4a46e6e918f496772) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) [DEPLOYING]
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) [DEPLOYING].
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (612b9bad9220a9e76a4cb30bfb01a91d) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (c1501a33e437e4caef70e312f6e846f0) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) switched from CREATED to DEPLOYING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) [DEPLOYING]
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (4edc6d933198d169caed575d2f1a3600) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot a02e4bc0685d29f5ca24391181cf94f0.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 9bd6ceaa9a3c55b7e45d52868fb57d45.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) switched from CREATED to DEPLOYING.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 0fbc372368374b632777ef2a6246cd7c.
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 98fb4efce3f9aab36245fd6dab3d8555.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) [DEPLOYING]
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot a090b2793c12dbb81bcb7839a8ae4559.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) [DEPLOYING].
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot bf6543dc224b579af5f3995bcb82fafd.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) [DEPLOYING].
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:31:22 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (3e81915ad3244e0bc5cc51c58b6af49a) switched from DEPLOYING to RUNNING.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:22 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:31:23 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 22:31:23 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 22:31:23 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 22:31:23 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 22:31:23 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:23 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 22:31:23 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-10, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:31:23 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-10, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 22:32:06 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 22:32:06 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 22:32:06 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 22:32:06 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-4d87b813-fd47-40ae-ab5b-59be885634a5
2020-01-14 22:32:40 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-14 22:32:40 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-14 22:32:40 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-14 22:32:40 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-14 22:32:40 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-14 22:32:41 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 22:32:41 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-14 22:32:41 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-14 22:32:41 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-14 22:32:41 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:35775]
2020-01-14 22:32:41 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:35775
2020-01-14 22:32:41 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-14 22:32:41 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-14 22:32:41 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-4df09208-f4f6-40e2-92d2-a4b9511ddfd1
2020-01-14 22:32:41 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:34911 - max concurrent requests: 50 - max backlog: 1000
2020-01-14 22:32:41 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-1021f1cf-0183-4899-ac3e-1618c4149015
2020-01-14 22:32:41 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-44794460-e5df-4b38-b6de-2c5bb2ea9e04
2020-01-14 22:32:41 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-14 22:32:41 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02
2020-01-14 22:32:41 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-14 22:32:41 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-e3f59bfa-0877-45b9-b6f8-136ad68f218b for spill files.
2020-01-14 22:32:41 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-5661a09b-d057-48ce-9a47-e989177e9f21 for spill files.
2020-01-14 22:32:41 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-14 22:32:41 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-14 22:32:41 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-14 22:32:41 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-14 22:32:41 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-14 22:32:41 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-14 22:32:41 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-14 22:32:41 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-16bcb24b-4517-4f19-bd43-8f1d290b7cdb
2020-01-14 22:32:41 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-14 22:32:42 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-14 22:32:42 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-14 22:32:42 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-14 22:32:42 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:35619
2020-01-14 22:32:42 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@ba17be6 @ http://localhost:35619
2020-01-14 22:32:42 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:35619 was granted leadership with leaderSessionID=1fb7c932-7a2a-4636-8240-2e1a1701aba1
2020-01-14 22:32:42 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:35619 , session=1fb7c932-7a2a-4636-8240-2e1a1701aba1
2020-01-14 22:32:42 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-14 22:32:42 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@3689ba0c @ akka://flink/user/resourcemanager
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@62dbdb85 @ akka://flink/user/dispatcher
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 4a90f05a-9776-46af-8c92-b880a504bb5c
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token ba14a948fd717250db0b2b8141da4768
2020-01-14 22:32:42 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=4a90f05a-9776-46af-8c92-b880a504bb5c
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=db0b2b81-41da-4768-ba14-a948fd717250
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(ba14a948fd717250db0b2b8141da4768).
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission b97a4fdaa850f2dbd9ac649050a27864 (Flink Streaming Job).
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job b97a4fdaa850f2dbd9ac649050a27864 (Flink Streaming Job).
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id fd188683a11df7fc79f3a2ff74a19dea.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (b97a4fdaa850f2dbd9ac649050a27864).
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (b97a4fdaa850f2dbd9ac649050a27864).
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (b97a4fdaa850f2dbd9ac649050a27864).
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@655c17a @ akka://flink/user/jobmanager_1
2020-01-14 22:32:42 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (b97a4fdaa850f2dbd9ac649050a27864) was granted leadership with session id 40a28701-c839-41bd-ad58-76c5871773e6 at akka://flink/user/jobmanager_1.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (b97a4fdaa850f2dbd9ac649050a27864) under job master id ad5876c5871773e640a28701c83941bd.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (b97a4fdaa850f2dbd9ac649050a27864) switched from state CREATED to RUNNING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) switched from CREATED to SCHEDULED.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{30366e2832293e80b8d2d14ae33dc407}]
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) switched from CREATED to SCHEDULED.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{699ce8b939509a532355606e1fc6524c}]
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) switched from CREATED to SCHEDULED.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{96ee125ead7bca4d4035e2468fc0da7a}]
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) switched from CREATED to SCHEDULED.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b0bc22fd03a42a1b9e1cad22a8bf4a95}]
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) switched from CREATED to SCHEDULED.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{0bf6d100115b5ef195144fb44be0d7f6}]
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) switched from CREATED to SCHEDULED.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1e0fbee8afc9c41eaa41f777faeaa346}]
2020-01-14 22:32:42 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=40a28701-c839-41bd-ad58-76c5871773e6
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(ba14a948fd717250db0b2b8141da4768)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager ad5876c5871773e640a28701c83941bd@akka://flink/user/jobmanager_1 for job b97a4fdaa850f2dbd9ac649050a27864.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager ad5876c5871773e640a28701c83941bd@akka://flink/user/jobmanager_1 for job b97a4fdaa850f2dbd9ac649050a27864.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: ba14a948fd717250db0b2b8141da4768.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{30366e2832293e80b8d2d14ae33dc407}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{699ce8b939509a532355606e1fc6524c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{96ee125ead7bca4d4035e2468fc0da7a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b0bc22fd03a42a1b9e1cad22a8bf4a95}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{0bf6d100115b5ef195144fb44be0d7f6}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b97a4fdaa850f2dbd9ac649050a27864 with allocation id c99968673cbe538c684d33b526dd2dc2.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request c99968673cbe538c684d33b526dd2dc2 for job b97a4fdaa850f2dbd9ac649050a27864 from resource manager with leader id ba14a948fd717250db0b2b8141da4768.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b97a4fdaa850f2dbd9ac649050a27864 with allocation id 3795331788bff4f18108cb67065bdbbb.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b97a4fdaa850f2dbd9ac649050a27864 with allocation id 78a4c21e56ba3fbee63a50b81c935306.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b97a4fdaa850f2dbd9ac649050a27864 with allocation id 7b1bd32b1788452af27d0da0cba53916.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b97a4fdaa850f2dbd9ac649050a27864 with allocation id c5c505dadf34efcc321a06e091093d97.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for c99968673cbe538c684d33b526dd2dc2.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job b97a4fdaa850f2dbd9ac649050a27864 for job leader monitoring.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1e0fbee8afc9c41eaa41f777faeaa346}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 3795331788bff4f18108cb67065bdbbb for job b97a4fdaa850f2dbd9ac649050a27864 from resource manager with leader id ba14a948fd717250db0b2b8141da4768.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 3795331788bff4f18108cb67065bdbbb.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job b97a4fdaa850f2dbd9ac649050a27864 for job leader monitoring.
2020-01-14 22:32:42 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 40a28701-c839-41bd-ad58-76c5871773e6.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 78a4c21e56ba3fbee63a50b81c935306 for job b97a4fdaa850f2dbd9ac649050a27864 from resource manager with leader id ba14a948fd717250db0b2b8141da4768.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 78a4c21e56ba3fbee63a50b81c935306.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job b97a4fdaa850f2dbd9ac649050a27864 for job leader monitoring.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b97a4fdaa850f2dbd9ac649050a27864 with allocation id a6d029f399736e941b54bdd8ea9e807b.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 7b1bd32b1788452af27d0da0cba53916 for job b97a4fdaa850f2dbd9ac649050a27864 from resource manager with leader id ba14a948fd717250db0b2b8141da4768.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 7b1bd32b1788452af27d0da0cba53916.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job b97a4fdaa850f2dbd9ac649050a27864 for job leader monitoring.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request c5c505dadf34efcc321a06e091093d97 for job b97a4fdaa850f2dbd9ac649050a27864 from resource manager with leader id ba14a948fd717250db0b2b8141da4768.
2020-01-14 22:32:42 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 40a28701-c839-41bd-ad58-76c5871773e6.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for c5c505dadf34efcc321a06e091093d97.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job b97a4fdaa850f2dbd9ac649050a27864 for job leader monitoring.
2020-01-14 22:32:42 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 40a28701-c839-41bd-ad58-76c5871773e6.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request a6d029f399736e941b54bdd8ea9e807b for job b97a4fdaa850f2dbd9ac649050a27864 from resource manager with leader id ba14a948fd717250db0b2b8141da4768.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for a6d029f399736e941b54bdd8ea9e807b.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job b97a4fdaa850f2dbd9ac649050a27864 for job leader monitoring.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:32:42 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 40a28701-c839-41bd-ad58-76c5871773e6.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job b97a4fdaa850f2dbd9ac649050a27864.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job b97a4fdaa850f2dbd9ac649050a27864.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b97a4fdaa850f2dbd9ac649050a27864.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02 @ localhost (dataPort=-1)
2020-01-14 22:32:42 [mini-cluster-io-thread-1] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02 @ localhost (dataPort=-1)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02 @ localhost (dataPort=-1)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02 @ localhost (dataPort=-1)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02 @ localhost (dataPort=-1)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) switched from SCHEDULED to DEPLOYING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to 5a89f75e-bae2-4aec-b0c0-eec33d8d6b02 @ localhost (dataPort=-1)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) switched from CREATED to DEPLOYING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) [DEPLOYING]
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) [DEPLOYING].
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) switched from CREATED to DEPLOYING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) [DEPLOYING]
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) switched from CREATED to DEPLOYING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) [DEPLOYING]
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) [DEPLOYING].
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) switched from CREATED to DEPLOYING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) [DEPLOYING]
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) [DEPLOYING].
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (8dcc75d2fda6a5392a8d7312511644b3) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) switched from CREATED to DEPLOYING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) [DEPLOYING]
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) [DEPLOYING].
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 78a4c21e56ba3fbee63a50b81c935306.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (d64174a5dac171a7063bf337cace217d) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (02478f9bf6c124dfcdba4894005ca313) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot c99968673cbe538c684d33b526dd2dc2.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 3795331788bff4f18108cb67065bdbbb.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot c5c505dadf34efcc321a06e091093d97.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 7b1bd32b1788452af27d0da0cba53916.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot a6d029f399736e941b54bdd8ea9e807b.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (a1ee37a053898c724d5750b4038b1285) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) switched from CREATED to DEPLOYING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) [DEPLOYING]
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (31ca11b60d0c773dc0d85a68d4ddf0f4) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) [DEPLOYING].
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (d1661a02a6cb194b7ec318c5c8f6c843) switched from DEPLOYING to RUNNING.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-14 22:32:42 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:32:43 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-14 22:32:43 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-14 22:32:43 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-14 22:32:43 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-14 22:32:43 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-9, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: aGNFuA6wTzuA-KH6ljhq2g
2020-01-14 22:32:43 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-9, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-14 22:33:17 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-14 22:33:17 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-16bcb24b-4517-4f19-bd43-8f1d290b7cdb
2020-01-14 22:33:17 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-14 22:33:17 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-14 22:33:17 [IOManagerAsync shutdown hook] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-e3f59bfa-0877-45b9-b6f8-136ad68f218b
2020-01-14 22:33:17 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:34911
2020-01-15 08:48:44 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 08:48:44 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 08:48:44 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:48:44 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 08:48:45 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 08:48:45 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 08:48:45 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 08:48:45 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 08:48:46 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:48:46 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 08:48:46 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:48:46 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 08:48:46 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:39507]
2020-01-15 08:48:46 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:39507
2020-01-15 08:48:46 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 08:48:46 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 08:48:46 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-806f4984-3a11-41c1-8aa5-bd4cbcd01fa9
2020-01-15 08:48:46 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:38691 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 08:48:46 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-ed6d6dfc-e5fe-4986-a7c6-69be962e7c91
2020-01-15 08:48:46 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-03325029-26ba-45a4-92fc-1e6adefb981d
2020-01-15 08:48:46 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 08:48:46 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: c4f3e778-4cc5-4603-ab1f-b592d20d144e
2020-01-15 08:48:46 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 08:48:46 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-575b7e09-8599-4459-9cae-382b3a5665f4 for spill files.
2020-01-15 08:48:46 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-05a7496b-4c36-447b-935e-0d2cc2cef293 for spill files.
2020-01-15 08:48:47 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 08:48:47 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 08:48:47 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 08:48:47 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 08:48:47 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 08:48:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-a195feb4-e7ae-41b2-9cff-d8ea075b8e67
2020-01-15 08:48:47 [main] INFO  DispatcherRestEndpoint:454 - Upload directory /tmp/flink-web-upload does not exist. 
2020-01-15 08:48:47 [main] INFO  DispatcherRestEndpoint:476 - Created directory /tmp/flink-web-upload for file uploads.
2020-01-15 08:48:47 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 08:48:47 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 08:48:47 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 08:48:47 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 08:48:47 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:40821
2020-01-15 08:48:47 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@40a72ecd @ http://localhost:40821
2020-01-15 08:48:47 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:40821 was granted leadership with leaderSessionID=04d2f94e-f22f-4fdf-a3a6-d8f0ff73af9b
2020-01-15 08:48:47 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:40821 , session=04d2f94e-f22f-4fdf-a3a6-d8f0ff73af9b
2020-01-15 08:48:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 08:48:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@77d6f9ae @ akka://flink/user/dispatcher
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@14d7b27a @ akka://flink/user/resourcemanager
2020-01-15 08:48:47 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token f0a87fb8-129e-4c7e-8b9b-0785c6943bf6
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 970db34e32ebac86381c8b16889b47dc
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=f0a87fb8-129e-4c7e-8b9b-0785c6943bf6
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=381c8b16-889b-47dc-970d-b34e32ebac86
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(970db34e32ebac86381c8b16889b47dc).
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID c4f3e778-4cc5-4603-ab1f-b592d20d144e (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 599624e9613b485cf83d33144e3d23bc (Flink Streaming Job).
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 599624e9613b485cf83d33144e3d23bc (Flink Streaming Job).
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 6de944842901d84b5822c348fd1ac3aa.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc).
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (599624e9613b485cf83d33144e3d23bc).
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc).
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@1ce5c368 @ akka://flink/user/jobmanager_1
2020-01-15 08:48:47 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc) was granted leadership with session id 00541173-cac4-4e72-8431-8b1333aefbde at akka://flink/user/jobmanager_1.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc) under job master id 84318b1333aefbde00541173cac44e72.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc) switched from state CREATED to RUNNING.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from CREATED to SCHEDULED.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{03e8488e8825d94a9ce1b9f8d367fe9f}]
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) switched from CREATED to SCHEDULED.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{eeeb53ee2b6da5c24b287e9de08b2ebc}]
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from CREATED to SCHEDULED.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3340e1d555332744d0ab58c133a6df9f}]
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from CREATED to SCHEDULED.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d73a2bf97d2277166c9686c20b169fc4}]
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from CREATED to SCHEDULED.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5d0484c5ca680b27794b7dd88212bacf}]
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from CREATED to SCHEDULED.
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{dda73d563abc0a63d80016721220c4b4}]
2020-01-15 08:48:47 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=00541173-cac4-4e72-8431-8b1333aefbde
2020-01-15 08:48:47 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(970db34e32ebac86381c8b16889b47dc)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 84318b1333aefbde00541173cac44e72@akka://flink/user/jobmanager_1 for job 599624e9613b485cf83d33144e3d23bc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager 84318b1333aefbde00541173cac44e72@akka://flink/user/jobmanager_1 for job 599624e9613b485cf83d33144e3d23bc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 970db34e32ebac86381c8b16889b47dc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{03e8488e8825d94a9ce1b9f8d367fe9f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{eeeb53ee2b6da5c24b287e9de08b2ebc}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 599624e9613b485cf83d33144e3d23bc with allocation id 786244e6d5cbf72cca42e3a46fe2b2de.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{3340e1d555332744d0ab58c133a6df9f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d73a2bf97d2277166c9686c20b169fc4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5d0484c5ca680b27794b7dd88212bacf}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 786244e6d5cbf72cca42e3a46fe2b2de for job 599624e9613b485cf83d33144e3d23bc from resource manager with leader id 970db34e32ebac86381c8b16889b47dc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 599624e9613b485cf83d33144e3d23bc with allocation id ed996ab260ab2f37b260c9c5dc51fd27.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 599624e9613b485cf83d33144e3d23bc with allocation id 4ac320fbe292fbdb1850e1e1c1d0cf9e.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 599624e9613b485cf83d33144e3d23bc with allocation id e9f3d6afa275c7f1c2d153f6da2af76d.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{dda73d563abc0a63d80016721220c4b4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 599624e9613b485cf83d33144e3d23bc with allocation id 52cd664d363be45ff6cd3cbabe9c1746.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 786244e6d5cbf72cca42e3a46fe2b2de.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 599624e9613b485cf83d33144e3d23bc for job leader monitoring.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 599624e9613b485cf83d33144e3d23bc with allocation id 2ca931fbae5b749b073af9cf39dcd184.
2020-01-15 08:48:48 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00541173-cac4-4e72-8431-8b1333aefbde.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request ed996ab260ab2f37b260c9c5dc51fd27 for job 599624e9613b485cf83d33144e3d23bc from resource manager with leader id 970db34e32ebac86381c8b16889b47dc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for ed996ab260ab2f37b260c9c5dc51fd27.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 599624e9613b485cf83d33144e3d23bc for job leader monitoring.
2020-01-15 08:48:48 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00541173-cac4-4e72-8431-8b1333aefbde.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 4ac320fbe292fbdb1850e1e1c1d0cf9e for job 599624e9613b485cf83d33144e3d23bc from resource manager with leader id 970db34e32ebac86381c8b16889b47dc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 4ac320fbe292fbdb1850e1e1c1d0cf9e.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 599624e9613b485cf83d33144e3d23bc for job leader monitoring.
2020-01-15 08:48:48 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00541173-cac4-4e72-8431-8b1333aefbde.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request e9f3d6afa275c7f1c2d153f6da2af76d for job 599624e9613b485cf83d33144e3d23bc from resource manager with leader id 970db34e32ebac86381c8b16889b47dc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for e9f3d6afa275c7f1c2d153f6da2af76d.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 599624e9613b485cf83d33144e3d23bc for job leader monitoring.
2020-01-15 08:48:48 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00541173-cac4-4e72-8431-8b1333aefbde.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 52cd664d363be45ff6cd3cbabe9c1746 for job 599624e9613b485cf83d33144e3d23bc from resource manager with leader id 970db34e32ebac86381c8b16889b47dc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 52cd664d363be45ff6cd3cbabe9c1746.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 599624e9613b485cf83d33144e3d23bc for job leader monitoring.
2020-01-15 08:48:48 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00541173-cac4-4e72-8431-8b1333aefbde.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 2ca931fbae5b749b073af9cf39dcd184 for job 599624e9613b485cf83d33144e3d23bc from resource manager with leader id 970db34e32ebac86381c8b16889b47dc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 2ca931fbae5b749b073af9cf39dcd184.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 599624e9613b485cf83d33144e3d23bc for job leader monitoring.
2020-01-15 08:48:48 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00541173-cac4-4e72-8431-8b1333aefbde.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 599624e9613b485cf83d33144e3d23bc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job 599624e9613b485cf83d33144e3d23bc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 599624e9613b485cf83d33144e3d23bc.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to c4f3e778-4cc5-4603-ab1f-b592d20d144e @ localhost (dataPort=-1)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to c4f3e778-4cc5-4603-ab1f-b592d20d144e @ localhost (dataPort=-1)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to c4f3e778-4cc5-4603-ab1f-b592d20d144e @ localhost (dataPort=-1)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to c4f3e778-4cc5-4603-ab1f-b592d20d144e @ localhost (dataPort=-1)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to c4f3e778-4cc5-4603-ab1f-b592d20d144e @ localhost (dataPort=-1)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to c4f3e778-4cc5-4603-ab1f-b592d20d144e @ localhost (dataPort=-1)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from CREATED to DEPLOYING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) [DEPLOYING]
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) [DEPLOYING].
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) [DEPLOYING].
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) switched from CREATED to DEPLOYING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) [DEPLOYING]
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from CREATED to DEPLOYING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) [DEPLOYING]
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) [DEPLOYING].
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) [DEPLOYING].
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) [DEPLOYING].
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) [DEPLOYING].
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from CREATED to DEPLOYING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) [DEPLOYING]
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) [DEPLOYING].
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) [DEPLOYING].
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from CREATED to DEPLOYING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) [DEPLOYING]
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) [DEPLOYING].
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) [DEPLOYING].
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot e9f3d6afa275c7f1c2d153f6da2af76d.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 786244e6d5cbf72cca42e3a46fe2b2de.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 52cd664d363be45ff6cd3cbabe9c1746.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot ed996ab260ab2f37b260c9c5dc51fd27.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 4ac320fbe292fbdb1850e1e1c1d0cf9e.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 2ca931fbae5b749b073af9cf39dcd184.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from CREATED to DEPLOYING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) [DEPLOYING]
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) [DEPLOYING].
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) [DEPLOYING].
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from DEPLOYING to RUNNING.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 08:48:48 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 08:48:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 08:48:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 08:48:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 08:48:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 08:48:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 08:48:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-9, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:48:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:48:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-9, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 08:48:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:727 - [Consumer clientId=consumer-9, groupId=flink_consumer] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 08:48:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-9, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 08:48:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:727 - [Consumer clientId=consumer-9, groupId=flink_consumer] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 08:48:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-9, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 08:48:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Fetcher:584 - [Consumer clientId=consumer-9, groupId=flink_consumer] Resetting offset for partition source-topic-0 to offset 0.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:960 - Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) [?:?]
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:654) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
Caused by: java.lang.NullPointerException
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:82) ~[classes/:?]
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:1) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:50) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:637) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) [FAILED]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Flat Map 91b164f8312093bb459f5872abfa1f39.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1493 - Source: Custom Source -> Flat Map (2/6) (91b164f8312093bb459f5872abfa1f39) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:654) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
Caused by: java.lang.NullPointerException
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:82) ~[classes/:?]
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:1) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:50) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:637) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:654) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
Caused by: java.lang.NullPointerException
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:82) ~[classes/:?]
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:1) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:50) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:637) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) [CANCELED]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) [CANCELED]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from RUNNING to CANCELING.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) [CANCELED]
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) [CANCELED]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map 0d7662e88cf3a8f19bc6b599681d50cb.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map 163a72cf0d36c401a38c99857973dd08.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map dd5bfbfbf1f7d33824ebec2b943d7f05.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (0d7662e88cf3a8f19bc6b599681d50cb) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map fc0f52ca772b4c25622bf28fa8b872fe.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (163a72cf0d36c401a38c99857973dd08) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (dd5bfbfbf1f7d33824ebec2b943d7f05) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fc0f52ca772b4c25622bf28fa8b872fe) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852).
2020-01-15 08:49:04 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) [CANCELED]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map a457e440106acb78e35debfc83c7d852.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a457e440106acb78e35debfc83c7d852) switched from CANCELING to CANCELED.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1446 - Try to restart or fail the job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc) if no longer possible.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:654) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
Caused by: java.lang.NullPointerException
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:82) ~[classes/:?]
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:1) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:50) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:637) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1472 - Could not restart the job Flink Streaming Job (599624e9613b485cf83d33144e3d23bc) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:654) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
Caused by: java.lang.NullPointerException
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:82) ~[classes/:?]
	at com.narioinc.flinkdemos.ReadJSONFromKafka$2.flatMap(ReadJSONFromKafka.java:1) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:50) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:637) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:612) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:592) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:727) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:705) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPeriodicWatermark(AbstractFetcher.java:436) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:402) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:185) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:150) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  CheckpointCoordinator:329 - Stopping checkpoint coordinator for job 599624e9613b485cf83d33144e3d23bc.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneCompletedCheckpointStore:97 - Shutting down
2020-01-15 08:49:04 [main] INFO  MiniCluster:416 - Shutting down Flink Mini Cluster
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-8] INFO  StandaloneDispatcher:775 - Job 599624e9613b485cf83d33144e3d23bc reached globally terminal state FAILED.
2020-01-15 08:49:04 [main] INFO  DispatcherRestEndpoint:290 - Shutting down rest endpoint.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  TaskExecutor:339 - Stopping TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  TaskExecutor:1078 - Close ResourceManager connection bc5d39cb5607b5e2ed0dd0312f56af68.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:805 - Closing TaskExecutor connection c4f3e778-4cc5-4603-ab1f-b592d20d144e because: The TaskExecutor is shutting down.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-575b7e09-8599-4459-9cae-382b3a5665f4
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  NettyShuffleEnvironment:304 - Shutting down the network environment and its components.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:335 - Stopping the JobMaster for job Flink Streaming Job(599624e9613b485cf83d33144e3d23bc).
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  SlotPoolImpl:228 - Suspending SlotPool.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:1010 - Close ResourceManager connection bc5d39cb5607b5e2ed0dd0312f56af68: JobManager is shutting down..
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  SlotPoolImpl:249 - Stopping SlotPool.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:776 - Disconnect job manager 84318b1333aefbde00541173cac44e72@akka://flink/user/jobmanager_1 for job 599624e9613b485cf83d33144e3d23bc from the resource manager.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-netty-shuffle-05a7496b-4c36-447b-935e-0d2cc2cef293
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  KvStateService:119 - Shutting down the kvState service and its components.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-a195feb4-e7ae-41b2-9cff-d8ea075b8e67
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  TaskExecutor:379 - Stopped TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 08:49:04 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:687 - Removing cache directory /tmp/flink-web-ui
2020-01-15 08:49:04 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:299 - Shut down complete.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-8] INFO  StandaloneResourceManager:499 - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneDispatcher:220 - Stopping dispatcher akka://flink/user/dispatcher.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneDispatcher:697 - Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:280 - Closing the SlotManager.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:243 - Suspending the SlotManager.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  StackTraceSampleCoordinator:220 - Shutting down stack trace sample coordinator.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneDispatcher:229 - Stopped dispatcher akka://flink/user/dispatcher.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-6] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 08:49:04 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Shutting down remote daemon.
2020-01-15 08:49:04 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remote daemon shut down; proceeding with flushing remote transports.
2020-01-15 08:49:04 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remoting shut down.
2020-01-15 08:49:04 [flink-metrics-2] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 08:49:04 [flink-metrics-2] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:38691
2020-01-15 08:49:04 [flink-akka.actor.default-dispatcher-9] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 08:50:46 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 08:50:46 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 08:50:46 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:50:46 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 08:50:47 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 08:50:47 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 08:50:47 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 08:50:47 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 08:50:47 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:50:47 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 08:50:47 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:50:48 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 08:50:48 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:36199]
2020-01-15 08:50:48 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:36199
2020-01-15 08:50:48 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 08:50:48 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 08:50:48 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-5930593c-75f8-4acc-9660-34c4c35c5230
2020-01-15 08:50:48 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:34693 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 08:50:48 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-4d5bb265-68d6-4589-9e1f-1530edfc1bd4
2020-01-15 08:50:48 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-d668bfab-af8a-4771-873a-0ac702952f0d
2020-01-15 08:50:48 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 08:50:48 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: ae666863-9b1f-4508-b7e4-3e78db0b4db4
2020-01-15 08:50:48 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 08:50:48 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-db6efd80-3715-4d9c-a95d-600d9147eae6 for spill files.
2020-01-15 08:50:48 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-6af4ad50-b9b2-4930-b3f2-50b2af48c555 for spill files.
2020-01-15 08:50:48 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 08:50:48 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 08:50:48 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 08:50:48 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 08:50:48 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 08:50:48 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 08:50:48 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 08:50:48 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-c22101ef-6679-4f73-b155-390d83b844b3
2020-01-15 08:50:49 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 08:50:49 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 08:50:49 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 08:50:49 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 08:50:49 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:37391
2020-01-15 08:50:49 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@2251b3bc @ http://localhost:37391
2020-01-15 08:50:49 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:37391 was granted leadership with leaderSessionID=303febec-a775-41da-bd3d-a12213bb5a80
2020-01-15 08:50:49 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:37391 , session=303febec-a775-41da-bd3d-a12213bb5a80
2020-01-15 08:50:49 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 08:50:49 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@55704d2b @ akka://flink/user/resourcemanager
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@7039aa88 @ akka://flink/user/dispatcher
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9444ed0927c91a7fab0432c28e60496d
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 08:50:49 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=ab0432c2-8e60-496d-9444-ed0927c91a7f
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 367cb1a8-1251-4fca-ae06-e50bf135e527
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(9444ed0927c91a7fab0432c28e60496d).
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=367cb1a8-1251-4fca-ae06-e50bf135e527
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID ae666863-9b1f-4508-b7e4-3e78db0b4db4 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 8f0fa732188c0028f7ac565838c8f44f (Flink Streaming Job).
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 8f0fa732188c0028f7ac565838c8f44f (Flink Streaming Job).
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 6a80171ef794b5748c3d00185d974c51.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (8f0fa732188c0028f7ac565838c8f44f).
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (8f0fa732188c0028f7ac565838c8f44f).
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (8f0fa732188c0028f7ac565838c8f44f).
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@1dbb56d3 @ akka://flink/user/jobmanager_1
2020-01-15 08:50:49 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (8f0fa732188c0028f7ac565838c8f44f) was granted leadership with session id 10d7c4d0-f5a8-4f53-b554-514e3be3a513 at akka://flink/user/jobmanager_1.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (8f0fa732188c0028f7ac565838c8f44f) under job master id b554514e3be3a51310d7c4d0f5a84f53.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (8f0fa732188c0028f7ac565838c8f44f) switched from state CREATED to RUNNING.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) switched from CREATED to SCHEDULED.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f5ef1adb61b41e60909b60164cac6506}]
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) switched from CREATED to SCHEDULED.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7b8efd7b10be0597e37d74986b3444f2}]
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) switched from CREATED to SCHEDULED.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3e47ea65b1aa448aa4ecfd0f2001ea33}]
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) switched from CREATED to SCHEDULED.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c833c58c55b30cdcbe306d85b3daa0b1}]
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) switched from CREATED to SCHEDULED.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{38159409067ad7d76950660c0b4d76ca}]
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) switched from CREATED to SCHEDULED.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9ace67ab7584790137bfc71dfa2cf74f}]
2020-01-15 08:50:49 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=10d7c4d0-f5a8-4f53-b554-514e3be3a513
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(9444ed0927c91a7fab0432c28e60496d)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager b554514e3be3a51310d7c4d0f5a84f53@akka://flink/user/jobmanager_1 for job 8f0fa732188c0028f7ac565838c8f44f.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager b554514e3be3a51310d7c4d0f5a84f53@akka://flink/user/jobmanager_1 for job 8f0fa732188c0028f7ac565838c8f44f.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 9444ed0927c91a7fab0432c28e60496d.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f5ef1adb61b41e60909b60164cac6506}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 8f0fa732188c0028f7ac565838c8f44f with allocation id a38238001edff45a7e7ccf3dd36aff0e.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request a38238001edff45a7e7ccf3dd36aff0e for job 8f0fa732188c0028f7ac565838c8f44f from resource manager with leader id 9444ed0927c91a7fab0432c28e60496d.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for a38238001edff45a7e7ccf3dd36aff0e.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7b8efd7b10be0597e37d74986b3444f2}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 8f0fa732188c0028f7ac565838c8f44f for job leader monitoring.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{3e47ea65b1aa448aa4ecfd0f2001ea33}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c833c58c55b30cdcbe306d85b3daa0b1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{38159409067ad7d76950660c0b4d76ca}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 8f0fa732188c0028f7ac565838c8f44f with allocation id 30c034c2536d6dfd00bf5a50f41882bb.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{9ace67ab7584790137bfc71dfa2cf74f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 30c034c2536d6dfd00bf5a50f41882bb for job 8f0fa732188c0028f7ac565838c8f44f from resource manager with leader id 9444ed0927c91a7fab0432c28e60496d.
2020-01-15 08:50:49 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 10d7c4d0-f5a8-4f53-b554-514e3be3a513.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 30c034c2536d6dfd00bf5a50f41882bb.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 8f0fa732188c0028f7ac565838c8f44f for job leader monitoring.
2020-01-15 08:50:49 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 10d7c4d0-f5a8-4f53-b554-514e3be3a513.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 8f0fa732188c0028f7ac565838c8f44f with allocation id ca5d219eb225285951fe89b9b50b15a9.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 8f0fa732188c0028f7ac565838c8f44f with allocation id 9321ae152520a3a895feb74eac15f91e.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request ca5d219eb225285951fe89b9b50b15a9 for job 8f0fa732188c0028f7ac565838c8f44f from resource manager with leader id 9444ed0927c91a7fab0432c28e60496d.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 8f0fa732188c0028f7ac565838c8f44f with allocation id 680e7e27fb19e7a4011cdb44146723b6.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for ca5d219eb225285951fe89b9b50b15a9.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 8f0fa732188c0028f7ac565838c8f44f for job leader monitoring.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 8f0fa732188c0028f7ac565838c8f44f with allocation id 64c502a8d10cb07e2941e81858e43976.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 9321ae152520a3a895feb74eac15f91e for job 8f0fa732188c0028f7ac565838c8f44f from resource manager with leader id 9444ed0927c91a7fab0432c28e60496d.
2020-01-15 08:50:49 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 10d7c4d0-f5a8-4f53-b554-514e3be3a513.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 9321ae152520a3a895feb74eac15f91e.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 8f0fa732188c0028f7ac565838c8f44f for job leader monitoring.
2020-01-15 08:50:49 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 10d7c4d0-f5a8-4f53-b554-514e3be3a513.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 680e7e27fb19e7a4011cdb44146723b6 for job 8f0fa732188c0028f7ac565838c8f44f from resource manager with leader id 9444ed0927c91a7fab0432c28e60496d.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 680e7e27fb19e7a4011cdb44146723b6.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 8f0fa732188c0028f7ac565838c8f44f for job leader monitoring.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 64c502a8d10cb07e2941e81858e43976 for job 8f0fa732188c0028f7ac565838c8f44f from resource manager with leader id 9444ed0927c91a7fab0432c28e60496d.
2020-01-15 08:50:49 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 10d7c4d0-f5a8-4f53-b554-514e3be3a513.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 64c502a8d10cb07e2941e81858e43976.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 8f0fa732188c0028f7ac565838c8f44f for job leader monitoring.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:50:49 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 10d7c4d0-f5a8-4f53-b554-514e3be3a513.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 8f0fa732188c0028f7ac565838c8f44f.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job 8f0fa732188c0028f7ac565838c8f44f.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 8f0fa732188c0028f7ac565838c8f44f.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to ae666863-9b1f-4508-b7e4-3e78db0b4db4 @ localhost (dataPort=-1)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to ae666863-9b1f-4508-b7e4-3e78db0b4db4 @ localhost (dataPort=-1)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to ae666863-9b1f-4508-b7e4-3e78db0b4db4 @ localhost (dataPort=-1)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to ae666863-9b1f-4508-b7e4-3e78db0b4db4 @ localhost (dataPort=-1)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to ae666863-9b1f-4508-b7e4-3e78db0b4db4 @ localhost (dataPort=-1)
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:50:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to ae666863-9b1f-4508-b7e4-3e78db0b4db4 @ localhost (dataPort=-1)
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) switched from CREATED to DEPLOYING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) [DEPLOYING]
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) switched from CREATED to DEPLOYING.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) switched from CREATED to DEPLOYING.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot a38238001edff45a7e7ccf3dd36aff0e.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) [DEPLOYING]
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot ca5d219eb225285951fe89b9b50b15a9.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 64c502a8d10cb07e2941e81858e43976.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 680e7e27fb19e7a4011cdb44146723b6.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 30c034c2536d6dfd00bf5a50f41882bb.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) [DEPLOYING]
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 9321ae152520a3a895feb74eac15f91e.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) [DEPLOYING].
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) switched from CREATED to DEPLOYING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) [DEPLOYING]
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) [DEPLOYING].
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) switched from CREATED to DEPLOYING.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (21ac7899a8b97a6510149185d059ed11) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) [DEPLOYING]
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) [DEPLOYING].
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (aa8b4cef8d7493d954d31201bd98f0a7) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (24d3be3b0ba3a604e66b91ee16955328) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (41b92cdf8f77c0bf5d0e1f197d28934b) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (1930d26dc7609387c5006b51d7500a3e) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) switched from CREATED to DEPLOYING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) [DEPLOYING]
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) [DEPLOYING].
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:50:50 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (4e5043e21802fc6fe3f7e251ac6315b8) switched from DEPLOYING to RUNNING.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:50 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 08:50:51 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 08:50:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 08:50:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 08:50:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 08:50:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 08:50:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 08:50:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-9, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-9, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:50:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:44 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 08:52:44 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 08:52:44 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:52:44 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 08:52:45 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 08:52:45 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 08:52:45 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 08:52:45 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 08:52:46 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:52:46 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 08:52:46 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:52:46 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 08:52:46 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:33999]
2020-01-15 08:52:46 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:33999
2020-01-15 08:52:46 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 08:52:46 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 08:52:46 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-4bc8aed7-44bb-47c5-b350-3d967e4f4ae9
2020-01-15 08:52:46 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:38169 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 08:52:46 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-2cbc2c8e-01a9-4a08-9a31-d239bd4707e6
2020-01-15 08:52:46 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-ca3763e6-6188-4b00-a8a4-51efe01ac544
2020-01-15 08:52:46 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 08:52:46 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 9faaa150-d433-4789-9e86-6f0b438c6487
2020-01-15 08:52:46 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 08:52:46 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-b316c039-a5e4-4ee5-893f-9c6539b4f105 for spill files.
2020-01-15 08:52:46 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-f8710edf-72ec-488e-b974-4c2be087b2ce for spill files.
2020-01-15 08:52:47 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 08:52:47 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 08:52:47 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 08:52:47 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 08:52:47 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 08:52:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-5b5021d8-4c3f-411d-ba30-a81deb6d808c
2020-01-15 08:52:47 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 08:52:47 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 08:52:47 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 08:52:47 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 08:52:47 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:44391
2020-01-15 08:52:47 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@ae73c80 @ http://localhost:44391
2020-01-15 08:52:47 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:44391 was granted leadership with leaderSessionID=6f9caaf1-256f-41ec-8218-7e7bbf74533f
2020-01-15 08:52:47 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:44391 , session=6f9caaf1-256f-41ec-8218-7e7bbf74533f
2020-01-15 08:52:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 08:52:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@3e926ec5 @ akka://flink/user/dispatcher
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@c1e9eb8 @ akka://flink/user/resourcemanager
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 0d27d8e3-f8fa-4580-b1be-0590352a28cb
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 942aef4b76f0b34d10ac31d673e8496d
2020-01-15 08:52:47 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=0d27d8e3-f8fa-4580-b1be-0590352a28cb
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=10ac31d6-73e8-496d-942a-ef4b76f0b34d
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(942aef4b76f0b34d10ac31d673e8496d).
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 59ce260ff4537a042c86b4195177ec69 (Flink Streaming Job).
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 59ce260ff4537a042c86b4195177ec69 (Flink Streaming Job).
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 9faaa150-d433-4789-9e86-6f0b438c6487 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id baf8c5a3ac90d55862a36b5cea77d535.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:241 - Initializing job Flink Streaming Job (59ce260ff4537a042c86b4195177ec69).
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (59ce260ff4537a042c86b4195177ec69).
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (59ce260ff4537a042c86b4195177ec69).
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:222 - Successfully ran initialization on master in 1 ms.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@4cc0378b @ akka://flink/user/jobmanager_1
2020-01-15 08:52:47 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (59ce260ff4537a042c86b4195177ec69) was granted leadership with session id c762cf29-59ad-4dd7-b5d0-943e85e8d929 at akka://flink/user/jobmanager_1.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (59ce260ff4537a042c86b4195177ec69) under job master id b5d0943e85e8d929c762cf2959ad4dd7.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (59ce260ff4537a042c86b4195177ec69) switched from state CREATED to RUNNING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) switched from CREATED to SCHEDULED.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b6bac7211796717584c12cf356d20cf7}]
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) switched from CREATED to SCHEDULED.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5b7087ef7e4fd4925fada3ad2c28591c}]
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) switched from CREATED to SCHEDULED.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{85f8a82f162257c673b6b76eff7f5265}]
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) switched from CREATED to SCHEDULED.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7c2534bb60abcf70c6b29ca795ab4275}]
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) switched from CREATED to SCHEDULED.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e3f93fa8ceef1f5c2d7f273724e615ab}]
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) switched from CREATED to SCHEDULED.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9cf3402c3eeeb371f5c1b3a9126191a9}]
2020-01-15 08:52:47 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=c762cf29-59ad-4dd7-b5d0-943e85e8d929
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(942aef4b76f0b34d10ac31d673e8496d)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:302 - Registering job manager b5d0943e85e8d929c762cf2959ad4dd7@akka://flink/user/jobmanager_1 for job 59ce260ff4537a042c86b4195177ec69.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager b5d0943e85e8d929c762cf2959ad4dd7@akka://flink/user/jobmanager_1 for job 59ce260ff4537a042c86b4195177ec69.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 942aef4b76f0b34d10ac31d673e8496d.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b6bac7211796717584c12cf356d20cf7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 59ce260ff4537a042c86b4195177ec69 with allocation id bd205a1e194bfca6b68c8aa95ea6f573.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5b7087ef7e4fd4925fada3ad2c28591c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{85f8a82f162257c673b6b76eff7f5265}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7c2534bb60abcf70c6b29ca795ab4275}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request bd205a1e194bfca6b68c8aa95ea6f573 for job 59ce260ff4537a042c86b4195177ec69 from resource manager with leader id 942aef4b76f0b34d10ac31d673e8496d.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e3f93fa8ceef1f5c2d7f273724e615ab}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 59ce260ff4537a042c86b4195177ec69 with allocation id dd4c2bac8de9589d76438bb39635861f.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{9cf3402c3eeeb371f5c1b3a9126191a9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for bd205a1e194bfca6b68c8aa95ea6f573.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 59ce260ff4537a042c86b4195177ec69 for job leader monitoring.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 59ce260ff4537a042c86b4195177ec69 with allocation id ef5669a7642f15a2ca34ddeabd43c2a3.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 59ce260ff4537a042c86b4195177ec69 with allocation id d0ee1a96c0c9ca8bb2ef353ef27d70a3.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request dd4c2bac8de9589d76438bb39635861f for job 59ce260ff4537a042c86b4195177ec69 from resource manager with leader id 942aef4b76f0b34d10ac31d673e8496d.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for dd4c2bac8de9589d76438bb39635861f.
2020-01-15 08:52:47 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c762cf29-59ad-4dd7-b5d0-943e85e8d929.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 59ce260ff4537a042c86b4195177ec69 with allocation id ad92042a19df81fedd65e1f3f03ce3dd.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 59ce260ff4537a042c86b4195177ec69 for job leader monitoring.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 59ce260ff4537a042c86b4195177ec69 with allocation id 139835e0e7d3811321f3bc730019df6d.
2020-01-15 08:52:47 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c762cf29-59ad-4dd7-b5d0-943e85e8d929.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request ef5669a7642f15a2ca34ddeabd43c2a3 for job 59ce260ff4537a042c86b4195177ec69 from resource manager with leader id 942aef4b76f0b34d10ac31d673e8496d.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for ef5669a7642f15a2ca34ddeabd43c2a3.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 59ce260ff4537a042c86b4195177ec69 for job leader monitoring.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request d0ee1a96c0c9ca8bb2ef353ef27d70a3 for job 59ce260ff4537a042c86b4195177ec69 from resource manager with leader id 942aef4b76f0b34d10ac31d673e8496d.
2020-01-15 08:52:47 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c762cf29-59ad-4dd7-b5d0-943e85e8d929.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for d0ee1a96c0c9ca8bb2ef353ef27d70a3.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 59ce260ff4537a042c86b4195177ec69 for job leader monitoring.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request ad92042a19df81fedd65e1f3f03ce3dd for job 59ce260ff4537a042c86b4195177ec69 from resource manager with leader id 942aef4b76f0b34d10ac31d673e8496d.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for ad92042a19df81fedd65e1f3f03ce3dd.
2020-01-15 08:52:47 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c762cf29-59ad-4dd7-b5d0-943e85e8d929.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 59ce260ff4537a042c86b4195177ec69 for job leader monitoring.
2020-01-15 08:52:47 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c762cf29-59ad-4dd7-b5d0-943e85e8d929.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 139835e0e7d3811321f3bc730019df6d for job 59ce260ff4537a042c86b4195177ec69 from resource manager with leader id 942aef4b76f0b34d10ac31d673e8496d.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 139835e0e7d3811321f3bc730019df6d.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 59ce260ff4537a042c86b4195177ec69 for job leader monitoring.
2020-01-15 08:52:47 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c762cf29-59ad-4dd7-b5d0-943e85e8d929.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 59ce260ff4537a042c86b4195177ec69.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job 59ce260ff4537a042c86b4195177ec69.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 59ce260ff4537a042c86b4195177ec69.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to 9faaa150-d433-4789-9e86-6f0b438c6487 @ localhost (dataPort=-1)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to 9faaa150-d433-4789-9e86-6f0b438c6487 @ localhost (dataPort=-1)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to 9faaa150-d433-4789-9e86-6f0b438c6487 @ localhost (dataPort=-1)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to 9faaa150-d433-4789-9e86-6f0b438c6487 @ localhost (dataPort=-1)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to 9faaa150-d433-4789-9e86-6f0b438c6487 @ localhost (dataPort=-1)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to 9faaa150-d433-4789-9e86-6f0b438c6487 @ localhost (dataPort=-1)
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) switched from CREATED to DEPLOYING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) [DEPLOYING]
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) [DEPLOYING].
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) switched from CREATED to DEPLOYING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) [DEPLOYING]
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) [DEPLOYING].
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (e8f57c53dc0eb4e95261a96b9bc7f392) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (ee9cdec033e9cfd59652100d89754d5b) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) switched from CREATED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) [DEPLOYING]
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) switched from CREATED to DEPLOYING.
2020-01-15 08:52:47 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) [DEPLOYING]
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) switched from CREATED to DEPLOYING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) [DEPLOYING]
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) [DEPLOYING].
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:47 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (b9183312e92072719a6104d544b54b61) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (3ecd2ae14fc1547f7f3eca020feb6fd5) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot ef5669a7642f15a2ca34ddeabd43c2a3.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot bd205a1e194bfca6b68c8aa95ea6f573.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (0b213b91fed58514a69d74485584debc) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 139835e0e7d3811321f3bc730019df6d.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot d0ee1a96c0c9ca8bb2ef353ef27d70a3.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot dd4c2bac8de9589d76438bb39635861f.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot ad92042a19df81fedd65e1f3f03ce3dd.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) switched from CREATED to DEPLOYING.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) [DEPLOYING]
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) [DEPLOYING].
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) [DEPLOYING].
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (3ec85f8dad920a20bd52310b833771d7) switched from DEPLOYING to RUNNING.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 08:52:48 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 08:52:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 08:52:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 08:52:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 08:52:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 08:52:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 08:52:48 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-8, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:52:48 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-8, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 08:53:27 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 08:53:27 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 08:53:27 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:53:27 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 08:53:28 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 08:53:28 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 08:53:28 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 08:53:28 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 08:53:28 [flink-akka.actor.default-dispatcher-4] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:53:28 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 08:53:28 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:53:28 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 08:53:29 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:38181]
2020-01-15 08:53:29 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:38181
2020-01-15 08:53:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 08:53:29 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 08:53:29 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-744d69da-9097-4d8c-84f7-d7a1a6d97587
2020-01-15 08:53:29 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:41667 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 08:53:29 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-c004a72e-6513-43bc-86b6-bae1bb0d5c07
2020-01-15 08:53:29 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-7b5398ea-e324-4048-922c-abd94c28b40b
2020-01-15 08:53:29 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 08:53:29 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 4f019dea-be58-46dd-9143-39afa553a54a
2020-01-15 08:53:29 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 08:53:29 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-859cfb3c-d328-495c-99a4-ce020f202bd9 for spill files.
2020-01-15 08:53:29 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-003b1ab2-54bb-4073-8ac2-8499ad696f88 for spill files.
2020-01-15 08:53:29 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 08:53:29 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 08:53:29 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 08:53:29 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 08:53:29 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 08:53:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 08:53:29 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 08:53:29 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-cda902ac-480c-40a1-baba-05432b6e11a1
2020-01-15 08:53:29 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 08:53:29 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 08:53:29 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 08:53:29 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 08:53:30 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:45115
2020-01-15 08:53:30 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@2f894ad9 @ http://localhost:45115
2020-01-15 08:53:30 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:45115 was granted leadership with leaderSessionID=54590663-2498-4ce8-a192-971dfb18fff4
2020-01-15 08:53:30 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 08:53:30 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:45115 , session=54590663-2498-4ce8-a192-971dfb18fff4
2020-01-15 08:53:30 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@129ce87b @ akka://flink/user/resourcemanager
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@69bc56de @ akka://flink/user/dispatcher
2020-01-15 08:53:30 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token ea59a55f-9b24-4eb5-a2b2-91047811fb23
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 92cb6c74c69f09cf0b98591419824e04
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=ea59a55f-9b24-4eb5-a2b2-91047811fb23
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=0b985914-1982-4e04-92cb-6c74c69f09cf
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(92cb6c74c69f09cf0b98591419824e04).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 10f3d4c65353a4062462576474238e1f (Flink Streaming Job).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 10f3d4c65353a4062462576474238e1f (Flink Streaming Job).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 4f019dea-be58-46dd-9143-39afa553a54a (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 1f11353caba75dde794a8cd4f8c849bf.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (10f3d4c65353a4062462576474238e1f).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (10f3d4c65353a4062462576474238e1f).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (10f3d4c65353a4062462576474238e1f).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@705d32 @ akka://flink/user/jobmanager_1
2020-01-15 08:53:30 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (10f3d4c65353a4062462576474238e1f) was granted leadership with session id 9479736b-0b34-4b17-9d8c-f149913ba2c0 at akka://flink/user/jobmanager_1.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (10f3d4c65353a4062462576474238e1f) under job master id 9d8cf149913ba2c09479736b0b344b17.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (10f3d4c65353a4062462576474238e1f) switched from state CREATED to RUNNING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) switched from CREATED to SCHEDULED.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f0f41178362143b6bddb0c2529efbe57}]
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) switched from CREATED to SCHEDULED.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{0b0b7ab9bd4725b071f1ab5f8d9fa97b}]
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) switched from CREATED to SCHEDULED.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e18225aee4feea38c7adb6a706dc1543}]
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) switched from CREATED to SCHEDULED.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6957a27c027f41d799793c62d8ed6396}]
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) switched from CREATED to SCHEDULED.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4dbd80e965f4611e16748572e2cf31cb}]
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) switched from CREATED to SCHEDULED.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5ae1e2fe4248950823c64f261ec170ee}]
2020-01-15 08:53:30 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=9479736b-0b34-4b17-9d8c-f149913ba2c0
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(92cb6c74c69f09cf0b98591419824e04)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager 9d8cf149913ba2c09479736b0b344b17@akka://flink/user/jobmanager_1 for job 10f3d4c65353a4062462576474238e1f.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 9d8cf149913ba2c09479736b0b344b17@akka://flink/user/jobmanager_1 for job 10f3d4c65353a4062462576474238e1f.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 92cb6c74c69f09cf0b98591419824e04.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f0f41178362143b6bddb0c2529efbe57}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 10f3d4c65353a4062462576474238e1f with allocation id bc8d2c35e18a9f1cb36a7d5cf06a1bfb.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{0b0b7ab9bd4725b071f1ab5f8d9fa97b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request bc8d2c35e18a9f1cb36a7d5cf06a1bfb for job 10f3d4c65353a4062462576474238e1f from resource manager with leader id 92cb6c74c69f09cf0b98591419824e04.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 10f3d4c65353a4062462576474238e1f with allocation id b7f44cdc1ac06bacfb33a478e16bcc52.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for bc8d2c35e18a9f1cb36a7d5cf06a1bfb.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 10f3d4c65353a4062462576474238e1f for job leader monitoring.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request b7f44cdc1ac06bacfb33a478e16bcc52 for job 10f3d4c65353a4062462576474238e1f from resource manager with leader id 92cb6c74c69f09cf0b98591419824e04.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e18225aee4feea38c7adb6a706dc1543}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for b7f44cdc1ac06bacfb33a478e16bcc52.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 10f3d4c65353a4062462576474238e1f for job leader monitoring.
2020-01-15 08:53:30 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9479736b-0b34-4b17-9d8c-f149913ba2c0.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{6957a27c027f41d799793c62d8ed6396}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 10f3d4c65353a4062462576474238e1f with allocation id e5346af3ef8686eb024c724e6fcd6a59.
2020-01-15 08:53:30 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9479736b-0b34-4b17-9d8c-f149913ba2c0.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{4dbd80e965f4611e16748572e2cf31cb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request e5346af3ef8686eb024c724e6fcd6a59 for job 10f3d4c65353a4062462576474238e1f from resource manager with leader id 92cb6c74c69f09cf0b98591419824e04.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 10f3d4c65353a4062462576474238e1f with allocation id 78fb1a364832982c0e0727a2d52f6395.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5ae1e2fe4248950823c64f261ec170ee}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 10f3d4c65353a4062462576474238e1f with allocation id 83142dde248a3d278bd13291c1960a58.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for e5346af3ef8686eb024c724e6fcd6a59.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 10f3d4c65353a4062462576474238e1f for job leader monitoring.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 78fb1a364832982c0e0727a2d52f6395 for job 10f3d4c65353a4062462576474238e1f from resource manager with leader id 92cb6c74c69f09cf0b98591419824e04.
2020-01-15 08:53:30 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9479736b-0b34-4b17-9d8c-f149913ba2c0.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 78fb1a364832982c0e0727a2d52f6395.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 10f3d4c65353a4062462576474238e1f for job leader monitoring.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 10f3d4c65353a4062462576474238e1f with allocation id 872e659c63d3e5d9d41fa6a1d86aae42.
2020-01-15 08:53:30 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9479736b-0b34-4b17-9d8c-f149913ba2c0.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 83142dde248a3d278bd13291c1960a58 for job 10f3d4c65353a4062462576474238e1f from resource manager with leader id 92cb6c74c69f09cf0b98591419824e04.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 83142dde248a3d278bd13291c1960a58.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 10f3d4c65353a4062462576474238e1f for job leader monitoring.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 872e659c63d3e5d9d41fa6a1d86aae42 for job 10f3d4c65353a4062462576474238e1f from resource manager with leader id 92cb6c74c69f09cf0b98591419824e04.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 872e659c63d3e5d9d41fa6a1d86aae42.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:53:30 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9479736b-0b34-4b17-9d8c-f149913ba2c0.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 10f3d4c65353a4062462576474238e1f for job leader monitoring.
2020-01-15 08:53:30 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9479736b-0b34-4b17-9d8c-f149913ba2c0.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 10f3d4c65353a4062462576474238e1f.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 10f3d4c65353a4062462576474238e1f.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 10f3d4c65353a4062462576474238e1f.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 10f3d4c65353a4062462576474238e1f.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 4f019dea-be58-46dd-9143-39afa553a54a @ localhost (dataPort=-1)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 4f019dea-be58-46dd-9143-39afa553a54a @ localhost (dataPort=-1)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 4f019dea-be58-46dd-9143-39afa553a54a @ localhost (dataPort=-1)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 4f019dea-be58-46dd-9143-39afa553a54a @ localhost (dataPort=-1)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 4f019dea-be58-46dd-9143-39afa553a54a @ localhost (dataPort=-1)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 4f019dea-be58-46dd-9143-39afa553a54a @ localhost (dataPort=-1)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) switched from CREATED to DEPLOYING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) [DEPLOYING]
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) switched from CREATED to DEPLOYING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) [DEPLOYING]
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) switched from CREATED to DEPLOYING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) [DEPLOYING]
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) switched from CREATED to DEPLOYING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) [DEPLOYING]
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) [DEPLOYING].
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot bc8d2c35e18a9f1cb36a7d5cf06a1bfb.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 83142dde248a3d278bd13291c1960a58.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot e5346af3ef8686eb024c724e6fcd6a59.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 78fb1a364832982c0e0727a2d52f6395.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (40445ec44b036c79ae555b517ea27d69) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) switched from CREATED to DEPLOYING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) [DEPLOYING]
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (d71018d8c4ced093474abc3c67b95fd8) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot b7f44cdc1ac06bacfb33a478e16bcc52.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 872e659c63d3e5d9d41fa6a1d86aae42.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (a733096a4408cdfbfe2c1b78fe104960) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (f56e358cab5b90bf720f3d8b280338e5) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) [DEPLOYING].
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (cdb9c80b97018b92a578ce461da9f74d) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) switched from CREATED to DEPLOYING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) [DEPLOYING]
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) [DEPLOYING].
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:53:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (b5f0b89905cda82f4713ded040b51c2b) switched from DEPLOYING to RUNNING.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:53:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 08:53:30 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 08:53:30 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 08:53:30 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 08:53:30 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 08:53:30 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 08:53:30 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:53:30 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 08:54:18 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 08:54:18 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 08:54:18 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 08:54:21 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 08:54:21 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 08:54:21 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:54:21 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 08:54:21 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 08:54:21 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 08:54:21 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 08:54:21 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 08:54:22 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:54:22 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 08:54:23 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:54:23 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 08:54:23 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:45369]
2020-01-15 08:54:23 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:45369
2020-01-15 08:54:23 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 08:54:23 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 08:54:23 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-90f832d4-8976-4eb6-a9e7-2b9fd482177c
2020-01-15 08:54:23 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:40395 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 08:54:23 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-d33f7fd9-6ad4-4102-9744-647d07fc98b0
2020-01-15 08:54:23 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-e16f6017-dbee-46cd-8d4a-6c852884cf88
2020-01-15 08:54:23 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 08:54:23 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: f379d64c-a230-4213-bda0-f2ebab981190
2020-01-15 08:54:23 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 08:54:23 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-a95dcded-23d3-4363-b6d2-ca0799e21137 for spill files.
2020-01-15 08:54:23 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-24a293b3-b065-4ad0-82a9-7b33bbad5a73 for spill files.
2020-01-15 08:54:23 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 08:54:23 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 08:54:23 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 08:54:23 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 08:54:23 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 08:54:23 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 08:54:23 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-fca10b1c-c268-4c27-bb79-457b0dc18699
2020-01-15 08:54:24 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 08:54:24 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 08:54:24 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 08:54:24 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 08:54:24 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:36839
2020-01-15 08:54:24 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@5afbd567 @ http://localhost:36839
2020-01-15 08:54:24 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:36839 was granted leadership with leaderSessionID=e784a5ca-9ed9-49e0-baab-b2118027a4e7
2020-01-15 08:54:24 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:36839 , session=e784a5ca-9ed9-49e0-baab-b2118027a4e7
2020-01-15 08:54:24 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 08:54:24 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@d548cb8 @ akka://flink/user/resourcemanager
2020-01-15 08:54:24 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token abf6567ca2cc87bf931341741fac49da
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@4b8b0fa0 @ akka://flink/user/dispatcher
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token c78bcb75-f5ea-4485-9127-cbf55d25bef0
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=93134174-1fac-49da-abf6-567ca2cc87bf
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=c78bcb75-f5ea-4485-9127-cbf55d25bef0
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(abf6567ca2cc87bf931341741fac49da).
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 46e2be8cc064cc1fb241b099dba897ae (Flink Streaming Job).
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 46e2be8cc064cc1fb241b099dba897ae (Flink Streaming Job).
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID f379d64c-a230-4213-bda0-f2ebab981190 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id d9823f527597fc2c97486aa9fb2d0cb4.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (46e2be8cc064cc1fb241b099dba897ae).
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (46e2be8cc064cc1fb241b099dba897ae).
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (46e2be8cc064cc1fb241b099dba897ae).
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 2 ms.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@6e466355 @ akka://flink/user/jobmanager_1
2020-01-15 08:54:24 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (46e2be8cc064cc1fb241b099dba897ae) was granted leadership with session id 857f60b5-315d-4da2-a073-b86ce41a2c53 at akka://flink/user/jobmanager_1.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (46e2be8cc064cc1fb241b099dba897ae) under job master id a073b86ce41a2c53857f60b5315d4da2.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (46e2be8cc064cc1fb241b099dba897ae) switched from state CREATED to RUNNING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) switched from CREATED to SCHEDULED.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{62a8090b29c6c0cda0524faa78bea3e1}]
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) switched from CREATED to SCHEDULED.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f5ab2d9584c328a7a004cee2fc735444}]
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) switched from CREATED to SCHEDULED.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1392bf8eaf9be978310ab64fa796034f}]
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) switched from CREATED to SCHEDULED.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e66e03429b02a274db1c91dd7e717f50}]
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) switched from CREATED to SCHEDULED.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ddc23a4e8d3034328d34d6a6e4f05335}]
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) switched from CREATED to SCHEDULED.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e15ee6154c50777bdfb7ffd6366eb836}]
2020-01-15 08:54:24 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=857f60b5-315d-4da2-a073-b86ce41a2c53
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(abf6567ca2cc87bf931341741fac49da)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager a073b86ce41a2c53857f60b5315d4da2@akka://flink/user/jobmanager_1 for job 46e2be8cc064cc1fb241b099dba897ae.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager a073b86ce41a2c53857f60b5315d4da2@akka://flink/user/jobmanager_1 for job 46e2be8cc064cc1fb241b099dba897ae.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: abf6567ca2cc87bf931341741fac49da.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{62a8090b29c6c0cda0524faa78bea3e1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 46e2be8cc064cc1fb241b099dba897ae with allocation id c222b165b4c1ffb69126b547206f7eb2.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f5ab2d9584c328a7a004cee2fc735444}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1392bf8eaf9be978310ab64fa796034f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request c222b165b4c1ffb69126b547206f7eb2 for job 46e2be8cc064cc1fb241b099dba897ae from resource manager with leader id abf6567ca2cc87bf931341741fac49da.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e66e03429b02a274db1c91dd7e717f50}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ddc23a4e8d3034328d34d6a6e4f05335}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 46e2be8cc064cc1fb241b099dba897ae with allocation id 2d2341805e45fa53c5b4d4b6e6e597c0.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e15ee6154c50777bdfb7ffd6366eb836}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 46e2be8cc064cc1fb241b099dba897ae with allocation id 18f8993aff4e1e40b73e27ab1f2f6587.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 46e2be8cc064cc1fb241b099dba897ae with allocation id ee16ef25a0d1ef1b3a26065e09778061.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 46e2be8cc064cc1fb241b099dba897ae with allocation id 95d34df9415aef452948941cd955a9a5.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 46e2be8cc064cc1fb241b099dba897ae with allocation id 37b4a22e1f2a5fe65e4118f66a4ab550.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for c222b165b4c1ffb69126b547206f7eb2.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 46e2be8cc064cc1fb241b099dba897ae for job leader monitoring.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 2d2341805e45fa53c5b4d4b6e6e597c0 for job 46e2be8cc064cc1fb241b099dba897ae from resource manager with leader id abf6567ca2cc87bf931341741fac49da.
2020-01-15 08:54:24 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 857f60b5-315d-4da2-a073-b86ce41a2c53.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 2d2341805e45fa53c5b4d4b6e6e597c0.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 46e2be8cc064cc1fb241b099dba897ae for job leader monitoring.
2020-01-15 08:54:24 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 857f60b5-315d-4da2-a073-b86ce41a2c53.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 18f8993aff4e1e40b73e27ab1f2f6587 for job 46e2be8cc064cc1fb241b099dba897ae from resource manager with leader id abf6567ca2cc87bf931341741fac49da.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 18f8993aff4e1e40b73e27ab1f2f6587.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 46e2be8cc064cc1fb241b099dba897ae for job leader monitoring.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:54:24 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 857f60b5-315d-4da2-a073-b86ce41a2c53.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request ee16ef25a0d1ef1b3a26065e09778061 for job 46e2be8cc064cc1fb241b099dba897ae from resource manager with leader id abf6567ca2cc87bf931341741fac49da.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for ee16ef25a0d1ef1b3a26065e09778061.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 46e2be8cc064cc1fb241b099dba897ae for job leader monitoring.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:54:24 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 857f60b5-315d-4da2-a073-b86ce41a2c53.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 95d34df9415aef452948941cd955a9a5 for job 46e2be8cc064cc1fb241b099dba897ae from resource manager with leader id abf6567ca2cc87bf931341741fac49da.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 95d34df9415aef452948941cd955a9a5.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 46e2be8cc064cc1fb241b099dba897ae for job leader monitoring.
2020-01-15 08:54:24 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 857f60b5-315d-4da2-a073-b86ce41a2c53.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 37b4a22e1f2a5fe65e4118f66a4ab550 for job 46e2be8cc064cc1fb241b099dba897ae from resource manager with leader id abf6567ca2cc87bf931341741fac49da.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 37b4a22e1f2a5fe65e4118f66a4ab550.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 46e2be8cc064cc1fb241b099dba897ae for job leader monitoring.
2020-01-15 08:54:24 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 857f60b5-315d-4da2-a073-b86ce41a2c53.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 46e2be8cc064cc1fb241b099dba897ae.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 46e2be8cc064cc1fb241b099dba897ae.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 46e2be8cc064cc1fb241b099dba897ae.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to f379d64c-a230-4213-bda0-f2ebab981190 @ localhost (dataPort=-1)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to f379d64c-a230-4213-bda0-f2ebab981190 @ localhost (dataPort=-1)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to f379d64c-a230-4213-bda0-f2ebab981190 @ localhost (dataPort=-1)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to f379d64c-a230-4213-bda0-f2ebab981190 @ localhost (dataPort=-1)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to f379d64c-a230-4213-bda0-f2ebab981190 @ localhost (dataPort=-1)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to f379d64c-a230-4213-bda0-f2ebab981190 @ localhost (dataPort=-1)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) switched from CREATED to DEPLOYING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) [DEPLOYING]
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) switched from CREATED to DEPLOYING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) [DEPLOYING]
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 18f8993aff4e1e40b73e27ab1f2f6587.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 95d34df9415aef452948941cd955a9a5.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 2d2341805e45fa53c5b4d4b6e6e597c0.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 37b4a22e1f2a5fe65e4118f66a4ab550.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot c222b165b4c1ffb69126b547206f7eb2.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot ee16ef25a0d1ef1b3a26065e09778061.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) switched from CREATED to DEPLOYING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) [DEPLOYING]
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) [DEPLOYING].
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) switched from CREATED to DEPLOYING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) [DEPLOYING]
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) [DEPLOYING].
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) [DEPLOYING].
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) switched from CREATED to DEPLOYING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) [DEPLOYING]
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) switched from CREATED to DEPLOYING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) [DEPLOYING]
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) [DEPLOYING].
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8263e3b2323fb78fccf8264b23533308) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (906f3d64333b891e2adebba23a0a5ca3) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (b7e81ddae8f543a26292ad096c1b1281) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (cc940ed41085521a0220c759d48b2add) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (2dce2a16bb0472060cb4a041d711a3e1) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:54:24 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (560a93ea909a927c989673ed8f6907e3) switched from DEPLOYING to RUNNING.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:24 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:54:25 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 08:54:25 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 08:54:25 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 08:54:25 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 08:54:25 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 08:54:25 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:25 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-8, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:54:25 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-8, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 08:55:25 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 08:59:23 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-15 08:59:23 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 08:59:23 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 08:59:23 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 08:59:23 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 08:59:23 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 08:59:25 [flink-akka.actor.default-dispatcher-4] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:59:25 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 08:59:25 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 08:59:25 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 08:59:26 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:45349]
2020-01-15 08:59:26 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:45349
2020-01-15 08:59:26 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 08:59:26 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 08:59:26 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-3f6ee82b-32dd-4666-93bf-d3f5d044565e
2020-01-15 08:59:26 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:41665 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 08:59:26 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-d1d01e8f-9786-4b52-8919-cd9a2324fd96
2020-01-15 08:59:26 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-ccddddb5-cdf4-4c70-b2b0-ba96428349da
2020-01-15 08:59:26 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 08:59:26 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 641fad91-e280-4240-a8db-25facd902c8d
2020-01-15 08:59:26 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 08:59:26 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-5364d83e-f160-4972-b5ab-1e4ce9ed1ea1 for spill files.
2020-01-15 08:59:26 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-e96853b9-8e13-41e0-b890-183a354d10d1 for spill files.
2020-01-15 08:59:26 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 08:59:26 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 08:59:26 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 08:59:26 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 08:59:26 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 08:59:26 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 08:59:26 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 08:59:26 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-30d4e797-f336-4256-ad9b-b2433b3ca1b8
2020-01-15 08:59:26 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 08:59:27 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 08:59:27 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 08:59:27 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 08:59:27 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:34301
2020-01-15 08:59:27 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@7f608e21 @ http://localhost:34301
2020-01-15 08:59:27 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:34301 was granted leadership with leaderSessionID=47391a3c-1d80-4cf1-b0b0-53c7f3a99016
2020-01-15 08:59:27 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:34301 , session=47391a3c-1d80-4cf1-b0b0-53c7f3a99016
2020-01-15 08:59:27 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 08:59:27 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6ba63068 @ akka://flink/user/resourcemanager
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@3b9a26d3 @ akka://flink/user/dispatcher
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 95f044f3-146a-4025-83e5-8fa3fbc35872
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9b2f54f20e7131e0fb7aeac78c4a460c
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=95f044f3-146a-4025-83e5-8fa3fbc35872
2020-01-15 08:59:27 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=fb7aeac7-8c4a-460c-9b2f-54f20e7131e0
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(9b2f54f20e7131e0fb7aeac78c4a460c).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 641fad91-e280-4240-a8db-25facd902c8d (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 559a8576c60e23d9cf89327f8946c0a7.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission c78e57d4af6d5969a9caaf152c0a1a2c (Flink Streaming Job).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job c78e57d4af6d5969a9caaf152c0a1a2c (Flink Streaming Job).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (c78e57d4af6d5969a9caaf152c0a1a2c).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (c78e57d4af6d5969a9caaf152c0a1a2c).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (c78e57d4af6d5969a9caaf152c0a1a2c).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@30477354 @ akka://flink/user/jobmanager_1
2020-01-15 08:59:27 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (c78e57d4af6d5969a9caaf152c0a1a2c) was granted leadership with session id 156bcc91-0533-472c-ba5f-8457d0b1b734 at akka://flink/user/jobmanager_1.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (c78e57d4af6d5969a9caaf152c0a1a2c) under job master id ba5f8457d0b1b734156bcc910533472c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (c78e57d4af6d5969a9caaf152c0a1a2c) switched from state CREATED to RUNNING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) switched from CREATED to SCHEDULED.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ec7a2d5d7ebb1ae4d18f4956328bef42}]
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) switched from CREATED to SCHEDULED.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) switched from CREATED to SCHEDULED.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) switched from CREATED to SCHEDULED.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) switched from CREATED to SCHEDULED.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) switched from CREATED to SCHEDULED.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) switched from CREATED to SCHEDULED.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(9b2f54f20e7131e0fb7aeac78c4a460c)
2020-01-15 08:59:27 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=156bcc91-0533-472c-ba5f-8457d0b1b734
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager ba5f8457d0b1b734156bcc910533472c@akka://flink/user/jobmanager_1 for job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager ba5f8457d0b1b734156bcc910533472c@akka://flink/user/jobmanager_1 for job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 9b2f54f20e7131e0fb7aeac78c4a460c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ec7a2d5d7ebb1ae4d18f4956328bef42}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c78e57d4af6d5969a9caaf152c0a1a2c with allocation id 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 1baf8cd3db892d4aff03ca6d654bb348 for job c78e57d4af6d5969a9caaf152c0a1a2c from resource manager with leader id 9b2f54f20e7131e0fb7aeac78c4a460c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job c78e57d4af6d5969a9caaf152c0a1a2c for job leader monitoring.
2020-01-15 08:59:27 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 156bcc91-0533-472c-ba5f-8457d0b1b734.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{3be4c6240f85eac56695543d1b4eecc0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c78e57d4af6d5969a9caaf152c0a1a2c with allocation id 29210e65895336be1184f3930ff15f94.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{8c25cd0b800689d22d2a83bac4c2d48d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 29210e65895336be1184f3930ff15f94 for job c78e57d4af6d5969a9caaf152c0a1a2c from resource manager with leader id 9b2f54f20e7131e0fb7aeac78c4a460c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c78e57d4af6d5969a9caaf152c0a1a2c with allocation id b0f216c414a8f32ee3cd6763a05f0a72.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 29210e65895336be1184f3930ff15f94.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request b0f216c414a8f32ee3cd6763a05f0a72 for job c78e57d4af6d5969a9caaf152c0a1a2c from resource manager with leader id 9b2f54f20e7131e0fb7aeac78c4a460c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for b0f216c414a8f32ee3cd6763a05f0a72.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{45cb1ad1ea3408c8db1a3a627cadaf37}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c78e57d4af6d5969a9caaf152c0a1a2c with allocation id 8455aa9259763b5349db40fa91210642.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 8455aa9259763b5349db40fa91210642 for job c78e57d4af6d5969a9caaf152c0a1a2c from resource manager with leader id 9b2f54f20e7131e0fb7aeac78c4a460c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{69b8812751fbe74d596f023576f3b9a4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 8455aa9259763b5349db40fa91210642.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c78e57d4af6d5969a9caaf152c0a1a2c with allocation id ae7dad953843f94488032289c552bc49.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request ae7dad953843f94488032289c552bc49 for job c78e57d4af6d5969a9caaf152c0a1a2c from resource manager with leader id 9b2f54f20e7131e0fb7aeac78c4a460c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{48e6f33dae6b886928c4fbadbe277e94}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for ae7dad953843f94488032289c552bc49.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c78e57d4af6d5969a9caaf152c0a1a2c with allocation id afd6c057b5a0c82609a8c5403e07cd8e.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request afd6c057b5a0c82609a8c5403e07cd8e for job c78e57d4af6d5969a9caaf152c0a1a2c from resource manager with leader id 9b2f54f20e7131e0fb7aeac78c4a460c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for afd6c057b5a0c82609a8c5403e07cd8e.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c78e57d4af6d5969a9caaf152c0a1a2c.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [1baf8cd3db892d4aff03ca6d654bb348]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 29210e65895336be1184f3930ff15f94.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [1baf8cd3db892d4aff03ca6d654bb348]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [29210e65895336be1184f3930ff15f94]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [1baf8cd3db892d4aff03ca6d654bb348]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 29210e65895336be1184f3930ff15f94.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [29210e65895336be1184f3930ff15f94]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot b0f216c414a8f32ee3cd6763a05f0a72.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [b0f216c414a8f32ee3cd6763a05f0a72]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 8455aa9259763b5349db40fa91210642.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 29210e65895336be1184f3930ff15f94.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot b0f216c414a8f32ee3cd6763a05f0a72.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [8455aa9259763b5349db40fa91210642]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [1baf8cd3db892d4aff03ca6d654bb348]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [29210e65895336be1184f3930ff15f94]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [b0f216c414a8f32ee3cd6763a05f0a72]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 8455aa9259763b5349db40fa91210642.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [8455aa9259763b5349db40fa91210642]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [1baf8cd3db892d4aff03ca6d654bb348]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 29210e65895336be1184f3930ff15f94.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [29210e65895336be1184f3930ff15f94]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [b0f216c414a8f32ee3cd6763a05f0a72]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot b0f216c414a8f32ee3cd6763a05f0a72.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [ae7dad953843f94488032289c552bc49]. Ignoring.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot ae7dad953843f94488032289c552bc49.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to 641fad91-e280-4240-a8db-25facd902c8d @ localhost (dataPort=-1)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to 641fad91-e280-4240-a8db-25facd902c8d @ localhost (dataPort=-1)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to 641fad91-e280-4240-a8db-25facd902c8d @ localhost (dataPort=-1)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to 641fad91-e280-4240-a8db-25facd902c8d @ localhost (dataPort=-1)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to 641fad91-e280-4240-a8db-25facd902c8d @ localhost (dataPort=-1)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to 641fad91-e280-4240-a8db-25facd902c8d @ localhost (dataPort=-1)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) switched from SCHEDULED to DEPLOYING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to 641fad91-e280-4240-a8db-25facd902c8d @ localhost (dataPort=-1)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-15 08:59:27 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) switched from CREATED to DEPLOYING.
2020-01-15 08:59:27 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) [DEPLOYING]
2020-01-15 08:59:27 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) [DEPLOYING].
2020-01-15 08:59:27 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) [DEPLOYING].
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) switched from CREATED to DEPLOYING.
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) [DEPLOYING]
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) [DEPLOYING].
2020-01-15 08:59:27 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) switched from CREATED to DEPLOYING.
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) [DEPLOYING]
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) [DEPLOYING].
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) [DEPLOYING].
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (9a1acf14844b7854d133259503b46e77) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) [DEPLOYING].
2020-01-15 08:59:27 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) switched from CREATED to DEPLOYING.
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) [DEPLOYING]
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) [DEPLOYING].
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (cb4e886e0cd61af37e56fe6dae570feb) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) [DEPLOYING].
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (1be16145acda72a7f4f06b252e53dd32) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (6888206fdc848351b436828665c3fe9c) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) switched from CREATED to DEPLOYING.
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) [DEPLOYING]
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) [DEPLOYING].
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) [DEPLOYING].
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (aee46ffe9b87b85471fe62cad8db04ac) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) switched from CREATED to DEPLOYING.
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) [DEPLOYING]
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) [DEPLOYING].
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) [DEPLOYING].
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 8455aa9259763b5349db40fa91210642.
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) switched from CREATED to DEPLOYING.
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 1baf8cd3db892d4aff03ca6d654bb348.
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) [DEPLOYING]
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 29210e65895336be1184f3930ff15f94.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (0c6da11be3cea93890df6902bf78263c) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) [DEPLOYING].
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot b0f216c414a8f32ee3cd6763a05f0a72.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot ae7dad953843f94488032289c552bc49.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot afd6c057b5a0c82609a8c5403e07cd8e.
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) [DEPLOYING].
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (ae05bddbe6afdf5ce3ee11c3bbb2d6c0) switched from DEPLOYING to RUNNING.
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:59:27 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:59:27 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:59:27 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:59:27 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:59:27 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 08:59:27 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-15 08:59:27 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:59:27 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:59:27 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:59:27 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:59:27 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:59:27 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 08:59:31 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 08:59:31 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:00:28 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:00:28 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:00:28 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:00:28 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:00:28 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:00:28 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:00:28 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:00:28 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:00:29 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:00:29 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:00:29 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:00:29 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:00:29 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:40345]
2020-01-15 09:00:29 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:40345
2020-01-15 09:00:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:00:29 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:00:29 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-19b934c8-d8fa-451f-ac02-0a9820f29e42
2020-01-15 09:00:29 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:33723 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:00:29 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-c8d0c37e-1db6-4749-9708-d6b0c98cfa8b
2020-01-15 09:00:29 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-67181c71-88ef-495e-ad32-5a5347900211
2020-01-15 09:00:29 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:00:29 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 7ba69179-8879-45cb-86e2-3ab248ffccb9
2020-01-15 09:00:30 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:00:30 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-c592e6fd-9a44-4419-b181-ff6bfe96580a for spill files.
2020-01-15 09:00:30 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-1fe3a6ac-3ce8-4eee-ab9b-e1d086ee0d7d for spill files.
2020-01-15 09:00:30 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:00:30 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:00:30 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:00:30 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:00:30 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:00:30 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:00:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:00:30 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-48264e2c-0e25-485b-b5f9-e5e4dc6ebec2
2020-01-15 09:00:30 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:00:31 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:00:31 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:00:31 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:00:31 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:42253
2020-01-15 09:00:31 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@30839e44 @ http://localhost:42253
2020-01-15 09:00:31 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:42253 was granted leadership with leaderSessionID=b9983cf1-b51b-4f72-93af-620c981a1ef0
2020-01-15 09:00:31 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:42253 , session=b9983cf1-b51b-4f72-93af-620c981a1ef0
2020-01-15 09:00:31 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:00:31 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@29c2a0e0 @ akka://flink/user/resourcemanager
2020-01-15 09:00:31 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@14e0944c @ akka://flink/user/dispatcher
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 96eb0b128b85d3e5dda153ca210f4d9f
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token fa6254d0-6e85-48cd-bef0-9eb6ec65859d
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=fa6254d0-6e85-48cd-bef0-9eb6ec65859d
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=dda153ca-210f-4d9f-96eb-0b128b85d3e5
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(96eb0b128b85d3e5dda153ca210f4d9f).
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 7ba69179-8879-45cb-86e2-3ab248ffccb9 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id a501aa2975775d60f199381e7058cb27.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 9c94c84d5d16735db1af24ee89bf80d2 (Flink Streaming Job).
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 9c94c84d5d16735db1af24ee89bf80d2 (Flink Streaming Job).
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2).
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2).
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2).
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@7531148 @ akka://flink/user/jobmanager_1
2020-01-15 09:00:31 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2) was granted leadership with session id 39e3eb80-49ab-4c65-ad58-eef0b4c8cef4 at akka://flink/user/jobmanager_1.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2) under job master id ad58eef0b4c8cef439e3eb8049ab4c65.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2) switched from state CREATED to RUNNING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from CREATED to SCHEDULED.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{63377ec986dfc617eb35cc79b4e8bee0}]
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) switched from CREATED to SCHEDULED.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e417681242b176ce54e5892e25b86822}]
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from CREATED to SCHEDULED.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e4ac1fdd48f5b2e43d01a411cc0fb07a}]
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from CREATED to SCHEDULED.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2bfdd5f816a8b0ae6cc04cf15002b150}]
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from CREATED to SCHEDULED.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7b5256b906e5e92cd0122524ad8a77f6}]
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from CREATED to SCHEDULED.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{24457826f9f41bbfda6abea3c717e5c3}]
2020-01-15 09:00:31 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=39e3eb80-49ab-4c65-ad58-eef0b4c8cef4
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(96eb0b128b85d3e5dda153ca210f4d9f)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:302 - Registering job manager ad58eef0b4c8cef439e3eb8049ab4c65@akka://flink/user/jobmanager_1 for job 9c94c84d5d16735db1af24ee89bf80d2.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager ad58eef0b4c8cef439e3eb8049ab4c65@akka://flink/user/jobmanager_1 for job 9c94c84d5d16735db1af24ee89bf80d2.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 96eb0b128b85d3e5dda153ca210f4d9f.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{63377ec986dfc617eb35cc79b4e8bee0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9c94c84d5d16735db1af24ee89bf80d2 with allocation id 7ed133b178b3e9ac8dd8880d91539a60.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 7ed133b178b3e9ac8dd8880d91539a60 for job 9c94c84d5d16735db1af24ee89bf80d2 from resource manager with leader id 96eb0b128b85d3e5dda153ca210f4d9f.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e417681242b176ce54e5892e25b86822}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e4ac1fdd48f5b2e43d01a411cc0fb07a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{2bfdd5f816a8b0ae6cc04cf15002b150}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9c94c84d5d16735db1af24ee89bf80d2 with allocation id 1dc9bf6702bac52d22faad4cefe75574.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7b5256b906e5e92cd0122524ad8a77f6}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{24457826f9f41bbfda6abea3c717e5c3}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9c94c84d5d16735db1af24ee89bf80d2 with allocation id 73a72d45a274485f25e18bd6bd7a3ebc.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9c94c84d5d16735db1af24ee89bf80d2 with allocation id b4c3b2cfc329fe6099319bda7ee50fbd.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 7ed133b178b3e9ac8dd8880d91539a60.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 9c94c84d5d16735db1af24ee89bf80d2 for job leader monitoring.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 1dc9bf6702bac52d22faad4cefe75574 for job 9c94c84d5d16735db1af24ee89bf80d2 from resource manager with leader id 96eb0b128b85d3e5dda153ca210f4d9f.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 1dc9bf6702bac52d22faad4cefe75574.
2020-01-15 09:00:31 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 39e3eb80-49ab-4c65-ad58-eef0b4c8cef4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 9c94c84d5d16735db1af24ee89bf80d2 for job leader monitoring.
2020-01-15 09:00:31 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 39e3eb80-49ab-4c65-ad58-eef0b4c8cef4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 73a72d45a274485f25e18bd6bd7a3ebc for job 9c94c84d5d16735db1af24ee89bf80d2 from resource manager with leader id 96eb0b128b85d3e5dda153ca210f4d9f.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 73a72d45a274485f25e18bd6bd7a3ebc.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 9c94c84d5d16735db1af24ee89bf80d2 for job leader monitoring.
2020-01-15 09:00:31 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 39e3eb80-49ab-4c65-ad58-eef0b4c8cef4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request b4c3b2cfc329fe6099319bda7ee50fbd for job 9c94c84d5d16735db1af24ee89bf80d2 from resource manager with leader id 96eb0b128b85d3e5dda153ca210f4d9f.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9c94c84d5d16735db1af24ee89bf80d2 with allocation id 5f4fca6a320aa5d7e27a9670a87e01c4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for b4c3b2cfc329fe6099319bda7ee50fbd.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 9c94c84d5d16735db1af24ee89bf80d2 for job leader monitoring.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 9c94c84d5d16735db1af24ee89bf80d2 with allocation id fb9af385b2f45849dd0fac6a5a0c3761.
2020-01-15 09:00:31 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 39e3eb80-49ab-4c65-ad58-eef0b4c8cef4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 5f4fca6a320aa5d7e27a9670a87e01c4 for job 9c94c84d5d16735db1af24ee89bf80d2 from resource manager with leader id 96eb0b128b85d3e5dda153ca210f4d9f.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 5f4fca6a320aa5d7e27a9670a87e01c4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 9c94c84d5d16735db1af24ee89bf80d2 for job leader monitoring.
2020-01-15 09:00:31 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 39e3eb80-49ab-4c65-ad58-eef0b4c8cef4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request fb9af385b2f45849dd0fac6a5a0c3761 for job 9c94c84d5d16735db1af24ee89bf80d2 from resource manager with leader id 96eb0b128b85d3e5dda153ca210f4d9f.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for fb9af385b2f45849dd0fac6a5a0c3761.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 9c94c84d5d16735db1af24ee89bf80d2 for job leader monitoring.
2020-01-15 09:00:31 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 39e3eb80-49ab-4c65-ad58-eef0b4c8cef4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 9c94c84d5d16735db1af24ee89bf80d2.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job 9c94c84d5d16735db1af24ee89bf80d2.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 9c94c84d5d16735db1af24ee89bf80d2.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 7ba69179-8879-45cb-86e2-3ab248ffccb9 @ localhost (dataPort=-1)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 7ba69179-8879-45cb-86e2-3ab248ffccb9 @ localhost (dataPort=-1)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 7ba69179-8879-45cb-86e2-3ab248ffccb9 @ localhost (dataPort=-1)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 7ba69179-8879-45cb-86e2-3ab248ffccb9 @ localhost (dataPort=-1)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 7ba69179-8879-45cb-86e2-3ab248ffccb9 @ localhost (dataPort=-1)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 7ba69179-8879-45cb-86e2-3ab248ffccb9 @ localhost (dataPort=-1)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from CREATED to DEPLOYING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) [DEPLOYING]
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) [DEPLOYING].
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) switched from CREATED to DEPLOYING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) [DEPLOYING]
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from CREATED to DEPLOYING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) [DEPLOYING]
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 73a72d45a274485f25e18bd6bd7a3ebc.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 5f4fca6a320aa5d7e27a9670a87e01c4.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 7ed133b178b3e9ac8dd8880d91539a60.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot fb9af385b2f45849dd0fac6a5a0c3761.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 1dc9bf6702bac52d22faad4cefe75574.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot b4c3b2cfc329fe6099319bda7ee50fbd.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from CREATED to DEPLOYING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) [DEPLOYING]
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) [DEPLOYING].
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from CREATED to DEPLOYING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) [DEPLOYING]
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from CREATED to DEPLOYING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) [DEPLOYING]
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) [DEPLOYING].
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from DEPLOYING to RUNNING.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:00:32 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:00:32 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:00:32 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:00:32 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:00:32 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:00:32 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:00:32 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:960 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) [?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) [FAILED]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 845041db5e6beb1c85e1cbc89ba62bbb.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1493 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (845041db5e6beb1c85e1cbc89ba62bbb) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) [CANCELED]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) [CANCELED]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from RUNNING to CANCELING.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) [CANCELED]
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) [CANCELED]
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462).
2020-01-15 09:00:32 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) [CANCELED]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out fd254fc9693ffca4845a545b3b893ace.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 61a209b918dbbfb1449b4ee0d471140d.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 69a14fcf2de8c099e71896f22509b85f.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (fd254fc9693ffca4845a545b3b893ace) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 067d4f7fc9602d1261dc5af8357d9c29.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (61a209b918dbbfb1449b4ee0d471140d) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 66e3f5f0d86d5b9bebbbf40ae3fdb462.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (69a14fcf2de8c099e71896f22509b85f) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (067d4f7fc9602d1261dc5af8357d9c29) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (66e3f5f0d86d5b9bebbbf40ae3fdb462) switched from CANCELING to CANCELED.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1446 - Try to restart or fail the job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2) if no longer possible.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1472 - Could not restart the job Flink Streaming Job (9c94c84d5d16735db1af24ee89bf80d2) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":62"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  CheckpointCoordinator:329 - Stopping checkpoint coordinator for job 9c94c84d5d16735db1af24ee89bf80d2.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneCompletedCheckpointStore:97 - Shutting down
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:775 - Job 9c94c84d5d16735db1af24ee89bf80d2 reached globally terminal state FAILED.
2020-01-15 09:00:32 [main] INFO  MiniCluster:416 - Shutting down Flink Mini Cluster
2020-01-15 09:00:32 [main] INFO  DispatcherRestEndpoint:290 - Shutting down rest endpoint.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:339 - Stopping TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1078 - Close ResourceManager connection 7c19794211540a0fa4dca5125f8c6da7.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:805 - Closing TaskExecutor connection 7ba69179-8879-45cb-86e2-3ab248ffccb9 because: The TaskExecutor is shutting down.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:335 - Stopping the JobMaster for job Flink Streaming Job(9c94c84d5d16735db1af24ee89bf80d2).
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:228 - Suspending SlotPool.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:1010 - Close ResourceManager connection 7c19794211540a0fa4dca5125f8c6da7: JobManager is shutting down..
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:776 - Disconnect job manager ad58eef0b4c8cef439e3eb8049ab4c65@akka://flink/user/jobmanager_1 for job 9c94c84d5d16735db1af24ee89bf80d2 from the resource manager.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:249 - Stopping SlotPool.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-c592e6fd-9a44-4419-b181-ff6bfe96580a
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  NettyShuffleEnvironment:304 - Shutting down the network environment and its components.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-netty-shuffle-1fe3a6ac-3ce8-4eee-ab9b-e1d086ee0d7d
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  KvStateService:119 - Shutting down the kvState service and its components.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-48264e2c-0e25-485b-b5f9-e5e4dc6ebec2
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:379 - Stopped TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 09:00:32 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:687 - Removing cache directory /tmp/flink-web-ui
2020-01-15 09:00:32 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:299 - Shut down complete.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:499 - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:280 - Closing the SlotManager.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:220 - Stopping dispatcher akka://flink/user/dispatcher.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:243 - Suspending the SlotManager.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:697 - Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  StackTraceSampleCoordinator:220 - Shutting down stack trace sample coordinator.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:229 - Stopped dispatcher akka://flink/user/dispatcher.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 09:00:32 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Shutting down remote daemon.
2020-01-15 09:00:32 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remote daemon shut down; proceeding with flushing remote transports.
2020-01-15 09:00:32 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remoting shut down.
2020-01-15 09:00:32 [flink-metrics-2] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 09:00:32 [flink-metrics-2] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-2] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-2] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-2] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:33723
2020-01-15 09:00:32 [flink-akka.actor.default-dispatcher-2] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 09:01:54 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-15 09:01:54 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:01:54 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:01:54 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:01:54 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:01:54 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:01:55 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:01:55 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:01:55 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:01:55 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:01:55 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:37071]
2020-01-15 09:01:55 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:37071
2020-01-15 09:01:55 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:01:55 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:01:55 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-11d7a700-7ca9-4ce0-b509-b5662e45875e
2020-01-15 09:01:55 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:45171 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:01:55 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-d94ff41e-7bb7-4fcf-b736-fe4299f6bccf
2020-01-15 09:01:55 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-aad98e1b-008c-4a7e-8417-86e63f8b8001
2020-01-15 09:01:55 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:01:55 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: e739d9d8-7a00-4e11-a428-29f14153b092
2020-01-15 09:01:56 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:01:56 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-a39b50aa-3bd7-4beb-acbc-09517381f9b9 for spill files.
2020-01-15 09:01:56 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-000904bd-7a5d-4fb0-be4d-a3ada595561c for spill files.
2020-01-15 09:01:56 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:01:56 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:01:56 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:01:56 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:01:56 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:01:56 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:01:56 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:01:56 [flink-akka.actor.default-dispatcher-5] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-0c90da9f-0d55-4fca-9de0-55d47e8b6b68
2020-01-15 09:01:56 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:01:56 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:01:56 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:01:56 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:01:57 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:44197
2020-01-15 09:01:57 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@3c854752 @ http://localhost:44197
2020-01-15 09:01:57 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:44197 was granted leadership with leaderSessionID=ab1fbde2-11d5-4f5e-ad3d-27c9909f53f8
2020-01-15 09:01:57 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:44197 , session=ab1fbde2-11d5-4f5e-ad3d-27c9909f53f8
2020-01-15 09:01:57 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:01:57 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@2b243afa @ akka://flink/user/resourcemanager
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@a6d6534 @ akka://flink/user/dispatcher
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 81600b73ae00f237835ed599927c4b01
2020-01-15 09:01:57 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 13b61256-95a8-416e-9da7-c803d361fc85
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=835ed599-927c-4b01-8160-0b73ae00f237
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=13b61256-95a8-416e-9da7-c803d361fc85
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(81600b73ae00f237835ed599927c4b01).
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission 395a87dc4493174c543cec1d3961d6d4 (Flink Streaming Job).
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job 395a87dc4493174c543cec1d3961d6d4 (Flink Streaming Job).
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID e739d9d8-7a00-4e11-a428-29f14153b092 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 0a12e8be30cc01505aa8fbe674c208aa.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:241 - Initializing job Flink Streaming Job (395a87dc4493174c543cec1d3961d6d4).
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (395a87dc4493174c543cec1d3961d6d4).
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (395a87dc4493174c543cec1d3961d6d4).
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@60083a85 @ akka://flink/user/jobmanager_1
2020-01-15 09:01:57 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (395a87dc4493174c543cec1d3961d6d4) was granted leadership with session id 9b2a4850-2f2b-4bae-a151-80fa49340f85 at akka://flink/user/jobmanager_1.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (395a87dc4493174c543cec1d3961d6d4) under job master id a15180fa49340f859b2a48502f2b4bae.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (395a87dc4493174c543cec1d3961d6d4) switched from state CREATED to RUNNING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) switched from CREATED to SCHEDULED.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{980eb7f85484aa2639514ef08dfff28f}]
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) switched from CREATED to SCHEDULED.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) switched from CREATED to SCHEDULED.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) switched from CREATED to SCHEDULED.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) switched from CREATED to SCHEDULED.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) switched from CREATED to SCHEDULED.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) switched from CREATED to SCHEDULED.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(81600b73ae00f237835ed599927c4b01)
2020-01-15 09:01:57 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=9b2a4850-2f2b-4bae-a151-80fa49340f85
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager a15180fa49340f859b2a48502f2b4bae@akka://flink/user/jobmanager_1 for job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager a15180fa49340f859b2a48502f2b4bae@akka://flink/user/jobmanager_1 for job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 81600b73ae00f237835ed599927c4b01.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{980eb7f85484aa2639514ef08dfff28f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 395a87dc4493174c543cec1d3961d6d4 with allocation id e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request e43d62f15cdf27f866d2f1be4f29a6f3 for job 395a87dc4493174c543cec1d3961d6d4 from resource manager with leader id 81600b73ae00f237835ed599927c4b01.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 395a87dc4493174c543cec1d3961d6d4 for job leader monitoring.
2020-01-15 09:01:57 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9b2a4850-2f2b-4bae-a151-80fa49340f85.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{201e5a664020ba21f791daad44595a75}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5ba9646066cb86f2ec7c284a49bd6ca6}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 395a87dc4493174c543cec1d3961d6d4 with allocation id 07d0595b2710a702f372f72f86f0cbea.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{fd5fa24d7e037f7398735a9434208857}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 07d0595b2710a702f372f72f86f0cbea for job 395a87dc4493174c543cec1d3961d6d4 from resource manager with leader id 81600b73ae00f237835ed599927c4b01.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 395a87dc4493174c543cec1d3961d6d4 with allocation id 5b7b6b7ad5e60426471fa4dde4d39581.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 07d0595b2710a702f372f72f86f0cbea.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 395a87dc4493174c543cec1d3961d6d4 with allocation id 7142e6552003e3bab762aafb241e7efa.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 5b7b6b7ad5e60426471fa4dde4d39581 for job 395a87dc4493174c543cec1d3961d6d4 from resource manager with leader id 81600b73ae00f237835ed599927c4b01.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 5b7b6b7ad5e60426471fa4dde4d39581.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 7142e6552003e3bab762aafb241e7efa for job 395a87dc4493174c543cec1d3961d6d4 from resource manager with leader id 81600b73ae00f237835ed599927c4b01.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 7142e6552003e3bab762aafb241e7efa.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{33c64ff15f5848e706671d6d1bfc8055}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{6c6fc792d9eb8b82a6b1b6a113c3f284}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 395a87dc4493174c543cec1d3961d6d4 with allocation id cf3bfda47b5f0f8772f800196f04a1b3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request cf3bfda47b5f0f8772f800196f04a1b3 for job 395a87dc4493174c543cec1d3961d6d4 from resource manager with leader id 81600b73ae00f237835ed599927c4b01.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 395a87dc4493174c543cec1d3961d6d4 with allocation id 90b2f9ab75c745b3ebd86dff7a0af5cc.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for cf3bfda47b5f0f8772f800196f04a1b3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 90b2f9ab75c745b3ebd86dff7a0af5cc for job 395a87dc4493174c543cec1d3961d6d4 from resource manager with leader id 81600b73ae00f237835ed599927c4b01.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 90b2f9ab75c745b3ebd86dff7a0af5cc.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 395a87dc4493174c543cec1d3961d6d4.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e43d62f15cdf27f866d2f1be4f29a6f3]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 07d0595b2710a702f372f72f86f0cbea.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e43d62f15cdf27f866d2f1be4f29a6f3]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [07d0595b2710a702f372f72f86f0cbea]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5b7b6b7ad5e60426471fa4dde4d39581]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e43d62f15cdf27f866d2f1be4f29a6f3]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5b7b6b7ad5e60426471fa4dde4d39581.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [07d0595b2710a702f372f72f86f0cbea]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 07d0595b2710a702f372f72f86f0cbea.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5b7b6b7ad5e60426471fa4dde4d39581.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5b7b6b7ad5e60426471fa4dde4d39581]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 7142e6552003e3bab762aafb241e7efa.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [7142e6552003e3bab762aafb241e7efa]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e43d62f15cdf27f866d2f1be4f29a6f3]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 07d0595b2710a702f372f72f86f0cbea.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [07d0595b2710a702f372f72f86f0cbea]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 5b7b6b7ad5e60426471fa4dde4d39581.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot cf3bfda47b5f0f8772f800196f04a1b3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 7142e6552003e3bab762aafb241e7efa.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 07d0595b2710a702f372f72f86f0cbea.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5b7b6b7ad5e60426471fa4dde4d39581]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [cf3bfda47b5f0f8772f800196f04a1b3]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [7142e6552003e3bab762aafb241e7efa]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to e739d9d8-7a00-4e11-a428-29f14153b092 @ localhost (dataPort=-1)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to e739d9d8-7a00-4e11-a428-29f14153b092 @ localhost (dataPort=-1)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to e739d9d8-7a00-4e11-a428-29f14153b092 @ localhost (dataPort=-1)
2020-01-15 09:01:57 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) switched from CREATED to DEPLOYING.
2020-01-15 09:01:57 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) [DEPLOYING]
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to e739d9d8-7a00-4e11-a428-29f14153b092 @ localhost (dataPort=-1)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to e739d9d8-7a00-4e11-a428-29f14153b092 @ localhost (dataPort=-1)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to e739d9d8-7a00-4e11-a428-29f14153b092 @ localhost (dataPort=-1)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to e739d9d8-7a00-4e11-a428-29f14153b092 @ localhost (dataPort=-1)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e43d62f15cdf27f866d2f1be4f29a6f3]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [07d0595b2710a702f372f72f86f0cbea]. Ignoring.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-15 09:01:57 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) switched from CREATED to DEPLOYING.
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) [DEPLOYING]
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) [DEPLOYING].
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) switched from CREATED to DEPLOYING.
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) [DEPLOYING]
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) [DEPLOYING].
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) switched from CREATED to DEPLOYING.
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) [DEPLOYING]
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) [DEPLOYING].
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-15 09:01:57 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) switched from CREATED to DEPLOYING.
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) [DEPLOYING]
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) [DEPLOYING].
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (e82643e15e53a29fe919c10365b3d479) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (ee309c9e72acee3615c926ee9d10c885) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (d34ca6e819d6f1054b3606bc4f8e15a1) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) switched from CREATED to DEPLOYING.
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) [DEPLOYING]
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) [DEPLOYING].
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (aca536928f67dce3efa5dc8ef829f9d9) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (2b85fcf583ae739555d6090d9c203a66) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-15 09:01:57 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (0f719689386413453eb6752feeb96eaf) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) switched from CREATED to DEPLOYING.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 5b7b6b7ad5e60426471fa4dde4d39581.
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) [DEPLOYING]
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) [DEPLOYING].
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot cf3bfda47b5f0f8772f800196f04a1b3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 7142e6552003e3bab762aafb241e7efa.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 90b2f9ab75c745b3ebd86dff7a0af5cc.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot e43d62f15cdf27f866d2f1be4f29a6f3.
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 07d0595b2710a702f372f72f86f0cbea.
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) [DEPLOYING].
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:01:57 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (021b877578eabc788b30c9a1f8deea7f) switched from DEPLOYING to RUNNING.
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:01:57 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:01:57 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:01:57 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:01:57 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:01:57 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:01:57 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-15 09:01:57 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:01:57 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:01:57 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:01:57 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:01:57 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:01:57 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:01:59 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:01:59 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:01:59 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:01:59 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:45171
2020-01-15 09:01:59 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-0c90da9f-0d55-4fca-9de0-55d47e8b6b68
2020-01-15 09:02:35 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:02:35 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:02:35 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:02:35 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:02:35 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:02:35 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:02:35 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:02:35 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:02:36 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:02:36 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:02:36 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:02:36 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:02:36 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:46515]
2020-01-15 09:02:36 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:46515
2020-01-15 09:02:36 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:02:36 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:02:36 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-7482a9bc-6a1e-4280-a2ce-eea78a6c7189
2020-01-15 09:02:36 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:39311 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:02:36 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-64e09eca-b18f-4ce0-8bb5-1e4d0705238e
2020-01-15 09:02:36 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-7ab337e9-60b3-4a50-ac9f-01c4b67bfc85
2020-01-15 09:02:36 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:02:36 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 1bca2758-419a-4055-96b4-dceebb22a610
2020-01-15 09:02:37 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:02:37 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-40692c7c-fa0b-4338-bb1e-c3e883b930ef for spill files.
2020-01-15 09:02:37 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-e9616b7c-71cf-4563-8a02-b136de180a36 for spill files.
2020-01-15 09:02:37 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:02:37 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:02:37 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:02:37 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:02:37 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:02:37 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:02:37 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:02:37 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-b048a8f4-7ae9-4f5d-bedc-a629b7305d5d
2020-01-15 09:02:37 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:02:37 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:02:37 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:02:37 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:02:37 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:43287
2020-01-15 09:02:37 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@2f894ad9 @ http://localhost:43287
2020-01-15 09:02:37 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:43287 was granted leadership with leaderSessionID=9a07b6fe-5ce9-4de3-9a3e-03639e3a2d31
2020-01-15 09:02:37 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:43287 , session=9a07b6fe-5ce9-4de3-9a3e-03639e3a2d31
2020-01-15 09:02:37 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:02:37 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:02:37 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@4571e503 @ akka://flink/user/resourcemanager
2020-01-15 09:02:37 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@1cc5e079 @ akka://flink/user/dispatcher
2020-01-15 09:02:37 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token b05f476603d9150c0bacbebbaf7848b4
2020-01-15 09:02:37 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:02:37 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=0bacbebb-af78-48b4-b05f-476603d9150c
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token e824eb39-364e-46f2-bd8b-3b53d1981fc1
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(b05f476603d9150c0bacbebbaf7848b4).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=e824eb39-364e-46f2-bd8b-3b53d1981fc1
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 1bca2758-419a-4055-96b4-dceebb22a610 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission fce86a514320821d5a524470062d44a7 (Flink Streaming Job).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id c8499893b52bb9398f2c1e0c3acc4f98.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job fce86a514320821d5a524470062d44a7 (Flink Streaming Job).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (fce86a514320821d5a524470062d44a7).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (fce86a514320821d5a524470062d44a7).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (fce86a514320821d5a524470062d44a7).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@3f228cf @ akka://flink/user/jobmanager_1
2020-01-15 09:02:38 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (fce86a514320821d5a524470062d44a7) was granted leadership with session id 09803f4c-9aeb-49d3-89ec-971d2a45f249 at akka://flink/user/jobmanager_1.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (fce86a514320821d5a524470062d44a7) under job master id 89ec971d2a45f24909803f4c9aeb49d3.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (fce86a514320821d5a524470062d44a7) switched from state CREATED to RUNNING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from CREATED to SCHEDULED.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1915648ceb6307298e351bc523d621e2}]
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) switched from CREATED to SCHEDULED.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{de4998ff04f29533d9d33a639c597666}]
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from CREATED to SCHEDULED.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{63d9a62d488f20fea12308a445938ccb}]
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from CREATED to SCHEDULED.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e99f07c2075b07277f636ae4486ee4b9}]
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from CREATED to SCHEDULED.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{532e4229f879cae718197e1941a92ce3}]
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from CREATED to SCHEDULED.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{72bd2b343a29288bb8da77c788540954}]
2020-01-15 09:02:38 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=09803f4c-9aeb-49d3-89ec-971d2a45f249
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(b05f476603d9150c0bacbebbaf7848b4)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 89ec971d2a45f24909803f4c9aeb49d3@akka://flink/user/jobmanager_1 for job fce86a514320821d5a524470062d44a7.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager 89ec971d2a45f24909803f4c9aeb49d3@akka://flink/user/jobmanager_1 for job fce86a514320821d5a524470062d44a7.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: b05f476603d9150c0bacbebbaf7848b4.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1915648ceb6307298e351bc523d621e2}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{de4998ff04f29533d9d33a639c597666}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job fce86a514320821d5a524470062d44a7 with allocation id f278e0cad95ff175d9b849ea91b6d844.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{63d9a62d488f20fea12308a445938ccb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request f278e0cad95ff175d9b849ea91b6d844 for job fce86a514320821d5a524470062d44a7 from resource manager with leader id b05f476603d9150c0bacbebbaf7848b4.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e99f07c2075b07277f636ae4486ee4b9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job fce86a514320821d5a524470062d44a7 with allocation id 7c558fe68e255c16760c45454e38c7fc.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{532e4229f879cae718197e1941a92ce3}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job fce86a514320821d5a524470062d44a7 with allocation id ac31dfb427b1012d29553ea8dd6a1c1c.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{72bd2b343a29288bb8da77c788540954}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job fce86a514320821d5a524470062d44a7 with allocation id 281ac698deb979d69d9fe5e0ede05202.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job fce86a514320821d5a524470062d44a7 with allocation id a169b3a577e668342244c629f43faf7b.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job fce86a514320821d5a524470062d44a7 with allocation id 491fad79cd5bdd4d1ffd804b8ce2f541.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for f278e0cad95ff175d9b849ea91b6d844.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job fce86a514320821d5a524470062d44a7 for job leader monitoring.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 7c558fe68e255c16760c45454e38c7fc for job fce86a514320821d5a524470062d44a7 from resource manager with leader id b05f476603d9150c0bacbebbaf7848b4.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 7c558fe68e255c16760c45454e38c7fc.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job fce86a514320821d5a524470062d44a7 for job leader monitoring.
2020-01-15 09:02:38 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 09803f4c-9aeb-49d3-89ec-971d2a45f249.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request ac31dfb427b1012d29553ea8dd6a1c1c for job fce86a514320821d5a524470062d44a7 from resource manager with leader id b05f476603d9150c0bacbebbaf7848b4.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for ac31dfb427b1012d29553ea8dd6a1c1c.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job fce86a514320821d5a524470062d44a7 for job leader monitoring.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 281ac698deb979d69d9fe5e0ede05202 for job fce86a514320821d5a524470062d44a7 from resource manager with leader id b05f476603d9150c0bacbebbaf7848b4.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 281ac698deb979d69d9fe5e0ede05202.
2020-01-15 09:02:38 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 09803f4c-9aeb-49d3-89ec-971d2a45f249.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job fce86a514320821d5a524470062d44a7 for job leader monitoring.
2020-01-15 09:02:38 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 09803f4c-9aeb-49d3-89ec-971d2a45f249.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request a169b3a577e668342244c629f43faf7b for job fce86a514320821d5a524470062d44a7 from resource manager with leader id b05f476603d9150c0bacbebbaf7848b4.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for a169b3a577e668342244c629f43faf7b.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job fce86a514320821d5a524470062d44a7 for job leader monitoring.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:02:38 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 09803f4c-9aeb-49d3-89ec-971d2a45f249.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 491fad79cd5bdd4d1ffd804b8ce2f541 for job fce86a514320821d5a524470062d44a7 from resource manager with leader id b05f476603d9150c0bacbebbaf7848b4.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 491fad79cd5bdd4d1ffd804b8ce2f541.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job fce86a514320821d5a524470062d44a7 for job leader monitoring.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:02:38 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 09803f4c-9aeb-49d3-89ec-971d2a45f249.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job fce86a514320821d5a524470062d44a7.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job fce86a514320821d5a524470062d44a7.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job fce86a514320821d5a524470062d44a7.
2020-01-15 09:02:38 [mini-cluster-io-thread-6] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 1bca2758-419a-4055-96b4-dceebb22a610 @ localhost (dataPort=-1)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 1bca2758-419a-4055-96b4-dceebb22a610 @ localhost (dataPort=-1)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 1bca2758-419a-4055-96b4-dceebb22a610 @ localhost (dataPort=-1)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 1bca2758-419a-4055-96b4-dceebb22a610 @ localhost (dataPort=-1)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 1bca2758-419a-4055-96b4-dceebb22a610 @ localhost (dataPort=-1)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 1bca2758-419a-4055-96b4-dceebb22a610 @ localhost (dataPort=-1)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from CREATED to DEPLOYING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) [DEPLOYING]
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot f278e0cad95ff175d9b849ea91b6d844.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from CREATED to DEPLOYING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 281ac698deb979d69d9fe5e0ede05202.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot ac31dfb427b1012d29553ea8dd6a1c1c.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 7c558fe68e255c16760c45454e38c7fc.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 491fad79cd5bdd4d1ffd804b8ce2f541.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot a169b3a577e668342244c629f43faf7b.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) [DEPLOYING]
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) switched from CREATED to DEPLOYING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) [DEPLOYING]
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) [DEPLOYING].
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) [DEPLOYING].
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from CREATED to DEPLOYING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) [DEPLOYING]
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) [DEPLOYING].
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from CREATED to DEPLOYING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) [DEPLOYING]
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from CREATED to DEPLOYING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) [DEPLOYING]
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) [DEPLOYING].
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:02:38 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from DEPLOYING to RUNNING.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:02:38 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:02:38 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:02:38 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:02:38 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:02:38 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:02:38 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:38 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:02:39 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:960 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) [?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) [FAILED]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 5a2ffc1808011257ffa1d1b15ebe6919.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1493 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (5a2ffc1808011257ffa1d1b15ebe6919) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (fce86a514320821d5a524470062d44a7) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) [CANCELED]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) [CANCELED]
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) [CANCELED]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from RUNNING to CANCELING.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) [CANCELED]
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4).
2020-01-15 09:02:39 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) [CANCELED]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 8921da8b8629f7732110d208eb7ad7f4.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out a1a912ae30dbac92e998b049597b52fd.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out ea1a6e91cccdd6bd4f9244421a47fa99.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (8921da8b8629f7732110d208eb7ad7f4) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 49e8e31f2279f75975d5e05e2177eb7a.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out bb41bc52fee3d91bf33a5bc302d7a0d4.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a1a912ae30dbac92e998b049597b52fd) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (ea1a6e91cccdd6bd4f9244421a47fa99) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (49e8e31f2279f75975d5e05e2177eb7a) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (bb41bc52fee3d91bf33a5bc302d7a0d4) switched from CANCELING to CANCELED.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1446 - Try to restart or fail the job Flink Streaming Job (fce86a514320821d5a524470062d44a7) if no longer possible.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (fce86a514320821d5a524470062d44a7) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1472 - Could not restart the job Flink Streaming Job (fce86a514320821d5a524470062d44a7) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":94"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  CheckpointCoordinator:329 - Stopping checkpoint coordinator for job fce86a514320821d5a524470062d44a7.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneCompletedCheckpointStore:97 - Shutting down
2020-01-15 09:02:39 [main] INFO  MiniCluster:416 - Shutting down Flink Mini Cluster
2020-01-15 09:02:39 [main] INFO  DispatcherRestEndpoint:290 - Shutting down rest endpoint.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:339 - Stopping TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1078 - Close ResourceManager connection b4fefacc626ce35a872074f8effcbea9.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:805 - Closing TaskExecutor connection 1bca2758-419a-4055-96b4-dceebb22a610 because: The TaskExecutor is shutting down.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:775 - Job fce86a514320821d5a524470062d44a7 reached globally terminal state FAILED.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-40692c7c-fa0b-4338-bb1e-c3e883b930ef
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  NettyShuffleEnvironment:304 - Shutting down the network environment and its components.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:335 - Stopping the JobMaster for job Flink Streaming Job(fce86a514320821d5a524470062d44a7).
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:228 - Suspending SlotPool.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:1010 - Close ResourceManager connection b4fefacc626ce35a872074f8effcbea9: JobManager is shutting down..
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:249 - Stopping SlotPool.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:776 - Disconnect job manager 89ec971d2a45f24909803f4c9aeb49d3@akka://flink/user/jobmanager_1 for job fce86a514320821d5a524470062d44a7 from the resource manager.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-netty-shuffle-e9616b7c-71cf-4563-8a02-b136de180a36
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  KvStateService:119 - Shutting down the kvState service and its components.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-b048a8f4-7ae9-4f5d-bedc-a629b7305d5d
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:379 - Stopped TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 09:02:39 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:687 - Removing cache directory /tmp/flink-web-ui
2020-01-15 09:02:39 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:299 - Shut down complete.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:499 - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:220 - Stopping dispatcher akka://flink/user/dispatcher.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:697 - Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  StackTraceSampleCoordinator:220 - Shutting down stack trace sample coordinator.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:229 - Stopped dispatcher akka://flink/user/dispatcher.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:280 - Closing the SlotManager.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:243 - Suspending the SlotManager.
2020-01-15 09:02:39 [ForkJoinPool.commonPool-worker-3] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 09:02:39 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Shutting down remote daemon.
2020-01-15 09:02:39 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remote daemon shut down; proceeding with flushing remote transports.
2020-01-15 09:02:39 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remoting shut down.
2020-01-15 09:02:39 [flink-metrics-2] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 09:02:39 [flink-metrics-2] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:39311
2020-01-15 09:02:39 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 09:03:34 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-15 09:03:34 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:03:34 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:03:34 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:03:34 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:03:34 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:03:35 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:03:35 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:03:35 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:03:35 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:03:35 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:37443]
2020-01-15 09:03:35 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:37443
2020-01-15 09:03:35 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:03:35 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:03:35 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-4012b05f-65cd-4652-b240-9f9635c9c54f
2020-01-15 09:03:35 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:34259 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:03:35 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-cee6ed8c-6d19-4072-8bbb-6cb9e3ffd532
2020-01-15 09:03:35 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-9fe8037a-054a-448a-a83b-9d43bd020e6c
2020-01-15 09:03:35 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:03:35 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 8a142df3-270a-4c9c-ade8-9f517774a860
2020-01-15 09:03:35 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:03:35 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-3e2f1744-b29d-453f-bba1-7c4bdf72f6a2 for spill files.
2020-01-15 09:03:35 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-8f8615ed-4bf7-4797-84b1-8c8ec1b06e7b for spill files.
2020-01-15 09:03:36 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:03:36 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:03:36 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:03:36 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:03:36 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:03:36 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-51c44803-b741-47c2-8240-07ab8e0322c7
2020-01-15 09:03:36 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:03:36 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:03:36 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:03:36 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:03:36 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:40885
2020-01-15 09:03:36 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@1a500561 @ http://localhost:40885
2020-01-15 09:03:36 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:40885 was granted leadership with leaderSessionID=d67691a3-4b14-49e1-bbcd-7982edee83b1
2020-01-15 09:03:36 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:40885 , session=d67691a3-4b14-49e1-bbcd-7982edee83b1
2020-01-15 09:03:36 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:03:36 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@49a8c9ea @ akka://flink/user/resourcemanager
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@3a263938 @ akka://flink/user/dispatcher
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token b90da8f5e75762bee012fcd1c38f4a03
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=e012fcd1-c38f-4a03-b90d-a8f5e75762be
2020-01-15 09:03:36 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token f41b2b36-2dd6-40fd-8525-36b9f39ae57c
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(b90da8f5e75762bee012fcd1c38f4a03).
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=f41b2b36-2dd6-40fd-8525-36b9f39ae57c
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission ee0f65a0b3785129df278a76ee8fed95 (Flink Streaming Job).
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 8a142df3-270a-4c9c-ade8-9f517774a860 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job ee0f65a0b3785129df278a76ee8fed95 (Flink Streaming Job).
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 1c4837f47df181bcc7a86ad8d1a597c8.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (ee0f65a0b3785129df278a76ee8fed95).
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (ee0f65a0b3785129df278a76ee8fed95).
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (ee0f65a0b3785129df278a76ee8fed95).
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@12b2de4 @ akka://flink/user/jobmanager_1
2020-01-15 09:03:36 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (ee0f65a0b3785129df278a76ee8fed95) was granted leadership with session id 3de597dc-85b3-4938-a301-1eedee6779bc at akka://flink/user/jobmanager_1.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (ee0f65a0b3785129df278a76ee8fed95) under job master id a3011eedee6779bc3de597dc85b34938.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (ee0f65a0b3785129df278a76ee8fed95) switched from state CREATED to RUNNING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) switched from CREATED to SCHEDULED.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{82bb4d5c5ea98438c312d2ab1f5b1fa5}]
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) switched from CREATED to SCHEDULED.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) switched from CREATED to SCHEDULED.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) switched from CREATED to SCHEDULED.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) switched from CREATED to SCHEDULED.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) switched from CREATED to SCHEDULED.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) switched from CREATED to SCHEDULED.
2020-01-15 09:03:36 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=3de597dc-85b3-4938-a301-1eedee6779bc
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(b90da8f5e75762bee012fcd1c38f4a03)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:302 - Registering job manager a3011eedee6779bc3de597dc85b34938@akka://flink/user/jobmanager_1 for job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager a3011eedee6779bc3de597dc85b34938@akka://flink/user/jobmanager_1 for job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: b90da8f5e75762bee012fcd1c38f4a03.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{82bb4d5c5ea98438c312d2ab1f5b1fa5}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee0f65a0b3785129df278a76ee8fed95 with allocation id 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 066d09e31336b0c5cad0ebb9ea8eb6fb for job ee0f65a0b3785129df278a76ee8fed95 from resource manager with leader id b90da8f5e75762bee012fcd1c38f4a03.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job ee0f65a0b3785129df278a76ee8fed95 for job leader monitoring.
2020-01-15 09:03:36 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3de597dc-85b3-4938-a301-1eedee6779bc.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f0fb5074b3f1ef321c5b9c9558150d39}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee0f65a0b3785129df278a76ee8fed95 with allocation id db54490dc1f90731a2e4261974cf8a22.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{211a25f829beb65c04f04f84f4d26df3}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request db54490dc1f90731a2e4261974cf8a22 for job ee0f65a0b3785129df278a76ee8fed95 from resource manager with leader id b90da8f5e75762bee012fcd1c38f4a03.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee0f65a0b3785129df278a76ee8fed95 with allocation id f448c34bb7632a589c968f8602711d39.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for db54490dc1f90731a2e4261974cf8a22.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e1a1fe5ca42ac30fbd3c77071785c922}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee0f65a0b3785129df278a76ee8fed95 with allocation id 288393385935e64a6b9a5a363e27628f.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ebef8f69d02a3e3e0676ef5cf981e8ed}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request f448c34bb7632a589c968f8602711d39 for job ee0f65a0b3785129df278a76ee8fed95 from resource manager with leader id b90da8f5e75762bee012fcd1c38f4a03.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for f448c34bb7632a589c968f8602711d39.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{13450d1b9989182f941d58509c3b8eb9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee0f65a0b3785129df278a76ee8fed95 with allocation id 25816154d7ee32d00e0c44555a8650de.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 288393385935e64a6b9a5a363e27628f for job ee0f65a0b3785129df278a76ee8fed95 from resource manager with leader id b90da8f5e75762bee012fcd1c38f4a03.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee0f65a0b3785129df278a76ee8fed95 with allocation id 8ade2f8167490f0cb59a42fa96866964.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 288393385935e64a6b9a5a363e27628f.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 25816154d7ee32d00e0c44555a8650de for job ee0f65a0b3785129df278a76ee8fed95 from resource manager with leader id b90da8f5e75762bee012fcd1c38f4a03.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 25816154d7ee32d00e0c44555a8650de.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 8ade2f8167490f0cb59a42fa96866964 for job ee0f65a0b3785129df278a76ee8fed95 from resource manager with leader id b90da8f5e75762bee012fcd1c38f4a03.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [066d09e31336b0c5cad0ebb9ea8eb6fb]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 8ade2f8167490f0cb59a42fa96866964.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [066d09e31336b0c5cad0ebb9ea8eb6fb]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job ee0f65a0b3785129df278a76ee8fed95.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [db54490dc1f90731a2e4261974cf8a22]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [f448c34bb7632a589c968f8602711d39]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [066d09e31336b0c5cad0ebb9ea8eb6fb]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot db54490dc1f90731a2e4261974cf8a22.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [db54490dc1f90731a2e4261974cf8a22]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [f448c34bb7632a589c968f8602711d39]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot f448c34bb7632a589c968f8602711d39.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [288393385935e64a6b9a5a363e27628f]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [066d09e31336b0c5cad0ebb9ea8eb6fb]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot db54490dc1f90731a2e4261974cf8a22.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [db54490dc1f90731a2e4261974cf8a22]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot f448c34bb7632a589c968f8602711d39.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 288393385935e64a6b9a5a363e27628f.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [f448c34bb7632a589c968f8602711d39]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [288393385935e64a6b9a5a363e27628f]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot db54490dc1f90731a2e4261974cf8a22.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot f448c34bb7632a589c968f8602711d39.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 288393385935e64a6b9a5a363e27628f.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to 8a142df3-270a-4c9c-ade8-9f517774a860 @ localhost (dataPort=-1)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot db54490dc1f90731a2e4261974cf8a22.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 25816154d7ee32d00e0c44555a8650de.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to 8a142df3-270a-4c9c-ade8-9f517774a860 @ localhost (dataPort=-1)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to 8a142df3-270a-4c9c-ade8-9f517774a860 @ localhost (dataPort=-1)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to 8a142df3-270a-4c9c-ade8-9f517774a860 @ localhost (dataPort=-1)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to 8a142df3-270a-4c9c-ade8-9f517774a860 @ localhost (dataPort=-1)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to 8a142df3-270a-4c9c-ade8-9f517774a860 @ localhost (dataPort=-1)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to 8a142df3-270a-4c9c-ade8-9f517774a860 @ localhost (dataPort=-1)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [066d09e31336b0c5cad0ebb9ea8eb6fb]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [db54490dc1f90731a2e4261974cf8a22]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [25816154d7ee32d00e0c44555a8650de]. Ignoring.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-15 09:03:36 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) switched from CREATED to DEPLOYING.
2020-01-15 09:03:36 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) [DEPLOYING]
2020-01-15 09:03:36 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) [DEPLOYING].
2020-01-15 09:03:36 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) [DEPLOYING].
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) switched from CREATED to DEPLOYING.
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) [DEPLOYING]
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) [DEPLOYING].
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-15 09:03:36 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) [DEPLOYING].
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (751d9c8df4da06a8fdf0caf34d2035f0) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) switched from CREATED to DEPLOYING.
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) [DEPLOYING]
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) [DEPLOYING].
2020-01-15 09:03:36 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (772a34e41ec6a02ec9b56d9bf42a8e0a) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) switched from CREATED to DEPLOYING.
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) [DEPLOYING]
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) [DEPLOYING].
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (17b80958f3560afd4f4224ed8d86f403) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot f448c34bb7632a589c968f8602711d39.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 288393385935e64a6b9a5a363e27628f.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 8ade2f8167490f0cb59a42fa96866964.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 066d09e31336b0c5cad0ebb9ea8eb6fb.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot db54490dc1f90731a2e4261974cf8a22.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 25816154d7ee32d00e0c44555a8650de.
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (283a42f08e718aac86d072b0f6ca7a05) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) switched from CREATED to DEPLOYING.
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) [DEPLOYING]
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (0fda0b887fabbb09194891f2e0f09e83) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) switched from CREATED to DEPLOYING.
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) [DEPLOYING]
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) switched from CREATED to DEPLOYING.
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) [DEPLOYING]
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (880c22b67f4975ee94b46c42b53e1d4f) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) [DEPLOYING].
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:03:36 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:03:36 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (9c1653e699cfc5de2ada9d539a376721) switched from DEPLOYING to RUNNING.
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:03:36 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-15 09:03:36 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:03:36 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:03:36 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:03:37 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:03:37 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:03:37 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:03:37 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:03:37 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:03:37 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:03:37 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:03:37 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-15 09:03:37 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:03:37 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-15 09:03:37 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:03:37 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-15 09:03:37 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:03:37 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:03:37 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-15 09:03:37 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:03:37 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:03:37 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-15 09:03:37 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:03:37 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:03:37 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-15 09:03:37 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:03:37 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:03:37 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:03:37 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:03:37 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:03:37 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:03:43 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:03:43 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-51c44803-b741-47c2-8240-07ab8e0322c7
2020-01-15 09:03:43 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:34259
2020-01-15 09:03:43 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:03:43 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:03:43 [IOManagerAsync shutdown hook] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-3e2f1744-b29d-453f-bba1-7c4bdf72f6a2
2020-01-15 09:04:05 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-15 09:04:06 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:04:06 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:04:06 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:04:06 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:04:06 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:04:06 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:04:07 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:04:07 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:04:07 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:04:07 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:37297]
2020-01-15 09:04:07 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:37297
2020-01-15 09:04:07 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:04:07 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:04:07 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-f73a57bc-3e4c-4085-a136-3d01bce035a1
2020-01-15 09:04:07 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:46013 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:04:07 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-69b220c1-313c-4978-8503-d8f3de8718d3
2020-01-15 09:04:07 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-ae09ac35-9f68-45c2-bf96-da4b10960327
2020-01-15 09:04:07 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:04:07 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 729239bb-3204-4526-b0a9-c22afe425504
2020-01-15 09:04:07 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:04:07 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-9bda5706-f2d8-446d-a213-a17ecd265840 for spill files.
2020-01-15 09:04:07 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-16afb9b2-c76d-4924-a980-4fd8940edf4e for spill files.
2020-01-15 09:04:07 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:04:07 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:04:07 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:04:07 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:04:07 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:04:07 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:04:07 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:04:07 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-41857062-4e1e-447d-9264-34466c4e427d
2020-01-15 09:04:07 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:04:08 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:04:08 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:04:08 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:04:08 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:37153
2020-01-15 09:04:08 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@3c854752 @ http://localhost:37153
2020-01-15 09:04:08 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:37153 was granted leadership with leaderSessionID=5e39b592-9609-45a3-9eb1-86a9af8aea3f
2020-01-15 09:04:08 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:37153 , session=5e39b592-9609-45a3-9eb1-86a9af8aea3f
2020-01-15 09:04:08 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:04:08 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@1dfa79a @ akka://flink/user/resourcemanager
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@4807ce8f @ akka://flink/user/dispatcher
2020-01-15 09:04:08 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9bb3d6c20ed7b83238535f11b15e426d
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token af74e4aa-9295-47f1-b8e0-490fb1d3fd96
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=38535f11-b15e-426d-9bb3-d6c20ed7b832
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(9bb3d6c20ed7b83238535f11b15e426d).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=af74e4aa-9295-47f1-b8e0-490fb1d3fd96
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 0d271fd52b672fd21f4dba6ed0feaa18 (Flink Streaming Job).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 0d271fd52b672fd21f4dba6ed0feaa18 (Flink Streaming Job).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 729239bb-3204-4526-b0a9-c22afe425504 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id b4c67a9174e62b993d777887d237dd80.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:241 - Initializing job Flink Streaming Job (0d271fd52b672fd21f4dba6ed0feaa18).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (0d271fd52b672fd21f4dba6ed0feaa18).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (0d271fd52b672fd21f4dba6ed0feaa18).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@75fe4ccb @ akka://flink/user/jobmanager_1
2020-01-15 09:04:08 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (0d271fd52b672fd21f4dba6ed0feaa18) was granted leadership with session id 3285332f-9ef3-4414-9ca6-44ef0f4f896a at akka://flink/user/jobmanager_1.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (0d271fd52b672fd21f4dba6ed0feaa18) under job master id 9ca644ef0f4f896a3285332f9ef34414.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (0d271fd52b672fd21f4dba6ed0feaa18) switched from state CREATED to RUNNING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) switched from CREATED to SCHEDULED.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f75d0cc95ef8711659b422533524ad10}]
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) switched from CREATED to SCHEDULED.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) switched from CREATED to SCHEDULED.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) switched from CREATED to SCHEDULED.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) switched from CREATED to SCHEDULED.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) switched from CREATED to SCHEDULED.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) switched from CREATED to SCHEDULED.
2020-01-15 09:04:08 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=3285332f-9ef3-4414-9ca6-44ef0f4f896a
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(9bb3d6c20ed7b83238535f11b15e426d)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager 9ca644ef0f4f896a3285332f9ef34414@akka://flink/user/jobmanager_1 for job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager 9ca644ef0f4f896a3285332f9ef34414@akka://flink/user/jobmanager_1 for job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 9bb3d6c20ed7b83238535f11b15e426d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f75d0cc95ef8711659b422533524ad10}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d271fd52b672fd21f4dba6ed0feaa18 with allocation id af4fad55ab28ceb93cfe86184e5d9142.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request af4fad55ab28ceb93cfe86184e5d9142 for job 0d271fd52b672fd21f4dba6ed0feaa18 from resource manager with leader id 9bb3d6c20ed7b83238535f11b15e426d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for af4fad55ab28ceb93cfe86184e5d9142.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 0d271fd52b672fd21f4dba6ed0feaa18 for job leader monitoring.
2020-01-15 09:04:08 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3285332f-9ef3-4414-9ca6-44ef0f4f896a.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{bb061b616ef3b6b17c4aae015972ea21}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{02d563195f63eb4f640be8eab8f4663e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d271fd52b672fd21f4dba6ed0feaa18 with allocation id 9b235b4f5221f31e3687700d4ffa7a78.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{485747d9d48010d2f6098f49f5c064fc}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 9b235b4f5221f31e3687700d4ffa7a78 for job 0d271fd52b672fd21f4dba6ed0feaa18 from resource manager with leader id 9bb3d6c20ed7b83238535f11b15e426d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{602208981127ce4206455f0d20cb1d26}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{eb845f415f2a9663799176edcad0e44b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 9b235b4f5221f31e3687700d4ffa7a78.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d271fd52b672fd21f4dba6ed0feaa18 with allocation id eb3b5a03242d579a6d5e28d8678a96bb.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [af4fad55ab28ceb93cfe86184e5d9142]. Ignoring.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot af4fad55ab28ceb93cfe86184e5d9142.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot af4fad55ab28ceb93cfe86184e5d9142.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d271fd52b672fd21f4dba6ed0feaa18 with allocation id 5a778360d4c1747d8fe79c3bd27d1a5d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d271fd52b672fd21f4dba6ed0feaa18 with allocation id f861ceb74359719e065fcd8324662c45.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d271fd52b672fd21f4dba6ed0feaa18 with allocation id 7d2f37db9d9501782cacd9876bb96f44.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 9b235b4f5221f31e3687700d4ffa7a78.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request eb3b5a03242d579a6d5e28d8678a96bb for job 0d271fd52b672fd21f4dba6ed0feaa18 from resource manager with leader id 9bb3d6c20ed7b83238535f11b15e426d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for eb3b5a03242d579a6d5e28d8678a96bb.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 5a778360d4c1747d8fe79c3bd27d1a5d for job 0d271fd52b672fd21f4dba6ed0feaa18 from resource manager with leader id 9bb3d6c20ed7b83238535f11b15e426d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 5a778360d4c1747d8fe79c3bd27d1a5d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [eb3b5a03242d579a6d5e28d8678a96bb]. Ignoring.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request f861ceb74359719e065fcd8324662c45 for job 0d271fd52b672fd21f4dba6ed0feaa18 from resource manager with leader id 9bb3d6c20ed7b83238535f11b15e426d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for f861ceb74359719e065fcd8324662c45.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [eb3b5a03242d579a6d5e28d8678a96bb]. Ignoring.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5a778360d4c1747d8fe79c3bd27d1a5d]. Ignoring.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 7d2f37db9d9501782cacd9876bb96f44 for job 0d271fd52b672fd21f4dba6ed0feaa18 from resource manager with leader id 9bb3d6c20ed7b83238535f11b15e426d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 7d2f37db9d9501782cacd9876bb96f44.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0d271fd52b672fd21f4dba6ed0feaa18.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [eb3b5a03242d579a6d5e28d8678a96bb]. Ignoring.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [f861ceb74359719e065fcd8324662c45]. Ignoring.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot eb3b5a03242d579a6d5e28d8678a96bb.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:618 - Received repeated offer for slot [5a778360d4c1747d8fe79c3bd27d1a5d]. Ignoring.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot eb3b5a03242d579a6d5e28d8678a96bb.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5a778360d4c1747d8fe79c3bd27d1a5d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot eb3b5a03242d579a6d5e28d8678a96bb.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to 729239bb-3204-4526-b0a9-c22afe425504 @ localhost (dataPort=-1)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot f861ceb74359719e065fcd8324662c45.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5a778360d4c1747d8fe79c3bd27d1a5d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to 729239bb-3204-4526-b0a9-c22afe425504 @ localhost (dataPort=-1)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to 729239bb-3204-4526-b0a9-c22afe425504 @ localhost (dataPort=-1)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to 729239bb-3204-4526-b0a9-c22afe425504 @ localhost (dataPort=-1)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to 729239bb-3204-4526-b0a9-c22afe425504 @ localhost (dataPort=-1)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to 729239bb-3204-4526-b0a9-c22afe425504 @ localhost (dataPort=-1)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to 729239bb-3204-4526-b0a9-c22afe425504 @ localhost (dataPort=-1)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-15 09:04:08 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) switched from CREATED to DEPLOYING.
2020-01-15 09:04:08 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) [DEPLOYING]
2020-01-15 09:04:08 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) [DEPLOYING].
2020-01-15 09:04:08 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) [DEPLOYING].
2020-01-15 09:04:08 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (7367f0d5545f59c8af0916c047f4f6fa) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) switched from CREATED to DEPLOYING.
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) [DEPLOYING]
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (c98c29800d9b903f6c792ccc78c25065) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) switched from CREATED to DEPLOYING.
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) [DEPLOYING]
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) switched from CREATED to DEPLOYING.
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) [DEPLOYING]
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) switched from CREATED to DEPLOYING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot eb3b5a03242d579a6d5e28d8678a96bb.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot f861ceb74359719e065fcd8324662c45.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 5a778360d4c1747d8fe79c3bd27d1a5d.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 7d2f37db9d9501782cacd9876bb96f44.
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (efc94d3b51bf8d28a815a7e95376fce5) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) [DEPLOYING]
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (a379bccbac48632bc4b42fc7b68dfa6c) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (d28fb00d13eab1e5c736c66cf1af4517) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) switched from CREATED to DEPLOYING.
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) switched from CREATED to DEPLOYING.
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) [DEPLOYING]
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (5596ebbfb4c264d2e6c685c24afa6919) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) [DEPLOYING]
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) [DEPLOYING].
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:08 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (501cff87355c9eeb1b9a46075c76f553) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:08 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:08 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:08 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:08 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:08 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:08 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-15 09:04:08 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:08 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:08 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:08 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:08 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:08 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:10 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:04:10 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:04:10 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:46013
2020-01-15 09:04:10 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:04:31 [main] WARN  FlinkKafkaProducer:667 - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-01-15 09:04:32 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:04:32 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:04:32 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:04:32 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:04:32 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:04:32 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:04:32 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:04:33 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:04:33 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:04:33 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:42509]
2020-01-15 09:04:33 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:42509
2020-01-15 09:04:33 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:04:33 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:04:33 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-6f4c8c30-62e4-458e-85d3-85ead6290013
2020-01-15 09:04:33 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:39871 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:04:33 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-5b986659-b299-466f-b3f3-e05fbb8e943d
2020-01-15 09:04:33 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-5688535a-9be9-486f-a630-6bb65ed8d0f6
2020-01-15 09:04:33 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:04:33 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: e8e7db5e-cff6-4c33-b054-8609cf3229ee
2020-01-15 09:04:33 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:04:33 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-8030d3bb-e474-44ef-9ae4-5fd5516cfa81 for spill files.
2020-01-15 09:04:33 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-419b101b-ea05-46de-a4fc-09f17c36b124 for spill files.
2020-01-15 09:04:34 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:04:34 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:04:34 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:04:34 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:04:34 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:04:34 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-5a410b98-52fa-4fc1-be82-28ca6d6d2afa
2020-01-15 09:04:34 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:04:34 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:04:34 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:04:34 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:04:34 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:41057
2020-01-15 09:04:34 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@210d2a6c @ http://localhost:41057
2020-01-15 09:04:34 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:41057 was granted leadership with leaderSessionID=fb7ea7af-aad7-4406-8e92-4bc4c3e88744
2020-01-15 09:04:34 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:41057 , session=fb7ea7af-aad7-4406-8e92-4bc4c3e88744
2020-01-15 09:04:34 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:04:34 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@18c20191 @ akka://flink/user/resourcemanager
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@29dea1bb @ akka://flink/user/dispatcher
2020-01-15 09:04:34 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 86a12c91f38e8cfaf04d889464aa4077
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-4] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token a17b0c39-9087-40c1-88a1-506838b38d88
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=f04d8894-64aa-4077-86a1-2c91f38e8cfa
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(86a12c91f38e8cfaf04d889464aa4077).
2020-01-15 09:04:34 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=a17b0c39-9087-40c1-88a1-506838b38d88
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID e8e7db5e-cff6-4c33-b054-8609cf3229ee (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id a9d2a67f7619f32f3d182d6e5d1bebfc.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission c020f79f37ee622eef705630ffed608a (Flink Streaming Job).
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job c020f79f37ee622eef705630ffed608a (Flink Streaming Job).
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (c020f79f37ee622eef705630ffed608a).
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (c020f79f37ee622eef705630ffed608a).
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (c020f79f37ee622eef705630ffed608a).
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@6cc303b9 @ akka://flink/user/jobmanager_1
2020-01-15 09:04:35 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (c020f79f37ee622eef705630ffed608a) was granted leadership with session id 83ae578b-9139-47d5-ac29-f3f154dae9b0 at akka://flink/user/jobmanager_1.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (c020f79f37ee622eef705630ffed608a) under job master id ac29f3f154dae9b083ae578b913947d5.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (c020f79f37ee622eef705630ffed608a) switched from state CREATED to RUNNING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) switched from CREATED to SCHEDULED.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9dd83a8f010dc7cd6b6858ba41443764}]
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) switched from CREATED to SCHEDULED.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) switched from CREATED to SCHEDULED.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) switched from CREATED to SCHEDULED.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) switched from CREATED to SCHEDULED.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) switched from CREATED to SCHEDULED.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) switched from CREATED to SCHEDULED.
2020-01-15 09:04:35 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=83ae578b-9139-47d5-ac29-f3f154dae9b0
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(86a12c91f38e8cfaf04d889464aa4077)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager ac29f3f154dae9b083ae578b913947d5@akka://flink/user/jobmanager_1 for job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager ac29f3f154dae9b083ae578b913947d5@akka://flink/user/jobmanager_1 for job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 86a12c91f38e8cfaf04d889464aa4077.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{9dd83a8f010dc7cd6b6858ba41443764}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c020f79f37ee622eef705630ffed608a with allocation id e63688ed4883cbb1966ea704041782db.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request e63688ed4883cbb1966ea704041782db for job c020f79f37ee622eef705630ffed608a from resource manager with leader id 86a12c91f38e8cfaf04d889464aa4077.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for e63688ed4883cbb1966ea704041782db.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job c020f79f37ee622eef705630ffed608a for job leader monitoring.
2020-01-15 09:04:35 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 83ae578b-9139-47d5-ac29-f3f154dae9b0.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ea78c82254eae2eafbabef582c7c0237}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c020f79f37ee622eef705630ffed608a with allocation id 7b933837e2a6bb2727ece472a84940d1.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{8c3f1931d8cfa61aea0d0bd3bbbe39bf}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 7b933837e2a6bb2727ece472a84940d1 for job c020f79f37ee622eef705630ffed608a from resource manager with leader id 86a12c91f38e8cfaf04d889464aa4077.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ac834dda0823d6c180d8f4727a12240f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 7b933837e2a6bb2727ece472a84940d1.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{724c705082a464aa24af729315287515}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{9b203da01ce92f107f5be8be95b08d1c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c020f79f37ee622eef705630ffed608a with allocation id ce6b17d52d9adb22c8c8cff396c21301.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request ce6b17d52d9adb22c8c8cff396c21301 for job c020f79f37ee622eef705630ffed608a from resource manager with leader id 86a12c91f38e8cfaf04d889464aa4077.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for ce6b17d52d9adb22c8c8cff396c21301.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e63688ed4883cbb1966ea704041782db]. Ignoring.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot e63688ed4883cbb1966ea704041782db.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [e63688ed4883cbb1966ea704041782db]. Ignoring.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:618 - Received repeated offer for slot [7b933837e2a6bb2727ece472a84940d1]. Ignoring.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c020f79f37ee622eef705630ffed608a with allocation id 6bb6712b3909de9c0cbe59bc1b673a2a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot e63688ed4883cbb1966ea704041782db.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 7b933837e2a6bb2727ece472a84940d1.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot ce6b17d52d9adb22c8c8cff396c21301.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot e63688ed4883cbb1966ea704041782db.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 7b933837e2a6bb2727ece472a84940d1.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 6bb6712b3909de9c0cbe59bc1b673a2a for job c020f79f37ee622eef705630ffed608a from resource manager with leader id 86a12c91f38e8cfaf04d889464aa4077.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 6bb6712b3909de9c0cbe59bc1b673a2a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c020f79f37ee622eef705630ffed608a with allocation id 743d20eadbbf48f2150c72d480b7c989.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 743d20eadbbf48f2150c72d480b7c989 for job c020f79f37ee622eef705630ffed608a from resource manager with leader id 86a12c91f38e8cfaf04d889464aa4077.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 743d20eadbbf48f2150c72d480b7c989.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c020f79f37ee622eef705630ffed608a with allocation id 2d7585c248bab0ff46d12cd62e299803.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:618 - Received repeated offer for slot [6bb6712b3909de9c0cbe59bc1b673a2a]. Ignoring.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 6bb6712b3909de9c0cbe59bc1b673a2a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 2d7585c248bab0ff46d12cd62e299803 for job c020f79f37ee622eef705630ffed608a from resource manager with leader id 86a12c91f38e8cfaf04d889464aa4077.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 2d7585c248bab0ff46d12cd62e299803.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c020f79f37ee622eef705630ffed608a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:618 - Received repeated offer for slot [743d20eadbbf48f2150c72d480b7c989]. Ignoring.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source (1/1) (attempt #0) to e8e7db5e-cff6-4c33-b054-8609cf3229ee @ localhost (dataPort=-1)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 743d20eadbbf48f2150c72d480b7c989.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 6bb6712b3909de9c0cbe59bc1b673a2a.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (1/6) (attempt #0) to e8e7db5e-cff6-4c33-b054-8609cf3229ee @ localhost (dataPort=-1)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (2/6) (attempt #0) to e8e7db5e-cff6-4c33-b054-8609cf3229ee @ localhost (dataPort=-1)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (3/6) (attempt #0) to e8e7db5e-cff6-4c33-b054-8609cf3229ee @ localhost (dataPort=-1)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (4/6) (attempt #0) to e8e7db5e-cff6-4c33-b054-8609cf3229ee @ localhost (dataPort=-1)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (5/6) (attempt #0) to e8e7db5e-cff6-4c33-b054-8609cf3229ee @ localhost (dataPort=-1)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Sink: Unnamed (6/6) (attempt #0) to e8e7db5e-cff6-4c33-b054-8609cf3229ee @ localhost (dataPort=-1)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source (1/1).
2020-01-15 09:04:35 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) switched from CREATED to DEPLOYING.
2020-01-15 09:04:35 [Source: Custom Source (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) [DEPLOYING]
2020-01-15 09:04:35 [Source: Custom Source (1/1)] INFO  Task:593 - Loading JAR files for task Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) [DEPLOYING].
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (1/6).
2020-01-15 09:04:35 [Source: Custom Source (1/1)] INFO  Task:619 - Registering task at network: Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) switched from CREATED to DEPLOYING.
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) [DEPLOYING]
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) [DEPLOYING].
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (2/6).
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) switched from CREATED to DEPLOYING.
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) [DEPLOYING]
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) [DEPLOYING].
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (3/6).
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) switched from CREATED to DEPLOYING.
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) [DEPLOYING]
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) [DEPLOYING].
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (4/6).
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) switched from CREATED to DEPLOYING.
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) [DEPLOYING]
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  Task:958 - Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  Task:958 - Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (5/6).
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) [DEPLOYING].
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (3/6) (9f0a938acfbdb94995b8fa26d0f587a4) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Unnamed (1/6) (c784b17c7dbc76211bd26b786f14998a) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  Task:958 - Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Unnamed (2/6) (7dace6145029f4e3f4adb9e75a8c6f53) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Unnamed (6/6).
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) switched from CREATED to DEPLOYING.
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) [DEPLOYING]
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) [DEPLOYING].
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 743d20eadbbf48f2150c72d480b7c989.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 2d7585c248bab0ff46d12cd62e299803.
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) switched from CREATED to DEPLOYING.
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) [DEPLOYING]
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  Task:958 - Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  Task:958 - Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (5/6) (0287e929c100987461ca6f6e327ef68b) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  Task:619 - Registering task at network: Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) [DEPLOYING].
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [Source: Custom Source (1/1)] INFO  Task:958 - Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Source: Custom Source (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (4/6) (c2c818ef0e692f258bdf511b0f98eb1c) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source (1/1) (ced14793006f4d6e79b657af738d8b56) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  Task:958 - Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Unnamed (6/6) (e901a92df133a17a8501fce6c6ad85b5) switched from DEPLOYING to RUNNING.
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 1/6 - no state to restore
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 0/6 - no state to restore
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 2/6 - no state to restore
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 4/6 - no state to restore
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 3/6 - no state to restore
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] WARN  FlinkKafkaProducer:998 - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  TwoPhaseCommitSinkFunction:367 - FlinkKafkaProducer 5/6 - no state to restore
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  ProducerConfig:279 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:35 [Sink: Unnamed (4/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (4/6) to produce into default topic source-topic
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:35 [Sink: Unnamed (3/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (3/6) to produce into default topic source-topic
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:35 [Sink: Unnamed (1/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (1/6) to produce into default topic source-topic
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:35 [Sink: Unnamed (6/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (6/6) to produce into default topic source-topic
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:35 [Sink: Unnamed (5/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (5/6) to produce into default topic source-topic
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:04:35 [Sink: Unnamed (2/6)] INFO  FlinkKafkaProducer:1158 - Starting FlinkKafkaInternalProducer (2/6) to produce into default topic source-topic
2020-01-15 09:04:35 [kafka-producer-network-thread | producer-5] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:35 [kafka-producer-network-thread | producer-1] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:35 [kafka-producer-network-thread | producer-2] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:35 [kafka-producer-network-thread | producer-6] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:35 [kafka-producer-network-thread | producer-3] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:35 [kafka-producer-network-thread | producer-4] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:04:39 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:04:39 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:04:39 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:04:39 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-5a410b98-52fa-4fc1-be82-28ca6d6d2afa
2020-01-15 09:04:39 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:39871
2020-01-15 09:04:39 [IOManagerAsync shutdown hook] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-8030d3bb-e474-44ef-9ae4-5fd5516cfa81
2020-01-15 09:05:27 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:05:27 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:05:27 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:05:27 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:05:27 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:05:27 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:05:27 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:05:27 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:05:28 [flink-akka.actor.default-dispatcher-4] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:05:28 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:05:28 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:05:28 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:05:29 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:40473]
2020-01-15 09:05:29 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:40473
2020-01-15 09:05:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:05:29 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:05:29 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-a53d47a4-2214-4172-95f8-45507a7ee44b
2020-01-15 09:05:29 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:43441 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:05:29 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-2f43f915-b412-43f3-add4-7e652cf4dabc
2020-01-15 09:05:29 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-2ddcd5fc-9574-4c5b-a5b3-a0b766b651e2
2020-01-15 09:05:29 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:05:29 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a
2020-01-15 09:05:29 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:05:29 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-331b0c2b-a977-4623-b194-374fae8bbf7f for spill files.
2020-01-15 09:05:29 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-28a40b14-21bd-461f-a4e7-e49c63424d2b for spill files.
2020-01-15 09:05:29 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:05:29 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:05:29 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:05:29 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:05:29 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:05:29 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:05:29 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:05:29 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-4ef0502e-a7c4-454e-b8ff-93b19927fef3
2020-01-15 09:05:29 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:05:29 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:05:29 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:05:29 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:05:30 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:33465
2020-01-15 09:05:30 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@2f894ad9 @ http://localhost:33465
2020-01-15 09:05:30 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:33465 was granted leadership with leaderSessionID=5c704e0a-87c2-4a41-a716-cbc88776268f
2020-01-15 09:05:30 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:33465 , session=5c704e0a-87c2-4a41-a716-cbc88776268f
2020-01-15 09:05:30 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:05:30 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@36394ef6 @ akka://flink/user/resourcemanager
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token bee6f41aaf9a0969abed15eab17f43a7
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@6d2b1f19 @ akka://flink/user/dispatcher
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=abed15ea-b17f-43a7-bee6-f41aaf9a0969
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 70e945ec-ee01-446c-91d5-c249b19a672f
2020-01-15 09:05:30 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=70e945ec-ee01-446c-91d5-c249b19a672f
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(bee6f41aaf9a0969abed15eab17f43a7).
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id a85111f34a457f48d18013e2344c0185.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission be7d3f0a25ecc4b7f71f4e32dc42b7e7 (Flink Streaming Job).
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job be7d3f0a25ecc4b7f71f4e32dc42b7e7 (Flink Streaming Job).
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7).
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7).
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7).
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@7f3515f1 @ akka://flink/user/jobmanager_1
2020-01-15 09:05:30 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7) was granted leadership with session id c653778b-9b2d-4f6f-a989-655649560979 at akka://flink/user/jobmanager_1.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7) under job master id a989655649560979c653778b9b2d4f6f.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7) switched from state CREATED to RUNNING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from CREATED to SCHEDULED.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fc909ef093b2a7dd1b2b23b2016e50f1}]
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) switched from CREATED to SCHEDULED.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{876544ba99b9d5278b361aa7057d4374}]
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from CREATED to SCHEDULED.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b286369d2643c5266abf1f142f47b1f8}]
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from CREATED to SCHEDULED.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e9e1d78d7f562b0da2c8fdba4360ad1b}]
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from CREATED to SCHEDULED.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{17fe1ddbbdcfd9b88dfb5aa6bffdbf2e}]
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from CREATED to SCHEDULED.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{db31178c0a33c6d4547c92eadadaf13d}]
2020-01-15 09:05:30 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=c653778b-9b2d-4f6f-a989-655649560979
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(bee6f41aaf9a0969abed15eab17f43a7)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager a989655649560979c653778b9b2d4f6f@akka://flink/user/jobmanager_1 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager a989655649560979c653778b9b2d4f6f@akka://flink/user/jobmanager_1 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: bee6f41aaf9a0969abed15eab17f43a7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{fc909ef093b2a7dd1b2b23b2016e50f1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{876544ba99b9d5278b361aa7057d4374}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 with allocation id 11af382812e35d1a7c15e4e2edc24752.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 11af382812e35d1a7c15e4e2edc24752 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 from resource manager with leader id bee6f41aaf9a0969abed15eab17f43a7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 with allocation id b51cffef83b8664d092eb1991899825c.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b286369d2643c5266abf1f142f47b1f8}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e9e1d78d7f562b0da2c8fdba4360ad1b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 with allocation id d35087e01b127b9fb6718afa3ab6544f.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 11af382812e35d1a7c15e4e2edc24752.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{17fe1ddbbdcfd9b88dfb5aa6bffdbf2e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 with allocation id 03295e3ced3aa6e6b2320f0bcabd7ef8.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job be7d3f0a25ecc4b7f71f4e32dc42b7e7 for job leader monitoring.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 with allocation id cd1f2285941fe9f880871401f36ebd35.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{db31178c0a33c6d4547c92eadadaf13d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 with allocation id 976519a4699410d95d2c7988f44c5bb7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request b51cffef83b8664d092eb1991899825c for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 from resource manager with leader id bee6f41aaf9a0969abed15eab17f43a7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for b51cffef83b8664d092eb1991899825c.
2020-01-15 09:05:30 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c653778b-9b2d-4f6f-a989-655649560979.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job be7d3f0a25ecc4b7f71f4e32dc42b7e7 for job leader monitoring.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d35087e01b127b9fb6718afa3ab6544f for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 from resource manager with leader id bee6f41aaf9a0969abed15eab17f43a7.
2020-01-15 09:05:30 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c653778b-9b2d-4f6f-a989-655649560979.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d35087e01b127b9fb6718afa3ab6544f.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job be7d3f0a25ecc4b7f71f4e32dc42b7e7 for job leader monitoring.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 03295e3ced3aa6e6b2320f0bcabd7ef8 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 from resource manager with leader id bee6f41aaf9a0969abed15eab17f43a7.
2020-01-15 09:05:30 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c653778b-9b2d-4f6f-a989-655649560979.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 03295e3ced3aa6e6b2320f0bcabd7ef8.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job be7d3f0a25ecc4b7f71f4e32dc42b7e7 for job leader monitoring.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:05:30 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c653778b-9b2d-4f6f-a989-655649560979.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request cd1f2285941fe9f880871401f36ebd35 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 from resource manager with leader id bee6f41aaf9a0969abed15eab17f43a7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for cd1f2285941fe9f880871401f36ebd35.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job be7d3f0a25ecc4b7f71f4e32dc42b7e7 for job leader monitoring.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:05:30 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c653778b-9b2d-4f6f-a989-655649560979.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 976519a4699410d95d2c7988f44c5bb7 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 from resource manager with leader id bee6f41aaf9a0969abed15eab17f43a7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 976519a4699410d95d2c7988f44c5bb7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job be7d3f0a25ecc4b7f71f4e32dc42b7e7 for job leader monitoring.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:05:30 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id c653778b-9b2d-4f6f-a989-655649560979.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job be7d3f0a25ecc4b7f71f4e32dc42b7e7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job be7d3f0a25ecc4b7f71f4e32dc42b7e7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a @ localhost (dataPort=-1)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a @ localhost (dataPort=-1)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a @ localhost (dataPort=-1)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a @ localhost (dataPort=-1)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a @ localhost (dataPort=-1)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a @ localhost (dataPort=-1)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from CREATED to DEPLOYING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) [DEPLOYING]
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) switched from CREATED to DEPLOYING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) [DEPLOYING]
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) [DEPLOYING].
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from CREATED to DEPLOYING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) [DEPLOYING]
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) [DEPLOYING].
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) [DEPLOYING].
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) [DEPLOYING].
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from CREATED to DEPLOYING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) [DEPLOYING]
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) [DEPLOYING].
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) [DEPLOYING].
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) [DEPLOYING].
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) [DEPLOYING].
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from CREATED to DEPLOYING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) [DEPLOYING]
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) [DEPLOYING].
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) [DEPLOYING].
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from CREATED to DEPLOYING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) [DEPLOYING]
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) [DEPLOYING].
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot cd1f2285941fe9f880871401f36ebd35.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 11af382812e35d1a7c15e4e2edc24752.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 976519a4699410d95d2c7988f44c5bb7.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot b51cffef83b8664d092eb1991899825c.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 03295e3ced3aa6e6b2320f0bcabd7ef8.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot d35087e01b127b9fb6718afa3ab6544f.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) [DEPLOYING].
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from DEPLOYING to RUNNING.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:30 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:05:31 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:05:31 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:05:31 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:05:31 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:05:31 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:05:31 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-11, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: 8iQsAjPiSsKNyOkQMkvggw
2020-01-15 09:05:31 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-11, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:960 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) [?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) [FAILED]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 2131cb09153f9d893418fbe923689f56.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1493 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (2131cb09153f9d893418fbe923689f56) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) [CANCELED]
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) [CANCELED]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) [CANCELED]
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3).
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) [CANCELED]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 517a4253f8618e0d114e16523a0537e7.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 42610f6182639e9877ad022605023e5b.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:982 - Attempting to cancel task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from RUNNING to CANCELING.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  Task:1031 - Triggering cancellation of task code Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (517a4253f8618e0d114e16523a0537e7) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out fde8a369948a5aa8a7c2b7a26c2c70ed.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 3acc867ea5e4b2cc68831a3f6f23c4b3.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (42610f6182639e9877ad022605023e5b) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (fde8a369948a5aa8a7c2b7a26c2c70ed) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:804 - Freeing task resources for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3acc867ea5e4b2cc68831a3f6f23c4b3) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:831 - Ensuring all FileSystem streams are closed for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) [CANCELED]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1459 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out 46ff398c9a72cbe16431ba7f63a57bc9.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (46ff398c9a72cbe16431ba7f63a57bc9) switched from CANCELING to CANCELED.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1446 - Try to restart or fail the job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7) if no longer possible.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1472 - Could not restart the job Flink Streaming Job (be7d3f0a25ecc4b7f71f4e32dc42b7e7) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:217) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.processInput(SourceStreamTask.java:133) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:301) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:406) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.lang.Thread.run(Thread.java:834) ~[?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: (byte[])"{"temp":93"}"; line: 1, column: 12]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:986) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeObject(JsonNodeDeserializer.java:247) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:68) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:15) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4013) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:203) ~[flink-streaming-java_2.12-1.9.1.jar:1.9.1]
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  CheckpointCoordinator:329 - Stopping checkpoint coordinator for job be7d3f0a25ecc4b7f71f4e32dc42b7e7.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneCompletedCheckpointStore:97 - Shutting down
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:775 - Job be7d3f0a25ecc4b7f71f4e32dc42b7e7 reached globally terminal state FAILED.
2020-01-15 09:05:31 [main] INFO  MiniCluster:416 - Shutting down Flink Mini Cluster
2020-01-15 09:05:31 [main] INFO  DispatcherRestEndpoint:290 - Shutting down rest endpoint.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:339 - Stopping TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1078 - Close ResourceManager connection c876d895539b6da0cb5949d04507fdb0.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:805 - Closing TaskExecutor connection 5352f9ef-3ce3-450b-ba8d-84b3d5788a2a because: The TaskExecutor is shutting down.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:335 - Stopping the JobMaster for job Flink Streaming Job(be7d3f0a25ecc4b7f71f4e32dc42b7e7).
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:228 - Suspending SlotPool.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:1010 - Close ResourceManager connection c876d895539b6da0cb5949d04507fdb0: JobManager is shutting down..
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:249 - Stopping SlotPool.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:776 - Disconnect job manager a989655649560979c653778b9b2d4f6f@akka://flink/user/jobmanager_1 for job be7d3f0a25ecc4b7f71f4e32dc42b7e7 from the resource manager.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-331b0c2b-a977-4623-b194-374fae8bbf7f
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  NettyShuffleEnvironment:304 - Shutting down the network environment and its components.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-netty-shuffle-28a40b14-21bd-461f-a4e7-e49c63424d2b
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  KvStateService:119 - Shutting down the kvState service and its components.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:142 - Stop job leader service.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-4ef0502e-a7c4-454e-b8ff-93b19927fef3
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:379 - Stopped TaskExecutor akka://flink/user/taskmanager_0.
2020-01-15 09:05:31 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:687 - Removing cache directory /tmp/flink-web-ui
2020-01-15 09:05:31 [ForkJoinPool.commonPool-worker-3] INFO  DispatcherRestEndpoint:299 - Shut down complete.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:499 - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:220 - Stopping dispatcher akka://flink/user/dispatcher.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:280 - Closing the SlotManager.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:697 - Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:243 - Suspending the SlotManager.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  StackTraceSampleCoordinator:220 - Shutting down stack trace sample coordinator.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:229 - Stopped dispatcher akka://flink/user/dispatcher.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 09:05:31 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Shutting down remote daemon.
2020-01-15 09:05:31 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remote daemon shut down; proceeding with flushing remote transports.
2020-01-15 09:05:31 [flink-metrics-2] INFO  RemoteActorRefProvider$RemotingTerminator:83 - Remoting shut down.
2020-01-15 09:05:31 [flink-metrics-2] INFO  AkkaRpcService:335 - Stopping Akka RPC service.
2020-01-15 09:05:31 [flink-metrics-2] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:43441
2020-01-15 09:05:31 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:354 - Stopped Akka RPC service.
2020-01-15 09:07:50 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:07:50 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:07:50 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:07:50 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:07:50 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:07:50 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:07:50 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:07:50 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:07:51 [flink-akka.actor.default-dispatcher-4] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:07:51 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:07:51 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:07:51 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:07:51 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:43549]
2020-01-15 09:07:51 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:43549
2020-01-15 09:07:51 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:07:51 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:07:51 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-897d4c63-5260-40e6-a0d4-5666bdbee72b
2020-01-15 09:07:51 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:39925 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:07:51 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-b1fc5c47-153e-4c8e-9589-41c6db5b7526
2020-01-15 09:07:51 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-636cd6eb-ce26-4069-9f22-60d33035a3fa
2020-01-15 09:07:51 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:07:51 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8
2020-01-15 09:07:51 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:07:51 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-d36c58ba-76b1-44b5-865a-1e9b36a50465 for spill files.
2020-01-15 09:07:51 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-63e1a40c-1219-4051-a952-02f8c742b965 for spill files.
2020-01-15 09:07:52 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:07:52 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:07:52 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:07:52 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:07:52 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:07:52 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-02fb1e70-1dc4-49d9-9bad-119dcb26495c
2020-01-15 09:07:52 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:07:52 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:07:52 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:07:52 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:07:52 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:45983
2020-01-15 09:07:52 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@6993c8df @ http://localhost:45983
2020-01-15 09:07:52 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:45983 was granted leadership with leaderSessionID=83e3a8c2-c1a2-41f7-9302-6e9b1c10729e
2020-01-15 09:07:52 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:45983 , session=83e3a8c2-c1a2-41f7-9302-6e9b1c10729e
2020-01-15 09:07:52 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:07:52 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@2fecd47 @ akka://flink/user/resourcemanager
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@28010b2c @ akka://flink/user/dispatcher
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token d7e7c1f8-af13-4805-a55b-9517a2013126
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 80d7769141aa108aece5d80714054b41
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:07:52 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=d7e7c1f8-af13-4805-a55b-9517a2013126
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=ece5d807-1405-4b41-80d7-769141aa108a
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(80d7769141aa108aece5d80714054b41).
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 600cd9dd70775fd8498d709e403393b2 (Flink Streaming Job).
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 600cd9dd70775fd8498d709e403393b2 (Flink Streaming Job).
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 6e40c7fe84f9c569139413b51ae71084.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (600cd9dd70775fd8498d709e403393b2).
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (600cd9dd70775fd8498d709e403393b2).
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (600cd9dd70775fd8498d709e403393b2).
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 2 ms.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@1c25e306 @ akka://flink/user/jobmanager_1
2020-01-15 09:07:52 [mini-cluster-io-thread-2] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (600cd9dd70775fd8498d709e403393b2) was granted leadership with session id eae11c3e-a255-4be5-9766-7ff1170975a0 at akka://flink/user/jobmanager_1.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (600cd9dd70775fd8498d709e403393b2) under job master id 97667ff1170975a0eae11c3ea2554be5.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (600cd9dd70775fd8498d709e403393b2) switched from state CREATED to RUNNING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) switched from CREATED to SCHEDULED.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{94ebda258ff766d02432c03cfa4d74d7}]
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) switched from CREATED to SCHEDULED.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{62dafc106821c9d8c348537e56adeb3b}]
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) switched from CREATED to SCHEDULED.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{dad3557d85f5143422e14d9035b1ae25}]
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) switched from CREATED to SCHEDULED.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{cc99b6bc923b510c077092dad9bb5711}]
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) switched from CREATED to SCHEDULED.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{97c8a70a4fdafc9a316e920d931a9678}]
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) switched from CREATED to SCHEDULED.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{03be563557090b9583e17516345b7719}]
2020-01-15 09:07:52 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=eae11c3e-a255-4be5-9766-7ff1170975a0
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(80d7769141aa108aece5d80714054b41)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager 97667ff1170975a0eae11c3ea2554be5@akka://flink/user/jobmanager_1 for job 600cd9dd70775fd8498d709e403393b2.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 97667ff1170975a0eae11c3ea2554be5@akka://flink/user/jobmanager_1 for job 600cd9dd70775fd8498d709e403393b2.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 80d7769141aa108aece5d80714054b41.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{94ebda258ff766d02432c03cfa4d74d7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 600cd9dd70775fd8498d709e403393b2 with allocation id 70c43da68069662688d88b8ac26ecff5.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{62dafc106821c9d8c348537e56adeb3b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{dad3557d85f5143422e14d9035b1ae25}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{cc99b6bc923b510c077092dad9bb5711}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 70c43da68069662688d88b8ac26ecff5 for job 600cd9dd70775fd8498d709e403393b2 from resource manager with leader id 80d7769141aa108aece5d80714054b41.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{97c8a70a4fdafc9a316e920d931a9678}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 600cd9dd70775fd8498d709e403393b2 with allocation id e2969b75cf8416dee35b415f14bfff8a.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 600cd9dd70775fd8498d709e403393b2 with allocation id 7522524007e92d9c9a84865e22941624.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 70c43da68069662688d88b8ac26ecff5.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{03be563557090b9583e17516345b7719}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 600cd9dd70775fd8498d709e403393b2 for job leader monitoring.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 600cd9dd70775fd8498d709e403393b2 with allocation id 8cdc6303279fd614d4971e9ad2e69713.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 600cd9dd70775fd8498d709e403393b2 with allocation id 42377d8e5703776f8beec34f5369ddff.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request e2969b75cf8416dee35b415f14bfff8a for job 600cd9dd70775fd8498d709e403393b2 from resource manager with leader id 80d7769141aa108aece5d80714054b41.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 600cd9dd70775fd8498d709e403393b2 with allocation id c46e5277e379d12a46af47ec2fd9e073.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for e2969b75cf8416dee35b415f14bfff8a.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 600cd9dd70775fd8498d709e403393b2 for job leader monitoring.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 7522524007e92d9c9a84865e22941624 for job 600cd9dd70775fd8498d709e403393b2 from resource manager with leader id 80d7769141aa108aece5d80714054b41.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 7522524007e92d9c9a84865e22941624.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 600cd9dd70775fd8498d709e403393b2 for job leader monitoring.
2020-01-15 09:07:52 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id eae11c3e-a255-4be5-9766-7ff1170975a0.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 8cdc6303279fd614d4971e9ad2e69713 for job 600cd9dd70775fd8498d709e403393b2 from resource manager with leader id 80d7769141aa108aece5d80714054b41.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 8cdc6303279fd614d4971e9ad2e69713.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 600cd9dd70775fd8498d709e403393b2 for job leader monitoring.
2020-01-15 09:07:52 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id eae11c3e-a255-4be5-9766-7ff1170975a0.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 42377d8e5703776f8beec34f5369ddff for job 600cd9dd70775fd8498d709e403393b2 from resource manager with leader id 80d7769141aa108aece5d80714054b41.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 42377d8e5703776f8beec34f5369ddff.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 600cd9dd70775fd8498d709e403393b2 for job leader monitoring.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request c46e5277e379d12a46af47ec2fd9e073 for job 600cd9dd70775fd8498d709e403393b2 from resource manager with leader id 80d7769141aa108aece5d80714054b41.
2020-01-15 09:07:52 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id eae11c3e-a255-4be5-9766-7ff1170975a0.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for c46e5277e379d12a46af47ec2fd9e073.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 600cd9dd70775fd8498d709e403393b2 for job leader monitoring.
2020-01-15 09:07:52 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id eae11c3e-a255-4be5-9766-7ff1170975a0.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 600cd9dd70775fd8498d709e403393b2.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 600cd9dd70775fd8498d709e403393b2.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 600cd9dd70775fd8498d709e403393b2.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8 @ localhost (dataPort=-1)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8 @ localhost (dataPort=-1)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8 @ localhost (dataPort=-1)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8 @ localhost (dataPort=-1)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8 @ localhost (dataPort=-1)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to e5e1387d-c6fa-47c1-af4d-ca3140a0a6a8 @ localhost (dataPort=-1)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) switched from CREATED to DEPLOYING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) [DEPLOYING]
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) switched from CREATED to DEPLOYING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) [DEPLOYING]
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) switched from CREATED to DEPLOYING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) [DEPLOYING]
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) [DEPLOYING].
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (0bcd41a9e5b93bd53ce8d732b81adfce) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (95b4171f17e31d046118e3f6f375ef90) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (08a8a186c7c110b81a7eb4c220475a96) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot e2969b75cf8416dee35b415f14bfff8a.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 42377d8e5703776f8beec34f5369ddff.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot c46e5277e379d12a46af47ec2fd9e073.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 70c43da68069662688d88b8ac26ecff5.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 8cdc6303279fd614d4971e9ad2e69713.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 7522524007e92d9c9a84865e22941624.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) switched from CREATED to DEPLOYING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) [DEPLOYING]
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (8a09b60ae64ee1dda30d5bee9374776d) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) switched from CREATED to DEPLOYING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) [DEPLOYING]
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (02d2956058d40a27831913371626807b) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) switched from CREATED to DEPLOYING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) [DEPLOYING]
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) [DEPLOYING].
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (2e97a9a40b4bc063e8ea4dabb4ca300f) switched from DEPLOYING to RUNNING.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:07:52 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:07:53 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:07:53 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:07:53 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:07:53 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:07:53 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:07:53 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:07:53 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-8, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:07:53 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:07:54 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-8, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:07:54 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:727 - [Consumer clientId=consumer-8, groupId=flink_consumer] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 09:07:54 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-8, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:07:54 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:727 - [Consumer clientId=consumer-8, groupId=flink_consumer] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 09:07:54 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-8, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:07:54 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Fetcher:584 - [Consumer clientId=consumer-8, groupId=flink_consumer] Resetting offset for partition source-topic-0 to offset 563.
2020-01-15 09:08:28 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:08:40 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:08:40 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:08:40 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:08:40 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:08:41 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:08:41 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:08:41 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:08:41 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:08:41 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:08:41 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:08:41 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:08:41 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:08:41 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:46481]
2020-01-15 09:08:42 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:46481
2020-01-15 09:08:42 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:08:42 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:08:42 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-2047c4ab-3138-42c2-9f73-803c28cffc60
2020-01-15 09:08:42 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:42041 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:08:42 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-61075819-aac7-4ca3-83a5-df24fd66253f
2020-01-15 09:08:42 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-23ea11c8-ab35-45a6-9fab-07772ea31759
2020-01-15 09:08:42 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:08:42 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: a3f3551d-c4bc-438c-ac44-5e4bad45cf80
2020-01-15 09:08:42 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:08:42 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-5ce9f47d-075b-4091-8e00-43dfb5f37a66 for spill files.
2020-01-15 09:08:42 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-bd511fbd-de94-4b4c-aaac-d29fd481347f for spill files.
2020-01-15 09:08:42 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:08:42 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:08:42 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:08:42 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:08:42 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:08:42 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:08:42 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:08:42 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-3d2d2342-248d-4728-b593-a2f56f3b1981
2020-01-15 09:08:42 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:08:43 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:08:43 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:08:43 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:08:43 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:33293
2020-01-15 09:08:43 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@2f894ad9 @ http://localhost:33293
2020-01-15 09:08:43 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:33293 was granted leadership with leaderSessionID=efb2a178-6774-4afd-ba55-1bc8b4506f67
2020-01-15 09:08:43 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:33293 , session=efb2a178-6774-4afd-ba55-1bc8b4506f67
2020-01-15 09:08:43 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:08:43 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@78f9fc1c @ akka://flink/user/resourcemanager
2020-01-15 09:08:43 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 985cb890776105697f0da4c9577c493a
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@8fdbf87 @ akka://flink/user/dispatcher
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 6ec8044f-d41e-432f-8e5f-68a927093725
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=7f0da4c9-577c-493a-985c-b89077610569
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=6ec8044f-d41e-432f-8e5f-68a927093725
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(985cb890776105697f0da4c9577c493a).
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID a3f3551d-c4bc-438c-ac44-5e4bad45cf80 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 0f6511f95bc21e093f6bc768c78a7d71.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 7b0f5c138309a24402606d7b299ccb19 (Flink Streaming Job).
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 7b0f5c138309a24402606d7b299ccb19 (Flink Streaming Job).
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (7b0f5c138309a24402606d7b299ccb19).
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (7b0f5c138309a24402606d7b299ccb19).
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (7b0f5c138309a24402606d7b299ccb19).
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 2 ms.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@690cbc04 @ akka://flink/user/jobmanager_1
2020-01-15 09:08:43 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (7b0f5c138309a24402606d7b299ccb19) was granted leadership with session id a745cb42-24a6-4a33-8c12-a4ca9c590898 at akka://flink/user/jobmanager_1.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (7b0f5c138309a24402606d7b299ccb19) under job master id 8c12a4ca9c590898a745cb4224a64a33.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (7b0f5c138309a24402606d7b299ccb19) switched from state CREATED to RUNNING.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) switched from CREATED to SCHEDULED.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c875f7a830dda87931f2fec5891fde61}]
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) switched from CREATED to SCHEDULED.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f2db5d9dbe603796471d1adafe064907}]
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) switched from CREATED to SCHEDULED.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{17e1fd83ddf5ccce27a34fa9b75bdb92}]
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) switched from CREATED to SCHEDULED.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e5aee412417ffba8fb357f4ac8c5e6ae}]
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) switched from CREATED to SCHEDULED.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{46f1b524875ef6e46ffb1373116926c5}]
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) switched from CREATED to SCHEDULED.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fe46e72025697ea13eaeee278b682c0f}]
2020-01-15 09:08:43 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=a745cb42-24a6-4a33-8c12-a4ca9c590898
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(985cb890776105697f0da4c9577c493a)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:302 - Registering job manager 8c12a4ca9c590898a745cb4224a64a33@akka://flink/user/jobmanager_1 for job 7b0f5c138309a24402606d7b299ccb19.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager 8c12a4ca9c590898a745cb4224a64a33@akka://flink/user/jobmanager_1 for job 7b0f5c138309a24402606d7b299ccb19.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 985cb890776105697f0da4c9577c493a.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c875f7a830dda87931f2fec5891fde61}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f2db5d9dbe603796471d1adafe064907}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0f5c138309a24402606d7b299ccb19 with allocation id d9d1a4ccd218df57a177153387e6a642.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{17e1fd83ddf5ccce27a34fa9b75bdb92}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e5aee412417ffba8fb357f4ac8c5e6ae}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{46f1b524875ef6e46ffb1373116926c5}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d9d1a4ccd218df57a177153387e6a642 for job 7b0f5c138309a24402606d7b299ccb19 from resource manager with leader id 985cb890776105697f0da4c9577c493a.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{fe46e72025697ea13eaeee278b682c0f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d9d1a4ccd218df57a177153387e6a642.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 7b0f5c138309a24402606d7b299ccb19 for job leader monitoring.
2020-01-15 09:08:43 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id a745cb42-24a6-4a33-8c12-a4ca9c590898.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0f5c138309a24402606d7b299ccb19 with allocation id 505fdf848d8536cdf0b13dc59a3f04db.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0f5c138309a24402606d7b299ccb19 with allocation id bc68870904bcd5de175cbd2562d41ed8.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 505fdf848d8536cdf0b13dc59a3f04db for job 7b0f5c138309a24402606d7b299ccb19 from resource manager with leader id 985cb890776105697f0da4c9577c493a.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0f5c138309a24402606d7b299ccb19 with allocation id 1c573c2d9b535a644dda4f2b9f09c7b9.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 505fdf848d8536cdf0b13dc59a3f04db.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 7b0f5c138309a24402606d7b299ccb19 for job leader monitoring.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:08:43 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id a745cb42-24a6-4a33-8c12-a4ca9c590898.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request bc68870904bcd5de175cbd2562d41ed8 for job 7b0f5c138309a24402606d7b299ccb19 from resource manager with leader id 985cb890776105697f0da4c9577c493a.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for bc68870904bcd5de175cbd2562d41ed8.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 7b0f5c138309a24402606d7b299ccb19 for job leader monitoring.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0f5c138309a24402606d7b299ccb19 with allocation id 8f0f2ccf7ca6f1d2c4cdd033654c961c.
2020-01-15 09:08:43 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id a745cb42-24a6-4a33-8c12-a4ca9c590898.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0f5c138309a24402606d7b299ccb19 with allocation id 14b8950089651454c3f4435d3d520d83.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 1c573c2d9b535a644dda4f2b9f09c7b9 for job 7b0f5c138309a24402606d7b299ccb19 from resource manager with leader id 985cb890776105697f0da4c9577c493a.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 1c573c2d9b535a644dda4f2b9f09c7b9.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 7b0f5c138309a24402606d7b299ccb19 for job leader monitoring.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 8f0f2ccf7ca6f1d2c4cdd033654c961c for job 7b0f5c138309a24402606d7b299ccb19 from resource manager with leader id 985cb890776105697f0da4c9577c493a.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 8f0f2ccf7ca6f1d2c4cdd033654c961c.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 7b0f5c138309a24402606d7b299ccb19 for job leader monitoring.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 14b8950089651454c3f4435d3d520d83 for job 7b0f5c138309a24402606d7b299ccb19 from resource manager with leader id 985cb890776105697f0da4c9577c493a.
2020-01-15 09:08:43 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id a745cb42-24a6-4a33-8c12-a4ca9c590898.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 14b8950089651454c3f4435d3d520d83.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 7b0f5c138309a24402606d7b299ccb19 for job leader monitoring.
2020-01-15 09:08:43 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id a745cb42-24a6-4a33-8c12-a4ca9c590898.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 7b0f5c138309a24402606d7b299ccb19.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job 7b0f5c138309a24402606d7b299ccb19.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 7b0f5c138309a24402606d7b299ccb19.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to a3f3551d-c4bc-438c-ac44-5e4bad45cf80 @ localhost (dataPort=-1)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to a3f3551d-c4bc-438c-ac44-5e4bad45cf80 @ localhost (dataPort=-1)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to a3f3551d-c4bc-438c-ac44-5e4bad45cf80 @ localhost (dataPort=-1)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to a3f3551d-c4bc-438c-ac44-5e4bad45cf80 @ localhost (dataPort=-1)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to a3f3551d-c4bc-438c-ac44-5e4bad45cf80 @ localhost (dataPort=-1)
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:08:43 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to a3f3551d-c4bc-438c-ac44-5e4bad45cf80 @ localhost (dataPort=-1)
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) switched from CREATED to DEPLOYING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) [DEPLOYING]
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) [DEPLOYING].
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) switched from CREATED to DEPLOYING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) [DEPLOYING]
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) switched from CREATED to DEPLOYING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) [DEPLOYING]
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) [DEPLOYING].
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) switched from CREATED to DEPLOYING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) [DEPLOYING]
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) [DEPLOYING].
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (207db8339e84dad3254b635e0c12020e) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (6249e0b06f61a494f9c6d29cbd7de4d9) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (ce46bf091e5f8f393db520b664599856) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) switched from CREATED to DEPLOYING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) [DEPLOYING]
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (2a6f64404b68cedccb3ffa01afe2cfbd) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (0febfff4f96a593a1a49376d77d964eb) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 14b8950089651454c3f4435d3d520d83.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) switched from CREATED to DEPLOYING.
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot d9d1a4ccd218df57a177153387e6a642.
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 8f0f2ccf7ca6f1d2c4cdd033654c961c.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) [DEPLOYING]
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 505fdf848d8536cdf0b13dc59a3f04db.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) [DEPLOYING].
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 1c573c2d9b535a644dda4f2b9f09c7b9.
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot bc68870904bcd5de175cbd2562d41ed8.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) [DEPLOYING].
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:08:44 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (c2c65c67d51cbb3619d72355778167d1) switched from DEPLOYING to RUNNING.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:08:44 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:08:44 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:08:44 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:08:44 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:08:44 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:08:44 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:08:44 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-11, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:08:44 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-11, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:10:21 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:10:48 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:10:48 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:10:48 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:10:48 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:10:48 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:10:48 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:10:48 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:10:48 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:10:50 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:10:50 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:10:50 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:10:50 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:10:50 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:35367]
2020-01-15 09:10:50 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:35367
2020-01-15 09:10:50 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:10:50 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:10:50 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-99e4ef80-9b9b-410a-9ac9-8043af1bc556
2020-01-15 09:10:50 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:41643 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:10:50 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-9afe0433-03ab-4dcb-831e-dc676bd18e76
2020-01-15 09:10:50 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-bf7bce09-69bb-432f-851a-1976a208ce81
2020-01-15 09:10:50 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:10:50 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: aff41ab9-fc61-4089-9c68-e0e589bd9649
2020-01-15 09:10:50 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:10:50 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-37fe34e6-50df-4142-8ecb-95e53641bd3c for spill files.
2020-01-15 09:10:50 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-591d5e77-8ea8-4a4b-8ff0-a63de8b3bddc for spill files.
2020-01-15 09:10:51 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:10:51 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:10:51 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:10:51 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:10:51 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:10:51 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-cf50a269-ea59-4428-9860-6f8c07f1fe43
2020-01-15 09:10:51 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:10:51 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:10:51 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:10:51 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:10:51 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:35495
2020-01-15 09:10:51 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@6993c8df @ http://localhost:35495
2020-01-15 09:10:51 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:35495 was granted leadership with leaderSessionID=746607bc-93c9-42e5-ae91-c525ef364445
2020-01-15 09:10:51 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:35495 , session=746607bc-93c9-42e5-ae91-c525ef364445
2020-01-15 09:10:51 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:10:51 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@63f2b32f @ akka://flink/user/resourcemanager
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@6b2dbf0 @ akka://flink/user/dispatcher
2020-01-15 09:10:51 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 0accbf05-7dfc-4d8b-81b6-06e8f9c6efc7
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token af989a4afa12176c3dfe251851f2483c
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=0accbf05-7dfc-4d8b-81b6-06e8f9c6efc7
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=3dfe2518-51f2-483c-af98-9a4afa12176c
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(af989a4afa12176c3dfe251851f2483c).
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission a4208820115d3d368188d27f773b4c06 (Flink Streaming Job).
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job a4208820115d3d368188d27f773b4c06 (Flink Streaming Job).
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID aff41ab9-fc61-4089-9c68-e0e589bd9649 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 5e461c99d84e9173bfcda96788520b61.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (a4208820115d3d368188d27f773b4c06).
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (a4208820115d3d368188d27f773b4c06).
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (a4208820115d3d368188d27f773b4c06).
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@3b677db3 @ akka://flink/user/jobmanager_1
2020-01-15 09:10:51 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (a4208820115d3d368188d27f773b4c06) was granted leadership with session id d0a15290-a801-4bc4-8f0e-5822ca3d3732 at akka://flink/user/jobmanager_1.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (a4208820115d3d368188d27f773b4c06) under job master id 8f0e5822ca3d3732d0a15290a8014bc4.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (a4208820115d3d368188d27f773b4c06) switched from state CREATED to RUNNING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) switched from CREATED to SCHEDULED.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1cb67d00756702eb127a07a1ade9b736}]
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) switched from CREATED to SCHEDULED.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a9969d2e295eae876aa91f48b9405ff8}]
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) switched from CREATED to SCHEDULED.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d1d16ada0684d9770d9af0b88c42de34}]
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) switched from CREATED to SCHEDULED.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8bdca9ae60edf1fc16c3fe6e75317b92}]
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) switched from CREATED to SCHEDULED.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{612f608136160e682a34f353bd7912e4}]
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) switched from CREATED to SCHEDULED.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bc15f50f7a6ba42a402f5ad8f73e9c12}]
2020-01-15 09:10:51 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=d0a15290-a801-4bc4-8f0e-5822ca3d3732
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(af989a4afa12176c3dfe251851f2483c)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 8f0e5822ca3d3732d0a15290a8014bc4@akka://flink/user/jobmanager_1 for job a4208820115d3d368188d27f773b4c06.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 8f0e5822ca3d3732d0a15290a8014bc4@akka://flink/user/jobmanager_1 for job a4208820115d3d368188d27f773b4c06.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: af989a4afa12176c3dfe251851f2483c.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1cb67d00756702eb127a07a1ade9b736}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a9969d2e295eae876aa91f48b9405ff8}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a4208820115d3d368188d27f773b4c06 with allocation id f3a4f186039095861c0c858209786155.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d1d16ada0684d9770d9af0b88c42de34}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request f3a4f186039095861c0c858209786155 for job a4208820115d3d368188d27f773b4c06 from resource manager with leader id af989a4afa12176c3dfe251851f2483c.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a4208820115d3d368188d27f773b4c06 with allocation id 54f43af450365117d8539e537264b445.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a4208820115d3d368188d27f773b4c06 with allocation id 48539063afbacf3be4032f5c8f0aadca.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for f3a4f186039095861c0c858209786155.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job a4208820115d3d368188d27f773b4c06 for job leader monitoring.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 54f43af450365117d8539e537264b445 for job a4208820115d3d368188d27f773b4c06 from resource manager with leader id af989a4afa12176c3dfe251851f2483c.
2020-01-15 09:10:51 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id d0a15290-a801-4bc4-8f0e-5822ca3d3732.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 54f43af450365117d8539e537264b445.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job a4208820115d3d368188d27f773b4c06 for job leader monitoring.
2020-01-15 09:10:51 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id d0a15290-a801-4bc4-8f0e-5822ca3d3732.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 48539063afbacf3be4032f5c8f0aadca for job a4208820115d3d368188d27f773b4c06 from resource manager with leader id af989a4afa12176c3dfe251851f2483c.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 48539063afbacf3be4032f5c8f0aadca.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job a4208820115d3d368188d27f773b4c06 for job leader monitoring.
2020-01-15 09:10:51 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id d0a15290-a801-4bc4-8f0e-5822ca3d3732.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{8bdca9ae60edf1fc16c3fe6e75317b92}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{612f608136160e682a34f353bd7912e4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a4208820115d3d368188d27f773b4c06 with allocation id d072a17bfd7246062d463deaf21abc73.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{bc15f50f7a6ba42a402f5ad8f73e9c12}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d072a17bfd7246062d463deaf21abc73 for job a4208820115d3d368188d27f773b4c06 from resource manager with leader id af989a4afa12176c3dfe251851f2483c.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a4208820115d3d368188d27f773b4c06 with allocation id 2f3711e9b5f122fbaf6943938ade6e58.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d072a17bfd7246062d463deaf21abc73.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a4208820115d3d368188d27f773b4c06 with allocation id dd0228bc54ad29d266c85fafb101b781.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job a4208820115d3d368188d27f773b4c06 for job leader monitoring.
2020-01-15 09:10:51 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id d0a15290-a801-4bc4-8f0e-5822ca3d3732.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 2f3711e9b5f122fbaf6943938ade6e58 for job a4208820115d3d368188d27f773b4c06 from resource manager with leader id af989a4afa12176c3dfe251851f2483c.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 2f3711e9b5f122fbaf6943938ade6e58.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job a4208820115d3d368188d27f773b4c06 for job leader monitoring.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request dd0228bc54ad29d266c85fafb101b781 for job a4208820115d3d368188d27f773b4c06 from resource manager with leader id af989a4afa12176c3dfe251851f2483c.
2020-01-15 09:10:51 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id d0a15290-a801-4bc4-8f0e-5822ca3d3732.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for dd0228bc54ad29d266c85fafb101b781.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job a4208820115d3d368188d27f773b4c06 for job leader monitoring.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:10:51 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id d0a15290-a801-4bc4-8f0e-5822ca3d3732.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job a4208820115d3d368188d27f773b4c06.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job a4208820115d3d368188d27f773b4c06.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job a4208820115d3d368188d27f773b4c06.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to aff41ab9-fc61-4089-9c68-e0e589bd9649 @ localhost (dataPort=-1)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to aff41ab9-fc61-4089-9c68-e0e589bd9649 @ localhost (dataPort=-1)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to aff41ab9-fc61-4089-9c68-e0e589bd9649 @ localhost (dataPort=-1)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to aff41ab9-fc61-4089-9c68-e0e589bd9649 @ localhost (dataPort=-1)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to aff41ab9-fc61-4089-9c68-e0e589bd9649 @ localhost (dataPort=-1)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to aff41ab9-fc61-4089-9c68-e0e589bd9649 @ localhost (dataPort=-1)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) switched from CREATED to DEPLOYING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) [DEPLOYING]
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) [DEPLOYING].
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) switched from CREATED to DEPLOYING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) [DEPLOYING]
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (5cbcc64f401ce76b7c9ed142b99fa1bb) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (e390e688bd4ece70e8dcb9e0ebec138e) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) switched from CREATED to DEPLOYING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) [DEPLOYING]
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) [DEPLOYING].
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) switched from CREATED to DEPLOYING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 54f43af450365117d8539e537264b445.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) [DEPLOYING]
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (101e3a703d8a9aa5831d0f281e397c74) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot d072a17bfd7246062d463deaf21abc73.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 2f3711e9b5f122fbaf6943938ade6e58.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 48539063afbacf3be4032f5c8f0aadca.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot dd0228bc54ad29d266c85fafb101b781.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot f3a4f186039095861c0c858209786155.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (a2a8ed3b41fa4b48c705394639837136) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) switched from CREATED to DEPLOYING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) [DEPLOYING]
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) [DEPLOYING].
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (a8e6054cb9433fa58c8c20d353388fc5) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) switched from CREATED to DEPLOYING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) [DEPLOYING]
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) [DEPLOYING].
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:10:51 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (ce346583706d3fdeb8e902481bd4bfa4) switched from DEPLOYING to RUNNING.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:10:51 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:10:51 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:10:51 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:10:51 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:10:51 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:10:51 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:10:51 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:51 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:10:52 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:11:04 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:11:11 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:11:11 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:11:11 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:11 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:11:12 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:11:12 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:11:12 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:11:12 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:11:12 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:11:12 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:11:12 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:11:12 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:11:12 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:38135]
2020-01-15 09:11:12 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:38135
2020-01-15 09:11:12 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:11:12 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:11:12 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-1a4a4eac-cace-4bf6-9767-2a2796f8ea3a
2020-01-15 09:11:12 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:40695 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:11:12 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-81c4f1cd-c1f8-466c-9f10-784a2d50f717
2020-01-15 09:11:12 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-baa59c2d-89d9-4eca-ab20-74915c4eb6ea
2020-01-15 09:11:12 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:11:12 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 3b5530f7-6e38-472a-9dcd-0e20448a993e
2020-01-15 09:11:13 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:11:13 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-b235cd19-4bf4-42fb-913f-beb48a2cb32f for spill files.
2020-01-15 09:11:13 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-d9cfcf87-b6fb-406d-92a0-a78cb1becd05 for spill files.
2020-01-15 09:11:13 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:11:13 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:11:13 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:11:13 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:11:13 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:11:13 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:11:13 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:11:13 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:11:13 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-8d4986b2-5efc-456a-abd2-e1c70e277dd7
2020-01-15 09:11:14 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:11:14 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:11:14 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:11:14 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:42457
2020-01-15 09:11:14 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@5f174dd2 @ http://localhost:42457
2020-01-15 09:11:14 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:42457 was granted leadership with leaderSessionID=0c2d63f5-181f-47f3-90bd-14995d75cdbb
2020-01-15 09:11:14 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:42457 , session=0c2d63f5-181f-47f3-90bd-14995d75cdbb
2020-01-15 09:11:14 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:11:14 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@566a4bd3 @ akka://flink/user/resourcemanager
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@2daf328f @ akka://flink/user/dispatcher
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token b1731994b9df466fb02f56274b864bcb
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=b02f5627-4b86-4bcb-b173-1994b9df466f
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 9b5c27d5-4fb1-4304-b7c1-aa5598ba5dc2
2020-01-15 09:11:14 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(b1731994b9df466fb02f56274b864bcb).
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=9b5c27d5-4fb1-4304-b7c1-aa5598ba5dc2
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 3b5530f7-6e38-472a-9dcd-0e20448a993e (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission b1141fbef5e46ae612f60c6bd33ca8c9 (Flink Streaming Job).
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job b1141fbef5e46ae612f60c6bd33ca8c9 (Flink Streaming Job).
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id b198993e2f2df401fa71c3bd100e9f66.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (b1141fbef5e46ae612f60c6bd33ca8c9).
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (b1141fbef5e46ae612f60c6bd33ca8c9).
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (b1141fbef5e46ae612f60c6bd33ca8c9).
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@6f8e740a @ akka://flink/user/jobmanager_1
2020-01-15 09:11:14 [mini-cluster-io-thread-5] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (b1141fbef5e46ae612f60c6bd33ca8c9) was granted leadership with session id 3ae62b8e-53a4-4a6b-9922-5c53cef0725f at akka://flink/user/jobmanager_1.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (b1141fbef5e46ae612f60c6bd33ca8c9) under job master id 99225c53cef0725f3ae62b8e53a44a6b.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (b1141fbef5e46ae612f60c6bd33ca8c9) switched from state CREATED to RUNNING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) switched from CREATED to SCHEDULED.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9db8cf457840d5385c0d0636f46d0c70}]
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) switched from CREATED to SCHEDULED.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2895bd091d24ca9ab4ef7fdecf3d169a}]
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) switched from CREATED to SCHEDULED.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{11fddb8a056227dfbe16adb9bdcb1a15}]
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) switched from CREATED to SCHEDULED.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8a07b9bc41ba2dbe370940d95e08358d}]
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) switched from CREATED to SCHEDULED.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b451203468829fa6531ccf88942276fe}]
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) switched from CREATED to SCHEDULED.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d93a1333daac6adf6d3e243e77467e2b}]
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(b1731994b9df466fb02f56274b864bcb)
2020-01-15 09:11:14 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=3ae62b8e-53a4-4a6b-9922-5c53cef0725f
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:302 - Registering job manager 99225c53cef0725f3ae62b8e53a44a6b@akka://flink/user/jobmanager_1 for job b1141fbef5e46ae612f60c6bd33ca8c9.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager 99225c53cef0725f3ae62b8e53a44a6b@akka://flink/user/jobmanager_1 for job b1141fbef5e46ae612f60c6bd33ca8c9.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: b1731994b9df466fb02f56274b864bcb.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{9db8cf457840d5385c0d0636f46d0c70}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{2895bd091d24ca9ab4ef7fdecf3d169a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b1141fbef5e46ae612f60c6bd33ca8c9 with allocation id f50fa6987c91ffee1e1b6d90c0b64f51.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{11fddb8a056227dfbe16adb9bdcb1a15}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{8a07b9bc41ba2dbe370940d95e08358d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request f50fa6987c91ffee1e1b6d90c0b64f51 for job b1141fbef5e46ae612f60c6bd33ca8c9 from resource manager with leader id b1731994b9df466fb02f56274b864bcb.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b451203468829fa6531ccf88942276fe}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b1141fbef5e46ae612f60c6bd33ca8c9 with allocation id d679f6f50ff062e4150818bca1d4565f.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d93a1333daac6adf6d3e243e77467e2b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b1141fbef5e46ae612f60c6bd33ca8c9 with allocation id 1f2352afd3a5e01e8b9a399b18c50b42.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b1141fbef5e46ae612f60c6bd33ca8c9 with allocation id fe54c7065637ef5e97b6188ae4df95a6.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b1141fbef5e46ae612f60c6bd33ca8c9 with allocation id 69c94233d88a0effb3d749883d85e364.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b1141fbef5e46ae612f60c6bd33ca8c9 with allocation id 5115bb3a65a0ca6e9fd6a38a2ae2d616.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for f50fa6987c91ffee1e1b6d90c0b64f51.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b1141fbef5e46ae612f60c6bd33ca8c9 for job leader monitoring.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request d679f6f50ff062e4150818bca1d4565f for job b1141fbef5e46ae612f60c6bd33ca8c9 from resource manager with leader id b1731994b9df466fb02f56274b864bcb.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for d679f6f50ff062e4150818bca1d4565f.
2020-01-15 09:11:14 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3ae62b8e-53a4-4a6b-9922-5c53cef0725f.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b1141fbef5e46ae612f60c6bd33ca8c9 for job leader monitoring.
2020-01-15 09:11:14 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3ae62b8e-53a4-4a6b-9922-5c53cef0725f.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 1f2352afd3a5e01e8b9a399b18c50b42 for job b1141fbef5e46ae612f60c6bd33ca8c9 from resource manager with leader id b1731994b9df466fb02f56274b864bcb.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 1f2352afd3a5e01e8b9a399b18c50b42.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b1141fbef5e46ae612f60c6bd33ca8c9 for job leader monitoring.
2020-01-15 09:11:14 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3ae62b8e-53a4-4a6b-9922-5c53cef0725f.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request fe54c7065637ef5e97b6188ae4df95a6 for job b1141fbef5e46ae612f60c6bd33ca8c9 from resource manager with leader id b1731994b9df466fb02f56274b864bcb.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for fe54c7065637ef5e97b6188ae4df95a6.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b1141fbef5e46ae612f60c6bd33ca8c9 for job leader monitoring.
2020-01-15 09:11:14 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3ae62b8e-53a4-4a6b-9922-5c53cef0725f.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 69c94233d88a0effb3d749883d85e364 for job b1141fbef5e46ae612f60c6bd33ca8c9 from resource manager with leader id b1731994b9df466fb02f56274b864bcb.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 69c94233d88a0effb3d749883d85e364.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b1141fbef5e46ae612f60c6bd33ca8c9 for job leader monitoring.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 5115bb3a65a0ca6e9fd6a38a2ae2d616 for job b1141fbef5e46ae612f60c6bd33ca8c9 from resource manager with leader id b1731994b9df466fb02f56274b864bcb.
2020-01-15 09:11:14 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3ae62b8e-53a4-4a6b-9922-5c53cef0725f.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 5115bb3a65a0ca6e9fd6a38a2ae2d616.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job b1141fbef5e46ae612f60c6bd33ca8c9 for job leader monitoring.
2020-01-15 09:11:14 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3ae62b8e-53a4-4a6b-9922-5c53cef0725f.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job b1141fbef5e46ae612f60c6bd33ca8c9.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job b1141fbef5e46ae612f60c6bd33ca8c9.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job b1141fbef5e46ae612f60c6bd33ca8c9.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (attempt #0) to 3b5530f7-6e38-472a-9dcd-0e20448a993e @ localhost (dataPort=-1)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (attempt #0) to 3b5530f7-6e38-472a-9dcd-0e20448a993e @ localhost (dataPort=-1)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (attempt #0) to 3b5530f7-6e38-472a-9dcd-0e20448a993e @ localhost (dataPort=-1)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (attempt #0) to 3b5530f7-6e38-472a-9dcd-0e20448a993e @ localhost (dataPort=-1)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (attempt #0) to 3b5530f7-6e38-472a-9dcd-0e20448a993e @ localhost (dataPort=-1)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (attempt #0) to 3b5530f7-6e38-472a-9dcd-0e20448a993e @ localhost (dataPort=-1)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6).
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) switched from CREATED to DEPLOYING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) [DEPLOYING]
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) [DEPLOYING].
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6).
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) [DEPLOYING].
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6).
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) switched from CREATED to DEPLOYING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) [DEPLOYING]
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6) (e3640173513eead4ccfef5e2ce80a662) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6).
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6) (1e4a2dba4b6ab70a32efc18bbe8029b0) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 1f2352afd3a5e01e8b9a399b18c50b42.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) switched from CREATED to DEPLOYING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 69c94233d88a0effb3d749883d85e364.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) [DEPLOYING]
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 5115bb3a65a0ca6e9fd6a38a2ae2d616.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) [DEPLOYING].
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot f50fa6987c91ffee1e1b6d90c0b64f51.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot fe54c7065637ef5e97b6188ae4df95a6.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot d679f6f50ff062e4150818bca1d4565f.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) [DEPLOYING].
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6).
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) switched from CREATED to DEPLOYING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) [DEPLOYING]
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6) (f1f90fd94df03312600132018ebbb277) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) switched from CREATED to DEPLOYING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) [DEPLOYING]
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6) (1bef88e56c6964be33b3c28e5e6b4218) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6).
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6) (e10dde9cd1729c41a7b3842e6f64eaac) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) switched from CREATED to DEPLOYING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) [DEPLOYING]
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) [DEPLOYING].
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6) (3764b11e7ce43be41891a63c7c4f44fa) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:14 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:11:15 [Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:11:15 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:11:15 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:11:15 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:11:15 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:11:15 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:11:15 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-8, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-8, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:15 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Print to Std. Out (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:24 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:11:47 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:11:47 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:11:47 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:47 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:11:48 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:11:48 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:11:48 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:11:48 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:11:48 [flink-akka.actor.default-dispatcher-4] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:11:48 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:11:48 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:11:49 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:11:49 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:33705]
2020-01-15 09:11:49 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:33705
2020-01-15 09:11:49 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:11:49 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:11:49 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-41a0c669-af58-4ad3-88d3-f93e9cbf73d8
2020-01-15 09:11:49 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:43397 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:11:49 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-e9898fe1-7597-4e65-a5b4-3f711f0d532a
2020-01-15 09:11:49 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-fc552329-7dae-429a-adba-0281531f0dd9
2020-01-15 09:11:49 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:11:49 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 8e3898c3-1db4-479d-a6f9-ca5508082b57
2020-01-15 09:11:49 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:11:49 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-c70844a6-8b33-4533-80e0-59ba012b5fe4 for spill files.
2020-01-15 09:11:49 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-99b7a678-d44a-44a4-9e2d-8464b4bca6d7 for spill files.
2020-01-15 09:11:49 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:11:49 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:11:49 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:11:49 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:11:49 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:11:49 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:11:49 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:11:49 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-b24e951b-2af1-4d89-97c6-17982ca8d00a
2020-01-15 09:11:49 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:11:50 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:11:50 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:11:50 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:11:50 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:34629
2020-01-15 09:11:50 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@bbd4791 @ http://localhost:34629
2020-01-15 09:11:50 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:34629 was granted leadership with leaderSessionID=3573a4bd-3bfb-43e1-9c92-b89c53e592d8
2020-01-15 09:11:50 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:34629 , session=3573a4bd-3bfb-43e1-9c92-b89c53e592d8
2020-01-15 09:11:50 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:11:50 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@574dce96 @ akka://flink/user/resourcemanager
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@3501c61b @ akka://flink/user/dispatcher
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token a8e9420c-c872-4473-9aa9-fbdca886a657
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:11:50 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 95a2544763584eb3a88adcd752534c6d
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=a8e9420c-c872-4473-9aa9-fbdca886a657
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=a88adcd7-5253-4c6d-95a2-544763584eb3
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(95a2544763584eb3a88adcd752534c6d).
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 8e3898c3-1db4-479d-a6f9-ca5508082b57 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission c82b79094c1fbe8f8bce75a17347a8c3 (Flink Streaming Job).
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job c82b79094c1fbe8f8bce75a17347a8c3 (Flink Streaming Job).
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 23525be79f960bfc7ef79174249484ea.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (c82b79094c1fbe8f8bce75a17347a8c3).
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (c82b79094c1fbe8f8bce75a17347a8c3).
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (c82b79094c1fbe8f8bce75a17347a8c3).
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@4df6670e @ akka://flink/user/jobmanager_1
2020-01-15 09:11:50 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (c82b79094c1fbe8f8bce75a17347a8c3) was granted leadership with session id 2e8b541e-83f6-45ee-ab5c-0d0f8083b220 at akka://flink/user/jobmanager_1.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (c82b79094c1fbe8f8bce75a17347a8c3) under job master id ab5c0d0f8083b2202e8b541e83f645ee.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (c82b79094c1fbe8f8bce75a17347a8c3) switched from state CREATED to RUNNING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) switched from CREATED to SCHEDULED.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{14784e48fa5edb762d5f1a8e82a7ece0}]
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) switched from CREATED to SCHEDULED.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f167bf33da543e197e16d0db5bdaf110}]
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) switched from CREATED to SCHEDULED.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7094218eee49e286a83e1e6b13fcb8e7}]
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) switched from CREATED to SCHEDULED.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e3a1d6d91eaea8aa11fa8715a11ec3c4}]
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) switched from CREATED to SCHEDULED.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{008227711191842169f8e3f32157b073}]
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) switched from CREATED to SCHEDULED.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{11d8500d8615a20cb1e6c3338360b5db}]
2020-01-15 09:11:50 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=2e8b541e-83f6-45ee-ab5c-0d0f8083b220
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(95a2544763584eb3a88adcd752534c6d)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager ab5c0d0f8083b2202e8b541e83f645ee@akka://flink/user/jobmanager_1 for job c82b79094c1fbe8f8bce75a17347a8c3.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager ab5c0d0f8083b2202e8b541e83f645ee@akka://flink/user/jobmanager_1 for job c82b79094c1fbe8f8bce75a17347a8c3.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 95a2544763584eb3a88adcd752534c6d.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{14784e48fa5edb762d5f1a8e82a7ece0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c82b79094c1fbe8f8bce75a17347a8c3 with allocation id f9a0dbd99bbfdda548c9f7e074c27c42.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f167bf33da543e197e16d0db5bdaf110}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{7094218eee49e286a83e1e6b13fcb8e7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{e3a1d6d91eaea8aa11fa8715a11ec3c4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c82b79094c1fbe8f8bce75a17347a8c3 with allocation id 6865d67c19036515f5b08144c4657bea.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{008227711191842169f8e3f32157b073}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c82b79094c1fbe8f8bce75a17347a8c3 with allocation id dfc08fe434a7035b45f4ff62a735c6b0.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{11d8500d8615a20cb1e6c3338360b5db}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c82b79094c1fbe8f8bce75a17347a8c3 with allocation id 11f7a347c672ee072094adc857ca846a.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c82b79094c1fbe8f8bce75a17347a8c3 with allocation id bebf819973f263c070ead720b8ac60be.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job c82b79094c1fbe8f8bce75a17347a8c3 with allocation id c1b0081aa63dc144344d5febba8a51c4.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request f9a0dbd99bbfdda548c9f7e074c27c42 for job c82b79094c1fbe8f8bce75a17347a8c3 from resource manager with leader id 95a2544763584eb3a88adcd752534c6d.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for f9a0dbd99bbfdda548c9f7e074c27c42.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job c82b79094c1fbe8f8bce75a17347a8c3 for job leader monitoring.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 6865d67c19036515f5b08144c4657bea for job c82b79094c1fbe8f8bce75a17347a8c3 from resource manager with leader id 95a2544763584eb3a88adcd752534c6d.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 6865d67c19036515f5b08144c4657bea.
2020-01-15 09:11:50 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e8b541e-83f6-45ee-ab5c-0d0f8083b220.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job c82b79094c1fbe8f8bce75a17347a8c3 for job leader monitoring.
2020-01-15 09:11:50 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e8b541e-83f6-45ee-ab5c-0d0f8083b220.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request dfc08fe434a7035b45f4ff62a735c6b0 for job c82b79094c1fbe8f8bce75a17347a8c3 from resource manager with leader id 95a2544763584eb3a88adcd752534c6d.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for dfc08fe434a7035b45f4ff62a735c6b0.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job c82b79094c1fbe8f8bce75a17347a8c3 for job leader monitoring.
2020-01-15 09:11:50 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e8b541e-83f6-45ee-ab5c-0d0f8083b220.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 11f7a347c672ee072094adc857ca846a for job c82b79094c1fbe8f8bce75a17347a8c3 from resource manager with leader id 95a2544763584eb3a88adcd752534c6d.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 11f7a347c672ee072094adc857ca846a.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job c82b79094c1fbe8f8bce75a17347a8c3 for job leader monitoring.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request bebf819973f263c070ead720b8ac60be for job c82b79094c1fbe8f8bce75a17347a8c3 from resource manager with leader id 95a2544763584eb3a88adcd752534c6d.
2020-01-15 09:11:50 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e8b541e-83f6-45ee-ab5c-0d0f8083b220.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for bebf819973f263c070ead720b8ac60be.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job c82b79094c1fbe8f8bce75a17347a8c3 for job leader monitoring.
2020-01-15 09:11:50 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e8b541e-83f6-45ee-ab5c-0d0f8083b220.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request c1b0081aa63dc144344d5febba8a51c4 for job c82b79094c1fbe8f8bce75a17347a8c3 from resource manager with leader id 95a2544763584eb3a88adcd752534c6d.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for c1b0081aa63dc144344d5febba8a51c4.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job c82b79094c1fbe8f8bce75a17347a8c3 for job leader monitoring.
2020-01-15 09:11:50 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e8b541e-83f6-45ee-ab5c-0d0f8083b220.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job c82b79094c1fbe8f8bce75a17347a8c3.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job c82b79094c1fbe8f8bce75a17347a8c3.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job c82b79094c1fbe8f8bce75a17347a8c3.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to 8e3898c3-1db4-479d-a6f9-ca5508082b57 @ localhost (dataPort=-1)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to 8e3898c3-1db4-479d-a6f9-ca5508082b57 @ localhost (dataPort=-1)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to 8e3898c3-1db4-479d-a6f9-ca5508082b57 @ localhost (dataPort=-1)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to 8e3898c3-1db4-479d-a6f9-ca5508082b57 @ localhost (dataPort=-1)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to 8e3898c3-1db4-479d-a6f9-ca5508082b57 @ localhost (dataPort=-1)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to 8e3898c3-1db4-479d-a6f9-ca5508082b57 @ localhost (dataPort=-1)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) switched from CREATED to DEPLOYING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) [DEPLOYING]
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) [DEPLOYING].
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) [DEPLOYING].
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) switched from CREATED to DEPLOYING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) [DEPLOYING]
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) [DEPLOYING].
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) [DEPLOYING].
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) switched from CREATED to DEPLOYING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) [DEPLOYING]
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) [DEPLOYING].
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) [DEPLOYING].
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) switched from CREATED to DEPLOYING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (91484aa07df594e1c9d716498e7b7999) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) [DEPLOYING]
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) [DEPLOYING].
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (db7c3ee7e49b976659654032eedd7cde) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (45ddb923b18d89b692c5d396dd9e6aa8) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) switched from CREATED to DEPLOYING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) [DEPLOYING]
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) [DEPLOYING].
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) [DEPLOYING].
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) [DEPLOYING].
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (e4bb06398f98362da9cee20723c655a7) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (1dd471ee5383b2dcd204aa4fb3fc67fc) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 11f7a347c672ee072094adc857ca846a.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) switched from CREATED to DEPLOYING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot f9a0dbd99bbfdda548c9f7e074c27c42.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) [DEPLOYING]
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot dfc08fe434a7035b45f4ff62a735c6b0.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) [DEPLOYING].
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot c1b0081aa63dc144344d5febba8a51c4.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 6865d67c19036515f5b08144c4657bea.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot bebf819973f263c070ead720b8ac60be.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) [DEPLOYING].
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (73d74f77699b008ac9e5e53554dd43d9) switched from DEPLOYING to RUNNING.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:50 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:11:51 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:11:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:11:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:11:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:11:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:11:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:11:51 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-9, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:11:51 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-9, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:12:18 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:43397
2020-01-15 09:12:18 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:12:18 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:23:30 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:23:30 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:23:30 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:23:30 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:23:30 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:23:30 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:23:30 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:23:30 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:23:31 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:23:31 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:23:31 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:23:31 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:23:31 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:45151]
2020-01-15 09:23:31 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:45151
2020-01-15 09:23:31 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:23:31 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:23:31 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-3fe93fe4-62cb-420b-be8b-4c6b7d266fa3
2020-01-15 09:23:31 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:45577 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:23:31 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-e327ad2b-ac9b-4994-8d9f-265272c35fe2
2020-01-15 09:23:31 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-25fb2ab2-76f6-4b81-bc12-c2a12886d1db
2020-01-15 09:23:31 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:23:31 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: f4ea47d1-9160-4ed4-84b9-3528a29fef4b
2020-01-15 09:23:31 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:23:31 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-ed28b676-0fd9-40ef-bdb5-0bcfbda753d6 for spill files.
2020-01-15 09:23:31 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-18462285-faa3-4b1d-be4f-e22b98d34c07 for spill files.
2020-01-15 09:23:32 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:23:32 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:23:32 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:23:32 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:23:32 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:23:32 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-c0bb2c10-0f56-47a5-b6b3-656eaf839be6
2020-01-15 09:23:32 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:23:32 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:23:32 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:23:32 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:23:32 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:39633
2020-01-15 09:23:32 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@d535a3d @ http://localhost:39633
2020-01-15 09:23:32 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:39633 was granted leadership with leaderSessionID=cb1d0c60-09ad-42ea-ab5f-979fcf2e5a3e
2020-01-15 09:23:32 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:39633 , session=cb1d0c60-09ad-42ea-ab5f-979fcf2e5a3e
2020-01-15 09:23:32 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:23:32 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@227ca5cc @ akka://flink/user/resourcemanager
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@78db7460 @ akka://flink/user/dispatcher
2020-01-15 09:23:32 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 11267202-c0b6-451a-bca3-76a121effd16
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 861556415b3394aef061d46f517642e8
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=11267202-c0b6-451a-bca3-76a121effd16
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=f061d46f-5176-42e8-8615-56415b3394ae
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(861556415b3394aef061d46f517642e8).
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission 6652363af87eabbfd1c4894c8a541d47 (Flink Streaming Job).
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID f4ea47d1-9160-4ed4-84b9-3528a29fef4b (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job 6652363af87eabbfd1c4894c8a541d47 (Flink Streaming Job).
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 4fdade85fc830eebb65092e321d6a773.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (6652363af87eabbfd1c4894c8a541d47).
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (6652363af87eabbfd1c4894c8a541d47).
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (6652363af87eabbfd1c4894c8a541d47).
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@169d86b4 @ akka://flink/user/jobmanager_1
2020-01-15 09:23:32 [mini-cluster-io-thread-2] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (6652363af87eabbfd1c4894c8a541d47) was granted leadership with session id 189ec115-f998-42c1-8f58-a68768afd04d at akka://flink/user/jobmanager_1.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (6652363af87eabbfd1c4894c8a541d47) under job master id 8f58a68768afd04d189ec115f99842c1.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (6652363af87eabbfd1c4894c8a541d47) switched from state CREATED to RUNNING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5ba43bd2e60209ed0078c2c41ba85f62}]
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fb5fd9299440f3b99a5b52d0cdd7bce6}]
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{90326b43e8a5c73f72cd9214edc4915a}]
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{98cb8560ab34a668bd25fe5ed8d4611b}]
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c71061f6bce7229619bc9533198a1b55}]
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8ac93fe4e090d72d632a69631fd2f573}]
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) switched from CREATED to SCHEDULED.
2020-01-15 09:23:32 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=189ec115-f998-42c1-8f58-a68768afd04d
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(861556415b3394aef061d46f517642e8)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:302 - Registering job manager 8f58a68768afd04d189ec115f99842c1@akka://flink/user/jobmanager_1 for job 6652363af87eabbfd1c4894c8a541d47.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:657 - Registered job manager 8f58a68768afd04d189ec115f99842c1@akka://flink/user/jobmanager_1 for job 6652363af87eabbfd1c4894c8a541d47.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 861556415b3394aef061d46f517642e8.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{5ba43bd2e60209ed0078c2c41ba85f62}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6652363af87eabbfd1c4894c8a541d47 with allocation id 21d0d9df94849c25d47b2abfe4420ddf.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{fb5fd9299440f3b99a5b52d0cdd7bce6}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{90326b43e8a5c73f72cd9214edc4915a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 21d0d9df94849c25d47b2abfe4420ddf for job 6652363af87eabbfd1c4894c8a541d47 from resource manager with leader id 861556415b3394aef061d46f517642e8.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{98cb8560ab34a668bd25fe5ed8d4611b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6652363af87eabbfd1c4894c8a541d47 with allocation id b2a5d96e2179d979df3d347049b6d678.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c71061f6bce7229619bc9533198a1b55}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6652363af87eabbfd1c4894c8a541d47 with allocation id 057d6271cd278a8f2c2b2e880c2c3dae.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{8ac93fe4e090d72d632a69631fd2f573}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 21d0d9df94849c25d47b2abfe4420ddf.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6652363af87eabbfd1c4894c8a541d47 with allocation id 3e664fb77d01bbd67020451b63593865.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 6652363af87eabbfd1c4894c8a541d47 for job leader monitoring.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6652363af87eabbfd1c4894c8a541d47 with allocation id a2c1f524a3e152b13f7e75bb8e634230.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 6652363af87eabbfd1c4894c8a541d47 with allocation id 73248c55188f407df6f8e031347471f6.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request b2a5d96e2179d979df3d347049b6d678 for job 6652363af87eabbfd1c4894c8a541d47 from resource manager with leader id 861556415b3394aef061d46f517642e8.
2020-01-15 09:23:32 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 189ec115-f998-42c1-8f58-a68768afd04d.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for b2a5d96e2179d979df3d347049b6d678.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 6652363af87eabbfd1c4894c8a541d47 for job leader monitoring.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:23:32 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 189ec115-f998-42c1-8f58-a68768afd04d.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 057d6271cd278a8f2c2b2e880c2c3dae for job 6652363af87eabbfd1c4894c8a541d47 from resource manager with leader id 861556415b3394aef061d46f517642e8.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 057d6271cd278a8f2c2b2e880c2c3dae.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 6652363af87eabbfd1c4894c8a541d47 for job leader monitoring.
2020-01-15 09:23:32 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 189ec115-f998-42c1-8f58-a68768afd04d.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 3e664fb77d01bbd67020451b63593865 for job 6652363af87eabbfd1c4894c8a541d47 from resource manager with leader id 861556415b3394aef061d46f517642e8.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 3e664fb77d01bbd67020451b63593865.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 6652363af87eabbfd1c4894c8a541d47 for job leader monitoring.
2020-01-15 09:23:32 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 189ec115-f998-42c1-8f58-a68768afd04d.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request a2c1f524a3e152b13f7e75bb8e634230 for job 6652363af87eabbfd1c4894c8a541d47 from resource manager with leader id 861556415b3394aef061d46f517642e8.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for a2c1f524a3e152b13f7e75bb8e634230.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 6652363af87eabbfd1c4894c8a541d47 for job leader monitoring.
2020-01-15 09:23:32 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 189ec115-f998-42c1-8f58-a68768afd04d.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 73248c55188f407df6f8e031347471f6 for job 6652363af87eabbfd1c4894c8a541d47 from resource manager with leader id 861556415b3394aef061d46f517642e8.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 73248c55188f407df6f8e031347471f6.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 6652363af87eabbfd1c4894c8a541d47 for job leader monitoring.
2020-01-15 09:23:32 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 189ec115-f998-42c1-8f58-a68768afd04d.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 6652363af87eabbfd1c4894c8a541d47.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job 6652363af87eabbfd1c4894c8a541d47.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 6652363af87eabbfd1c4894c8a541d47.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (1/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (2/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (3/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (4/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (5/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (6/6) (attempt #0) to f4ea47d1-9160-4ed4-84b9-3528a29fef4b @ localhost (dataPort=-1)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) switched from CREATED to DEPLOYING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) [DEPLOYING]
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) switched from CREATED to DEPLOYING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) [DEPLOYING]
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) [DEPLOYING].
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) switched from CREATED to DEPLOYING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) [DEPLOYING]
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) switched from CREATED to DEPLOYING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) [DEPLOYING]
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) [DEPLOYING].
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) switched from CREATED to DEPLOYING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) [DEPLOYING]
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) [DEPLOYING].
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (782744cf2b622be7430a9fdb0df16e34) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (80da607102aecee1c5413edb20c660a4) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (a05df9da5229cb3d14a65ab12cfd1ccd) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) switched from CREATED to DEPLOYING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) [DEPLOYING]
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) [DEPLOYING].
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (600ba64b9f6227c3d19a38e82f35630c) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (0795dc7655e70996e782badcc5eb57bd) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (0b438dcf1f26ff50ded676b3fb4be553) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:32 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1).
2020-01-15 09:23:32 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) switched from CREATED to DEPLOYING.
2020-01-15 09:23:32 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) [DEPLOYING]
2020-01-15 09:23:32 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:593 - Loading JAR files for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) [DEPLOYING].
2020-01-15 09:23:32 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:619 - Registering task at network: TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) [DEPLOYING].
2020-01-15 09:23:32 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (1/6).
2020-01-15 09:23:33 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (3b23a589b1240fae22bfe8d6a31b1dcf) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] WARN  MetricGroup:143 - The operator name TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) exceeded the 80 characters length limit and was truncated.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:23:33 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) switched from CREATED to DEPLOYING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) [DEPLOYING]
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (2/6).
2020-01-15 09:23:33 [Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) switched from CREATED to DEPLOYING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) [DEPLOYING]
2020-01-15 09:23:33 [Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) [DEPLOYING].
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:23:33 [Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) [DEPLOYING].
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:23:33 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (bc0da5aef63af1ae5a13b2a97eb20714) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (f209c428d4688fa3c6d75644c5518184) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (3/6).
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot b2a5d96e2179d979df3d347049b6d678.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 73248c55188f407df6f8e031347471f6.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3e664fb77d01bbd67020451b63593865.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot a2c1f524a3e152b13f7e75bb8e634230.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 057d6271cd278a8f2c2b2e880c2c3dae.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 21d0d9df94849c25d47b2abfe4420ddf.
2020-01-15 09:23:33 [Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (6/6).
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:23:33 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) switched from CREATED to DEPLOYING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) switched from CREATED to DEPLOYING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) [DEPLOYING]
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (4/6).
2020-01-15 09:23:33 [Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) [DEPLOYING]
2020-01-15 09:23:33 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) switched from CREATED to DEPLOYING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) [DEPLOYING]
2020-01-15 09:23:33 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (0b44da7f743123f4ce28956ca4aa67dd) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (af062d99a1c751136cccc4fd4f0bb36b) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (253dd079c65c22e4fbf35a9d552cea00) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:33 [Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (5/6).
2020-01-15 09:23:33 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) switched from CREATED to DEPLOYING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) [DEPLOYING]
2020-01-15 09:23:33 [Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) [DEPLOYING].
2020-01-15 09:23:33 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (c884a930c4edcb1d00fcdf75eaeddc1a) switched from DEPLOYING to RUNNING.
2020-01-15 09:23:33 [Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:23:33 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  HeapKeyedStateBackend:140 - Initializing heap keyed state backend with stream factory.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:23:33 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:23:33 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:23:33 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:23:33 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:23:33 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:23:33 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:23:33 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-11, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:23:33 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-11, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:24:20 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:24:20 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:24:20 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-c0bb2c10-0f56-47a5-b6b3-656eaf839be6
2020-01-15 09:24:23 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:24:23 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:24:23 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:23 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:24:23 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:24:23 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:24:23 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:24:23 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:24:24 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:24:24 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:24:24 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:24:24 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:24:25 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:39119]
2020-01-15 09:24:25 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:39119
2020-01-15 09:24:25 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:24:25 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:24:25 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-5b60b255-00c4-4d44-89ef-f2b265ca1857
2020-01-15 09:24:25 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:40459 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:24:25 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-a4bcbf20-6c53-48b4-95e5-97ce64931013
2020-01-15 09:24:25 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-7b309758-dcff-43f8-8764-87560b51773c
2020-01-15 09:24:25 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:24:25 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: b76dd7a6-1e5f-436f-9fff-394fe040333a
2020-01-15 09:24:25 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:24:25 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-58d32c8e-b6c9-4144-8001-b2c246d37871 for spill files.
2020-01-15 09:24:25 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-28e7905e-973b-4300-a21c-10bec7cc66c6 for spill files.
2020-01-15 09:24:25 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:24:25 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:24:25 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:24:25 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:24:26 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:24:26 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-922adcb4-27d3-4111-a150-dc82b35ce630
2020-01-15 09:24:26 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:24:26 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:24:26 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:24:26 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:24:26 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:44805
2020-01-15 09:24:26 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@d535a3d @ http://localhost:44805
2020-01-15 09:24:26 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:44805 was granted leadership with leaderSessionID=a8f5b112-0970-463c-be6d-6590aa41d189
2020-01-15 09:24:26 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:44805 , session=a8f5b112-0970-463c-be6d-6590aa41d189
2020-01-15 09:24:26 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:24:26 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6caa11bb @ akka://flink/user/resourcemanager
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@e11e734 @ akka://flink/user/dispatcher
2020-01-15 09:24:26 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 987a6b44-121c-49f4-a1ce-ee3f051beb67
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token a7ab44104f797e0e1a949417c4414540
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=987a6b44-121c-49f4-a1ce-ee3f051beb67
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=1a949417-c441-4540-a7ab-44104f797e0e
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(a7ab44104f797e0e1a949417c4414540).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission d3c3ab7c97a55a030cc7b5d2347e60c4 (Flink Streaming Job).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job d3c3ab7c97a55a030cc7b5d2347e60c4 (Flink Streaming Job).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID b76dd7a6-1e5f-436f-9fff-394fe040333a (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 0a21e27ab1eed06ee0da1934d5742721.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (d3c3ab7c97a55a030cc7b5d2347e60c4).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (d3c3ab7c97a55a030cc7b5d2347e60c4).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (d3c3ab7c97a55a030cc7b5d2347e60c4).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@3ebf61a9 @ akka://flink/user/jobmanager_1
2020-01-15 09:24:26 [mini-cluster-io-thread-2] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (d3c3ab7c97a55a030cc7b5d2347e60c4) was granted leadership with session id 5f40037d-4eb2-415b-93eb-c63b092f87b3 at akka://flink/user/jobmanager_1.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (d3c3ab7c97a55a030cc7b5d2347e60c4) under job master id 93ebc63b092f87b35f40037d4eb2415b.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (d3c3ab7c97a55a030cc7b5d2347e60c4) switched from state CREATED to RUNNING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{641a4e42d0940cf39c49cca752a64ed0}]
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{515d243be3ba163631d9bf81f8ae7e70}]
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b8f8258f1c1342839642726d3bca8064}]
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c88d8c0e717c6244d85652f9ac748440}]
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3e4259b62cb75bd0e19598f8e8cfdd2d}]
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{035d04cd3d6b9b524e7bf5f2cfb621b4}]
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) switched from CREATED to SCHEDULED.
2020-01-15 09:24:26 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=5f40037d-4eb2-415b-93eb-c63b092f87b3
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(a7ab44104f797e0e1a949417c4414540)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 93ebc63b092f87b35f40037d4eb2415b@akka://flink/user/jobmanager_1 for job d3c3ab7c97a55a030cc7b5d2347e60c4.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:657 - Registered job manager 93ebc63b092f87b35f40037d4eb2415b@akka://flink/user/jobmanager_1 for job d3c3ab7c97a55a030cc7b5d2347e60c4.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: a7ab44104f797e0e1a949417c4414540.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{641a4e42d0940cf39c49cca752a64ed0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d3c3ab7c97a55a030cc7b5d2347e60c4 with allocation id a72676cbf14374434aa47826cfcd739e.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{515d243be3ba163631d9bf81f8ae7e70}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b8f8258f1c1342839642726d3bca8064}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request a72676cbf14374434aa47826cfcd739e for job d3c3ab7c97a55a030cc7b5d2347e60c4 from resource manager with leader id a7ab44104f797e0e1a949417c4414540.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{c88d8c0e717c6244d85652f9ac748440}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{3e4259b62cb75bd0e19598f8e8cfdd2d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{035d04cd3d6b9b524e7bf5f2cfb621b4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d3c3ab7c97a55a030cc7b5d2347e60c4 with allocation id af244e1d9e4c5f9cf42e86ad9d4b796b.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d3c3ab7c97a55a030cc7b5d2347e60c4 with allocation id 49e973e10160bbc7828cda6a2f3544eb.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d3c3ab7c97a55a030cc7b5d2347e60c4 with allocation id 639289af02984559cc6146d6c8729250.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d3c3ab7c97a55a030cc7b5d2347e60c4 with allocation id 3641a398d6a2992fa4ba3ad98450d91a.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d3c3ab7c97a55a030cc7b5d2347e60c4 with allocation id 0b2eb05d18524a91525f8615dcecc8e0.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for a72676cbf14374434aa47826cfcd739e.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job d3c3ab7c97a55a030cc7b5d2347e60c4 for job leader monitoring.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request af244e1d9e4c5f9cf42e86ad9d4b796b for job d3c3ab7c97a55a030cc7b5d2347e60c4 from resource manager with leader id a7ab44104f797e0e1a949417c4414540.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for af244e1d9e4c5f9cf42e86ad9d4b796b.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job d3c3ab7c97a55a030cc7b5d2347e60c4 for job leader monitoring.
2020-01-15 09:24:26 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5f40037d-4eb2-415b-93eb-c63b092f87b3.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 49e973e10160bbc7828cda6a2f3544eb for job d3c3ab7c97a55a030cc7b5d2347e60c4 from resource manager with leader id a7ab44104f797e0e1a949417c4414540.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 49e973e10160bbc7828cda6a2f3544eb.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job d3c3ab7c97a55a030cc7b5d2347e60c4 for job leader monitoring.
2020-01-15 09:24:26 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5f40037d-4eb2-415b-93eb-c63b092f87b3.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 639289af02984559cc6146d6c8729250 for job d3c3ab7c97a55a030cc7b5d2347e60c4 from resource manager with leader id a7ab44104f797e0e1a949417c4414540.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 639289af02984559cc6146d6c8729250.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job d3c3ab7c97a55a030cc7b5d2347e60c4 for job leader monitoring.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 3641a398d6a2992fa4ba3ad98450d91a for job d3c3ab7c97a55a030cc7b5d2347e60c4 from resource manager with leader id a7ab44104f797e0e1a949417c4414540.
2020-01-15 09:24:26 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5f40037d-4eb2-415b-93eb-c63b092f87b3.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 3641a398d6a2992fa4ba3ad98450d91a.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job d3c3ab7c97a55a030cc7b5d2347e60c4 for job leader monitoring.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 0b2eb05d18524a91525f8615dcecc8e0 for job d3c3ab7c97a55a030cc7b5d2347e60c4 from resource manager with leader id a7ab44104f797e0e1a949417c4414540.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 0b2eb05d18524a91525f8615dcecc8e0.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job d3c3ab7c97a55a030cc7b5d2347e60c4 for job leader monitoring.
2020-01-15 09:24:26 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 5f40037d-4eb2-415b-93eb-c63b092f87b3.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job d3c3ab7c97a55a030cc7b5d2347e60c4.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job d3c3ab7c97a55a030cc7b5d2347e60c4.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job d3c3ab7c97a55a030cc7b5d2347e60c4.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (1/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (2/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (3/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (4/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (5/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (6/6) (attempt #0) to b76dd7a6-1e5f-436f-9fff-394fe040333a @ localhost (dataPort=-1)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) [DEPLOYING]
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (73f3c7121572aef0d8301d8f0e2e092f) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) [DEPLOYING]
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (b3dc2411f4cb325ba4fa1b873ad5a645) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) [DEPLOYING]
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) [DEPLOYING].
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (417a65af81765dc9bec56c02695b91d4) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) [DEPLOYING]
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) [DEPLOYING]
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (089bb43ae445e640683b36a1905565a7) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (ff2468895e06260937b838dcd0a6fa92) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1).
2020-01-15 09:24:26 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) [DEPLOYING]
2020-01-15 09:24:26 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:593 - Loading JAR files for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:24:26 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:619 - Registering task at network: TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (1/6).
2020-01-15 09:24:26 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) [DEPLOYING]
2020-01-15 09:24:26 [Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) [DEPLOYING].
2020-01-15 09:24:26 [Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) [DEPLOYING].
2020-01-15 09:24:26 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (cb65ddec8eefd54a848ca4e73c02543c) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:24:26 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (90cb25630d6e2c50993d0d3ca10942ee) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (2/6).
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] WARN  MetricGroup:143 - The operator name TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) exceeded the 80 characters length limit and was truncated.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) [DEPLOYING]
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) [DEPLOYING].
2020-01-15 09:24:26 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) switched from CREATED to DEPLOYING.
2020-01-15 09:24:26 [Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) [DEPLOYING]
2020-01-15 09:24:26 [Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) [DEPLOYING].
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (c827e601a3db16137dfaa64ff67bc727) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:26 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (3/6).
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:26 [Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) [DEPLOYING].
2020-01-15 09:24:26 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:26 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:27 [Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (3194a20533c3f5a4a91d39de8f9a7719) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) switched from CREATED to DEPLOYING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) [DEPLOYING]
2020-01-15 09:24:27 [Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) [DEPLOYING].
2020-01-15 09:24:27 [Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) [DEPLOYING].
2020-01-15 09:24:27 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (4/6).
2020-01-15 09:24:27 [Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (edffd79d690bf36e7b8f97b9bd4e99ee) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) switched from CREATED to DEPLOYING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) [DEPLOYING]
2020-01-15 09:24:27 [Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) [DEPLOYING].
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (5/6).
2020-01-15 09:24:27 [Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) [DEPLOYING].
2020-01-15 09:24:27 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) switched from CREATED to DEPLOYING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) [DEPLOYING]
2020-01-15 09:24:27 [Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) [DEPLOYING].
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:24:27 [Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) [DEPLOYING].
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:27 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (4da6cf1fe728ac8b1fd7d24a46158ff9) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (e70e449eb79f347bb7118ef4af9751f4) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (6/6).
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 639289af02984559cc6146d6c8729250.
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot af244e1d9e4c5f9cf42e86ad9d4b796b.
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot a72676cbf14374434aa47826cfcd739e.
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 3641a398d6a2992fa4ba3ad98450d91a.
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 0b2eb05d18524a91525f8615dcecc8e0.
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 49e973e10160bbc7828cda6a2f3544eb.
2020-01-15 09:24:27 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  HeapKeyedStateBackend:140 - Initializing heap keyed state backend with stream factory.
2020-01-15 09:24:27 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) switched from CREATED to DEPLOYING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) [DEPLOYING]
2020-01-15 09:24:27 [Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) [DEPLOYING].
2020-01-15 09:24:27 [Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) [DEPLOYING].
2020-01-15 09:24:27 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:24:27 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (33518cd6750ca9abbcc7d544094f5d63) switched from DEPLOYING to RUNNING.
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:24:27 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:24:27 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:24:27 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:24:27 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:24:27 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:24:27 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:24:27 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-7, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:24:27 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-7, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:24:54 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:40459
2020-01-15 09:24:54 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-922adcb4-27d3-4111-a150-dc82b35ce630
2020-01-15 09:24:54 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:24:54 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:24:54 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:24:57 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:24:57 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:24:57 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:24:57 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:24:58 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:24:58 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:24:58 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:24:58 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:25:00 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:25:00 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:25:00 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:25:00 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:25:00 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:41681]
2020-01-15 09:25:00 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:41681
2020-01-15 09:25:00 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:25:00 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:25:00 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-af4e212f-274a-4ac8-8c1f-9546ecad3bed
2020-01-15 09:25:00 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:42449 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:25:00 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-786fbf62-6eb2-4e73-bce7-3e23e5bf0d6b
2020-01-15 09:25:00 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-b5699e4f-caf9-4c74-82d3-e5bbb893b50d
2020-01-15 09:25:00 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:25:00 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 78ba1872-bb17-46ec-ad78-75c724e38b5b
2020-01-15 09:25:00 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:25:00 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-83d8152d-cc84-441d-aa3a-3583e2e7499d for spill files.
2020-01-15 09:25:00 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-ad786f32-ec57-440c-9455-2deb92dab3fd for spill files.
2020-01-15 09:25:00 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:25:00 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:25:00 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:25:00 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:25:00 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:25:00 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:25:00 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:25:00 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-d88dde88-0c02-4c91-ba18-f5669ed961a3
2020-01-15 09:25:00 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:25:01 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:25:01 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:25:01 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:25:01 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:42533
2020-01-15 09:25:01 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@d535a3d @ http://localhost:42533
2020-01-15 09:25:01 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:42533 was granted leadership with leaderSessionID=41a44d2f-2c0d-41c1-93c1-891159f3dada
2020-01-15 09:25:01 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:42533 , session=41a44d2f-2c0d-41c1-93c1-891159f3dada
2020-01-15 09:25:01 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:25:01 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@eaf9bed @ akka://flink/user/resourcemanager
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@5d379df1 @ akka://flink/user/dispatcher
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 80f1f2798c3b4fafdfa4c6ae10734b8d
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 8882be8a-202e-41d7-8277-fe64c9a7e967
2020-01-15 09:25:01 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=dfa4c6ae-1073-4b8d-80f1-f2798c3b4faf
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=8882be8a-202e-41d7-8277-fe64c9a7e967
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(80f1f2798c3b4fafdfa4c6ae10734b8d).
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:264 - Received JobGraph submission 3beb4ff862dfcc36ece72e5d978e7deb (Flink Streaming Job).
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:321 - Submitting job 3beb4ff862dfcc36ece72e5d978e7deb (Flink Streaming Job).
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 78ba1872-bb17-46ec-ad78-75c724e38b5b (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 59d0618ecd9346d5267178899fa5362f.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (3beb4ff862dfcc36ece72e5d978e7deb).
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (3beb4ff862dfcc36ece72e5d978e7deb).
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (3beb4ff862dfcc36ece72e5d978e7deb).
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@39cdce28 @ akka://flink/user/jobmanager_1
2020-01-15 09:25:01 [mini-cluster-io-thread-2] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (3beb4ff862dfcc36ece72e5d978e7deb) was granted leadership with session id 0db96393-7885-450b-8b19-af2434f7ac66 at akka://flink/user/jobmanager_1.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (3beb4ff862dfcc36ece72e5d978e7deb) under job master id 8b19af2434f7ac660db963937885450b.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (3beb4ff862dfcc36ece72e5d978e7deb) switched from state CREATED to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9751a03d111cc063f3d6087496fe1bd7}]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1bfd5f5e86c86dfb099ffb30fb3e9b46}]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d37811445c96f6029ca8ece2e28bf6b0}]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1ac27424fa45645ec385abba5015a014}]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8df808f1be8e9d3742f7ec53105333e1}]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a0f40917b24d4cd137b1126427ce7234}]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) switched from CREATED to SCHEDULED.
2020-01-15 09:25:01 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=0db96393-7885-450b-8b19-af2434f7ac66
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(80f1f2798c3b4fafdfa4c6ae10734b8d)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager 8b19af2434f7ac660db963937885450b@akka://flink/user/jobmanager_1 for job 3beb4ff862dfcc36ece72e5d978e7deb.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager 8b19af2434f7ac660db963937885450b@akka://flink/user/jobmanager_1 for job 3beb4ff862dfcc36ece72e5d978e7deb.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 80f1f2798c3b4fafdfa4c6ae10734b8d.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{9751a03d111cc063f3d6087496fe1bd7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3beb4ff862dfcc36ece72e5d978e7deb with allocation id 74b7d43d95aba859f572aa30b9d4d186.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1bfd5f5e86c86dfb099ffb30fb3e9b46}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d37811445c96f6029ca8ece2e28bf6b0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1ac27424fa45645ec385abba5015a014}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 74b7d43d95aba859f572aa30b9d4d186 for job 3beb4ff862dfcc36ece72e5d978e7deb from resource manager with leader id 80f1f2798c3b4fafdfa4c6ae10734b8d.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{8df808f1be8e9d3742f7ec53105333e1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{a0f40917b24d4cd137b1126427ce7234}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3beb4ff862dfcc36ece72e5d978e7deb with allocation id e7bc29bd4fdcede7e9b56c65810de087.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3beb4ff862dfcc36ece72e5d978e7deb with allocation id bd02f89f83d748ab891bfae7c7a8f0f5.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 74b7d43d95aba859f572aa30b9d4d186.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3beb4ff862dfcc36ece72e5d978e7deb with allocation id 59df730b368d70c0bbc4c6d742701dce.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 3beb4ff862dfcc36ece72e5d978e7deb for job leader monitoring.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3beb4ff862dfcc36ece72e5d978e7deb with allocation id c71eb3916da9ef8d50faf9db84f74a70.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request e7bc29bd4fdcede7e9b56c65810de087 for job 3beb4ff862dfcc36ece72e5d978e7deb from resource manager with leader id 80f1f2798c3b4fafdfa4c6ae10734b8d.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3beb4ff862dfcc36ece72e5d978e7deb with allocation id 06f2ebfa2566213ac6004c8e585a4328.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for e7bc29bd4fdcede7e9b56c65810de087.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 3beb4ff862dfcc36ece72e5d978e7deb for job leader monitoring.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request bd02f89f83d748ab891bfae7c7a8f0f5 for job 3beb4ff862dfcc36ece72e5d978e7deb from resource manager with leader id 80f1f2798c3b4fafdfa4c6ae10734b8d.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for bd02f89f83d748ab891bfae7c7a8f0f5.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 3beb4ff862dfcc36ece72e5d978e7deb for job leader monitoring.
2020-01-15 09:25:01 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 0db96393-7885-450b-8b19-af2434f7ac66.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 59df730b368d70c0bbc4c6d742701dce for job 3beb4ff862dfcc36ece72e5d978e7deb from resource manager with leader id 80f1f2798c3b4fafdfa4c6ae10734b8d.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 59df730b368d70c0bbc4c6d742701dce.
2020-01-15 09:25:01 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 0db96393-7885-450b-8b19-af2434f7ac66.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 3beb4ff862dfcc36ece72e5d978e7deb for job leader monitoring.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request c71eb3916da9ef8d50faf9db84f74a70 for job 3beb4ff862dfcc36ece72e5d978e7deb from resource manager with leader id 80f1f2798c3b4fafdfa4c6ae10734b8d.
2020-01-15 09:25:01 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 0db96393-7885-450b-8b19-af2434f7ac66.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for c71eb3916da9ef8d50faf9db84f74a70.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 3beb4ff862dfcc36ece72e5d978e7deb for job leader monitoring.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 06f2ebfa2566213ac6004c8e585a4328 for job 3beb4ff862dfcc36ece72e5d978e7deb from resource manager with leader id 80f1f2798c3b4fafdfa4c6ae10734b8d.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 06f2ebfa2566213ac6004c8e585a4328.
2020-01-15 09:25:01 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 0db96393-7885-450b-8b19-af2434f7ac66.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job 3beb4ff862dfcc36ece72e5d978e7deb for job leader monitoring.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:25:01 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 0db96393-7885-450b-8b19-af2434f7ac66.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:25:01 [mini-cluster-io-thread-4] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 3beb4ff862dfcc36ece72e5d978e7deb.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job 3beb4ff862dfcc36ece72e5d978e7deb.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 3beb4ff862dfcc36ece72e5d978e7deb.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (1/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (2/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (3/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (4/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (5/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (6/6) (attempt #0) to 78ba1872-bb17-46ec-ad78-75c724e38b5b @ localhost (dataPort=-1)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) [DEPLOYING]
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) [DEPLOYING].
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) [DEPLOYING]
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) [DEPLOYING]
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) [DEPLOYING]
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) [DEPLOYING].
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) [DEPLOYING].
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) [DEPLOYING].
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) [DEPLOYING]
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) [DEPLOYING].
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 74b7d43d95aba859f572aa30b9d4d186.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot e7bc29bd4fdcede7e9b56c65810de087.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot bd02f89f83d748ab891bfae7c7a8f0f5.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) [DEPLOYING]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 06f2ebfa2566213ac6004c8e585a4328.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 59df730b368d70c0bbc4c6d742701dce.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot c71eb3916da9ef8d50faf9db84f74a70.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) [DEPLOYING].
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (20310676b94d3542eb42627aa5b8c8c4) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (430b99fb22a9c32c2b925c9a4aaa5561) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (fff9c2c1b258e4926c7695be9e777a37) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (2/6).
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (8852c4eff5e4e3ea765542ab2d3139b7) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (f8ace54ba6d009fcfdc05b6cf011fbd2) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (424b09bcf696a5b5576ce7fc0478a767) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (3/6).
2020-01-15 09:25:01 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) [DEPLOYING]
2020-01-15 09:25:01 [Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (4/6).
2020-01-15 09:25:01 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) [DEPLOYING]
2020-01-15 09:25:01 [Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) [DEPLOYING]
2020-01-15 09:25:01 [Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (6617c7d18810cfb120213507361da47f) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (5/6).
2020-01-15 09:25:01 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (488e4c29589b0baab3504d08def8e03c) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (6/6).
2020-01-15 09:25:01 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) [DEPLOYING]
2020-01-15 09:25:01 [Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) [DEPLOYING].
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (1/6).
2020-01-15 09:25:01 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) [DEPLOYING]
2020-01-15 09:25:01 [Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) [DEPLOYING]
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1).
2020-01-15 09:25:01 [Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) [DEPLOYING].
2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) switched from CREATED to DEPLOYING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) [DEPLOYING]
2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:593 - Loading JAR files for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) [DEPLOYING].
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (341dccca464306f4ea91f88400a6d6da) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (69587e26dabf89c11437375785219f63) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:619 - Registering task at network: TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) [DEPLOYING].
2020-01-15 09:25:01 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (d53f30cc91006d365baf442ce2a96bca) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (e4e37cd65420c918cad4c93134c7b9b7) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (a0cb8ad903fdc1e99714f36fc7a4f74d) switched from DEPLOYING to RUNNING.
2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] WARN  MetricGroup:143 - The operator name TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) exceeded the 80 characters length limit and was truncated.
2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:01 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:01 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  HeapKeyedStateBackend:140 - Initializing heap keyed state backend with stream factory.
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:25:02 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:25:02 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:25:02 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:25:02 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:25:02 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:25:02 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:02 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:25:02 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:26:11 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:42449
2020-01-15 09:26:11 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:26:11 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:26:11 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:26:11 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-d88dde88-0c02-4c91-ba18-f5669ed961a3
2020-01-15 09:26:11 [IOManagerAsync shutdown hook] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-83d8152d-cc84-441d-aa3a-3583e2e7499d
2020-01-15 09:49:12 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:49:12 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:49:12 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:13 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:49:13 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:49:13 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:49:13 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:49:13 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:49:14 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:49:14 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:49:14 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:49:14 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:49:14 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:45491]
2020-01-15 09:49:14 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:45491
2020-01-15 09:49:14 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:49:14 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:49:14 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-7c89718c-23c7-4c7c-8c1a-a08c22d89cd9
2020-01-15 09:49:14 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:46211 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:49:14 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-8a71bf2e-0390-4c58-9e0f-ad549f4942f3
2020-01-15 09:49:14 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-b0e8154a-416c-4fab-93d0-7ff462f1f50a
2020-01-15 09:49:14 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:49:14 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: c4e24940-a14f-4a1c-b459-6136c9d62d2f
2020-01-15 09:49:14 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:49:14 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-98e1ada5-befa-45ec-885a-ba99eba9ac5e for spill files.
2020-01-15 09:49:14 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-a76e8c46-5c9c-4ed3-b9fc-b05af476e747 for spill files.
2020-01-15 09:49:15 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:49:15 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:49:15 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:49:15 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:49:15 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:49:15 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:49:15 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:49:15 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-71078df7-6025-4f6f-92be-be3348aca159
2020-01-15 09:49:15 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:49:15 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:49:15 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:49:15 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:49:16 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:45443
2020-01-15 09:49:16 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@d535a3d @ http://localhost:45443
2020-01-15 09:49:16 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:45443 was granted leadership with leaderSessionID=14ce4386-77dc-4cf9-92b7-69c40221d883
2020-01-15 09:49:16 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:45443 , session=14ce4386-77dc-4cf9-92b7-69c40221d883
2020-01-15 09:49:16 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:49:16 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@53fbd7ef @ akka://flink/user/resourcemanager
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@10a8700b @ akka://flink/user/dispatcher
2020-01-15 09:49:16 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 937e6751-828f-4609-acd2-0b15540f0246
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 88b4282d9d96c8380ff0c1e70a634fe9
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=937e6751-828f-4609-acd2-0b15540f0246
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=0ff0c1e7-0a63-4fe9-88b4-282d9d96c838
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(88b4282d9d96c8380ff0c1e70a634fe9).
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission eb5b1c45722cc6aec8674852fa775232 (Flink Streaming Job).
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job eb5b1c45722cc6aec8674852fa775232 (Flink Streaming Job).
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID c4e24940-a14f-4a1c-b459-6136c9d62d2f (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id c87cfdc280a16da2abbbc312c5b5c335.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:241 - Initializing job Flink Streaming Job (eb5b1c45722cc6aec8674852fa775232).
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (eb5b1c45722cc6aec8674852fa775232).
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (eb5b1c45722cc6aec8674852fa775232).
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@420f574f @ akka://flink/user/jobmanager_1
2020-01-15 09:49:16 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (eb5b1c45722cc6aec8674852fa775232) was granted leadership with session id 02a1544c-0c8b-41d2-849b-122fb0c173fd at akka://flink/user/jobmanager_1.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (eb5b1c45722cc6aec8674852fa775232) under job master id 849b122fb0c173fd02a1544c0c8b41d2.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (eb5b1c45722cc6aec8674852fa775232) switched from state CREATED to RUNNING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2a8f47f8946e08524c2208010f84133f}]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f40590ded677cc74175bb3234beca573}]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{dd46e2f5e3086fbecea478ba975d6905}]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2d55d0b58b12feedb199ae0f575a79f7}]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ce746c2bbb7123f0d017bc4aacfa6468}]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9fe9d69578d77356d65e1f7b4fa01dde}]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) switched from CREATED to SCHEDULED.
2020-01-15 09:49:16 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=02a1544c-0c8b-41d2-849b-122fb0c173fd
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(88b4282d9d96c8380ff0c1e70a634fe9)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:302 - Registering job manager 849b122fb0c173fd02a1544c0c8b41d2@akka://flink/user/jobmanager_1 for job eb5b1c45722cc6aec8674852fa775232.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager 849b122fb0c173fd02a1544c0c8b41d2@akka://flink/user/jobmanager_1 for job eb5b1c45722cc6aec8674852fa775232.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 88b4282d9d96c8380ff0c1e70a634fe9.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{2a8f47f8946e08524c2208010f84133f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb5b1c45722cc6aec8674852fa775232 with allocation id b8a4fa6b99835d7d64fff02037f8caf3.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f40590ded677cc74175bb3234beca573}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{dd46e2f5e3086fbecea478ba975d6905}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{2d55d0b58b12feedb199ae0f575a79f7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request b8a4fa6b99835d7d64fff02037f8caf3 for job eb5b1c45722cc6aec8674852fa775232 from resource manager with leader id 88b4282d9d96c8380ff0c1e70a634fe9.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb5b1c45722cc6aec8674852fa775232 with allocation id 6f9fcb524c6e68acd0a8879b65afe681.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ce746c2bbb7123f0d017bc4aacfa6468}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb5b1c45722cc6aec8674852fa775232 with allocation id e0ce997d5821643082e47517ee293a9e.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb5b1c45722cc6aec8674852fa775232 with allocation id 379634ff886c4c13d7313bac63091745.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb5b1c45722cc6aec8674852fa775232 with allocation id 3cffc14a204d2f70796c48ff2ef02bc9.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{9fe9d69578d77356d65e1f7b4fa01dde}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb5b1c45722cc6aec8674852fa775232 with allocation id 880d43e00c16ab119994851ef58e3c16.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for b8a4fa6b99835d7d64fff02037f8caf3.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job eb5b1c45722cc6aec8674852fa775232 for job leader monitoring.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 6f9fcb524c6e68acd0a8879b65afe681 for job eb5b1c45722cc6aec8674852fa775232 from resource manager with leader id 88b4282d9d96c8380ff0c1e70a634fe9.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 6f9fcb524c6e68acd0a8879b65afe681.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job eb5b1c45722cc6aec8674852fa775232 for job leader monitoring.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request e0ce997d5821643082e47517ee293a9e for job eb5b1c45722cc6aec8674852fa775232 from resource manager with leader id 88b4282d9d96c8380ff0c1e70a634fe9.
2020-01-15 09:49:16 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 02a1544c-0c8b-41d2-849b-122fb0c173fd.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for e0ce997d5821643082e47517ee293a9e.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job eb5b1c45722cc6aec8674852fa775232 for job leader monitoring.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 379634ff886c4c13d7313bac63091745 for job eb5b1c45722cc6aec8674852fa775232 from resource manager with leader id 88b4282d9d96c8380ff0c1e70a634fe9.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 379634ff886c4c13d7313bac63091745.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job eb5b1c45722cc6aec8674852fa775232 for job leader monitoring.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 3cffc14a204d2f70796c48ff2ef02bc9 for job eb5b1c45722cc6aec8674852fa775232 from resource manager with leader id 88b4282d9d96c8380ff0c1e70a634fe9.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 3cffc14a204d2f70796c48ff2ef02bc9.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job eb5b1c45722cc6aec8674852fa775232 for job leader monitoring.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 880d43e00c16ab119994851ef58e3c16 for job eb5b1c45722cc6aec8674852fa775232 from resource manager with leader id 88b4282d9d96c8380ff0c1e70a634fe9.
2020-01-15 09:49:16 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 02a1544c-0c8b-41d2-849b-122fb0c173fd.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:49:16 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 02a1544c-0c8b-41d2-849b-122fb0c173fd.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 880d43e00c16ab119994851ef58e3c16.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job eb5b1c45722cc6aec8674852fa775232 for job leader monitoring.
2020-01-15 09:49:16 [mini-cluster-io-thread-1] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 02a1544c-0c8b-41d2-849b-122fb0c173fd.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job eb5b1c45722cc6aec8674852fa775232.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1241 - Establish JobManager connection for job eb5b1c45722cc6aec8674852fa775232.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job eb5b1c45722cc6aec8674852fa775232.
2020-01-15 09:49:16 [mini-cluster-io-thread-2] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (1/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (2/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (3/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (4/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (5/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (6/6) (attempt #0) to c4e24940-a14f-4a1c-b459-6136c9d62d2f @ localhost (dataPort=-1)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) [DEPLOYING]
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) [DEPLOYING]
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) [DEPLOYING]
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) [DEPLOYING].
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) [DEPLOYING].
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) [DEPLOYING]
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) [DEPLOYING].
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) [DEPLOYING].
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) [DEPLOYING]
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) [DEPLOYING].
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (1/6).
2020-01-15 09:49:16 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) [DEPLOYING]
2020-01-15 09:49:16 [Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:49:16 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (c2d2b9f14e08fb54a1bcb04befbd719e) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) [DEPLOYING]
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) [DEPLOYING].
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (d1ca7f455c89e86638f1f9d19e01d0ef) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (a0132714507d23976f171d4e8c1892eb) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (f2a70eba8fab43d86955ccd1fae26034) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (2/6).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (d149fd49d1ddf4a9ec4c7c326cc7031c) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (e2f7f041f1564a19136877b2d910b8ee) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (37ef7343707110c726bd575764803508) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) [DEPLOYING]
2020-01-15 09:49:16 [Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) [DEPLOYING].
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) [DEPLOYING]
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:593 - Loading JAR files for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) [DEPLOYING].
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:619 - Registering task at network: TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (de5ec4cc4f5fe9c73e666057bfefbf6f) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (b490c9292636e1b687e82d8afe840fa9) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] WARN  MetricGroup:143 - The operator name TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) exceeded the 80 characters length limit and was truncated.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (3/6).
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 880d43e00c16ab119994851ef58e3c16.
2020-01-15 09:49:16 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) [DEPLOYING]
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 6f9fcb524c6e68acd0a8879b65afe681.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 3cffc14a204d2f70796c48ff2ef02bc9.
2020-01-15 09:49:16 [Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot b8a4fa6b99835d7d64fff02037f8caf3.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot e0ce997d5821643082e47517ee293a9e.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskSlotTable:237 - Activate slot 379634ff886c4c13d7313bac63091745.
2020-01-15 09:49:16 [Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (4/6).
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:49:16 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:49:16 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (927dc924250f419197867bddfa2d824e) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (6/6).
2020-01-15 09:49:16 [Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) [DEPLOYING]
2020-01-15 09:49:16 [Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (332f97408386b9c3abe7c51c5e44fe44) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (5/6).
2020-01-15 09:49:16 [Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) [DEPLOYING]
2020-01-15 09:49:16 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) switched from CREATED to DEPLOYING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) [DEPLOYING]
2020-01-15 09:49:16 [Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) [DEPLOYING].
2020-01-15 09:49:16 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) [DEPLOYING].
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (391bd6ff339a1ea271d02a3839bd1f77) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (151e25c13d034a87e024964e905d77af) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:16 [Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:16 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  HeapKeyedStateBackend:140 - Initializing heap keyed state backend with stream factory.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:49:16 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:49:16 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:49:16 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:49:16 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:49:16 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:49:16 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:16 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:17 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:17 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:49:28 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:49:28 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-71078df7-6025-4f6f-92be-be3348aca159
2020-01-15 09:49:28 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:49:28 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:49:43 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:49:43 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:49:43 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:43 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:49:44 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:49:44 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:49:44 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:49:44 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:49:44 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:49:44 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:49:44 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:49:45 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:49:45 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:46041]
2020-01-15 09:49:45 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:46041
2020-01-15 09:49:45 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:49:45 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:49:45 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-199ba703-e5b3-4df7-80fb-43f2f2ac5a92
2020-01-15 09:49:45 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:39027 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:49:45 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-f25e3e2a-562f-4cd0-8913-c30e73f64ee3
2020-01-15 09:49:45 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-03f47a92-394a-4cda-b043-5b13e8e3a4b9
2020-01-15 09:49:45 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:49:45 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 9a480960-05c9-42db-a55a-78cc1cf862bb
2020-01-15 09:49:45 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:49:45 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-11dacd15-e421-48b8-b012-339ddc274c68 for spill files.
2020-01-15 09:49:45 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-b45b155a-da92-4f56-b5d9-f5a0b98182cf for spill files.
2020-01-15 09:49:45 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:49:45 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:49:45 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:49:45 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:49:45 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:49:45 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:49:45 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:49:45 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-e99be699-0279-42b2-b1d1-e7fa688eeb07
2020-01-15 09:49:45 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:49:46 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:49:46 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:49:46 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:49:46 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:41365
2020-01-15 09:49:46 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@d535a3d @ http://localhost:41365
2020-01-15 09:49:46 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:41365 was granted leadership with leaderSessionID=4e8d3d90-56a0-4535-ab62-401e5dbd1f7e
2020-01-15 09:49:46 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:41365 , session=4e8d3d90-56a0-4535-ab62-401e5dbd1f7e
2020-01-15 09:49:46 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:49:46 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@2563411 @ akka://flink/user/resourcemanager
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token bded9c369eb27f87503b1d84d0194fa7
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@41be94bf @ akka://flink/user/dispatcher
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 49362746-b8ea-42cd-8691-c9b80f4685f4
2020-01-15 09:49:46 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=503b1d84-d019-4fa7-bded-9c369eb27f87
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=49362746-b8ea-42cd-8691-c9b80f4685f4
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(bded9c369eb27f87503b1d84d0194fa7).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:264 - Received JobGraph submission e9023c96c3b959452dc0762528264d10 (Flink Streaming Job).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:321 - Submitting job e9023c96c3b959452dc0762528264d10 (Flink Streaming Job).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 9a480960-05c9-42db-a55a-78cc1cf862bb (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id d5321652f4ebd523348ba3c6526a5631.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:241 - Initializing job Flink Streaming Job (e9023c96c3b959452dc0762528264d10).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (e9023c96c3b959452dc0762528264d10).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (e9023c96c3b959452dc0762528264d10).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:222 - Successfully ran initialization on master in 0 ms.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@2e3b213 @ akka://flink/user/jobmanager_1
2020-01-15 09:49:46 [mini-cluster-io-thread-4] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (e9023c96c3b959452dc0762528264d10) was granted leadership with session id 21ec8166-d9d3-4b7f-a8f7-e4e205d50c22 at akka://flink/user/jobmanager_1.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (e9023c96c3b959452dc0762528264d10) under job master id a8f7e4e205d50c2221ec8166d9d34b7f.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (e9023c96c3b959452dc0762528264d10) switched from state CREATED to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{693114438649dea5f9251ec4f86c4d0a}]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3b26102ed6ae58c1002d26bbff227438}]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6505f3e633869faa822e386b104e3842}]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8cde688e93c4cf52b83ca0a13410f6e3}]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1fd592e40bc0868e2b0345b573a3bcc7}]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{aa422394caf8864997c5f5451e794696}]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) switched from CREATED to SCHEDULED.
2020-01-15 09:49:46 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=21ec8166-d9d3-4b7f-a8f7-e4e205d50c22
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(bded9c369eb27f87503b1d84d0194fa7)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:302 - Registering job manager a8f7e4e205d50c2221ec8166d9d34b7f@akka://flink/user/jobmanager_1 for job e9023c96c3b959452dc0762528264d10.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager a8f7e4e205d50c2221ec8166d9d34b7f@akka://flink/user/jobmanager_1 for job e9023c96c3b959452dc0762528264d10.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: bded9c369eb27f87503b1d84d0194fa7.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{693114438649dea5f9251ec4f86c4d0a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job e9023c96c3b959452dc0762528264d10 with allocation id c834b0736436163b0059737c50975edd.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{3b26102ed6ae58c1002d26bbff227438}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{6505f3e633869faa822e386b104e3842}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{8cde688e93c4cf52b83ca0a13410f6e3}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{1fd592e40bc0868e2b0345b573a3bcc7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{aa422394caf8864997c5f5451e794696}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job e9023c96c3b959452dc0762528264d10 with allocation id 45793ab57939be70562ccc71f5135602.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job e9023c96c3b959452dc0762528264d10 with allocation id 6aea091e6f1fb18f0416d00d0215fe58.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job e9023c96c3b959452dc0762528264d10 with allocation id 3fe542fe2600cb7e415a4d3f4f1e0944.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job e9023c96c3b959452dc0762528264d10 with allocation id 4d2eaecb693355a5c657b8eb3bfb291b.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job e9023c96c3b959452dc0762528264d10 with allocation id e626b9108ce834d425e49002ff90cba0.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request c834b0736436163b0059737c50975edd for job e9023c96c3b959452dc0762528264d10 from resource manager with leader id bded9c369eb27f87503b1d84d0194fa7.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for c834b0736436163b0059737c50975edd.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job e9023c96c3b959452dc0762528264d10 for job leader monitoring.
2020-01-15 09:49:46 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 21ec8166-d9d3-4b7f-a8f7-e4e205d50c22.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 45793ab57939be70562ccc71f5135602 for job e9023c96c3b959452dc0762528264d10 from resource manager with leader id bded9c369eb27f87503b1d84d0194fa7.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 45793ab57939be70562ccc71f5135602.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job e9023c96c3b959452dc0762528264d10 for job leader monitoring.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 6aea091e6f1fb18f0416d00d0215fe58 for job e9023c96c3b959452dc0762528264d10 from resource manager with leader id bded9c369eb27f87503b1d84d0194fa7.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 6aea091e6f1fb18f0416d00d0215fe58.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job e9023c96c3b959452dc0762528264d10 for job leader monitoring.
2020-01-15 09:49:46 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 21ec8166-d9d3-4b7f-a8f7-e4e205d50c22.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 3fe542fe2600cb7e415a4d3f4f1e0944 for job e9023c96c3b959452dc0762528264d10 from resource manager with leader id bded9c369eb27f87503b1d84d0194fa7.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 3fe542fe2600cb7e415a4d3f4f1e0944.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job e9023c96c3b959452dc0762528264d10 for job leader monitoring.
2020-01-15 09:49:46 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 21ec8166-d9d3-4b7f-a8f7-e4e205d50c22.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request 4d2eaecb693355a5c657b8eb3bfb291b for job e9023c96c3b959452dc0762528264d10 from resource manager with leader id bded9c369eb27f87503b1d84d0194fa7.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for 4d2eaecb693355a5c657b8eb3bfb291b.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job e9023c96c3b959452dc0762528264d10 for job leader monitoring.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:836 - Receive slot request e626b9108ce834d425e49002ff90cba0 for job e9023c96c3b959452dc0762528264d10 from resource manager with leader id bded9c369eb27f87503b1d84d0194fa7.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:848 - Allocated slot for e626b9108ce834d425e49002ff90cba0.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:193 - Add job e9023c96c3b959452dc0762528264d10 for job leader monitoring.
2020-01-15 09:49:46 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 21ec8166-d9d3-4b7f-a8f7-e4e205d50c22.
2020-01-15 09:49:46 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 21ec8166-d9d3-4b7f-a8f7-e4e205d50c22.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job e9023c96c3b959452dc0762528264d10.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1241 - Establish JobManager connection for job e9023c96c3b959452dc0762528264d10.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job e9023c96c3b959452dc0762528264d10.
2020-01-15 09:49:46 [mini-cluster-io-thread-6] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (1/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (2/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (3/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (4/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (5/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (6/6) (attempt #0) to 9a480960-05c9-42db-a55a-78cc1cf862bb @ localhost (dataPort=-1)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (64ba82d125562b12cc69cf59f0fd711c) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (b0fc7c7a969c8b333cdf0b844dc4e80f) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (f40cabf55de5d3a9d6bf57c43ce2a0d8) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (07b62aaba4cf6d2fdb2c60b401b59118) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (3b93164cf0797044290fcd8d56a34b73) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (1/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (9368e1378477ffdbbd42cc7724d00170) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) [DEPLOYING]
2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:593 - Loading JAR files for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) [DEPLOYING].
2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:619 - Registering task at network: TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 45793ab57939be70562ccc71f5135602.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 6aea091e6f1fb18f0416d00d0215fe58.
2020-01-15 09:49:46 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 3fe542fe2600cb7e415a4d3f4f1e0944.
2020-01-15 09:49:46 [Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) [DEPLOYING]
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot e626b9108ce834d425e49002ff90cba0.
2020-01-15 09:49:46 [Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) [DEPLOYING].
2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot c834b0736436163b0059737c50975edd.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTable:237 - Activate slot 4d2eaecb693355a5c657b8eb3bfb291b.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (c6520c6312a65d93efad9b19289edfa9) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (9d322b82ec7ad84de932ad7d1f376108) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] WARN  MetricGroup:143 - The operator name TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) exceeded the 80 characters length limit and was truncated.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (3/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (2/6).
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:49:46 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:49:46 [Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:49:46 [Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) [DEPLOYING].
2020-01-15 09:49:46 [Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) [DEPLOYING].
2020-01-15 09:49:46 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) [DEPLOYING]
2020-01-15 09:49:46 [Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) [DEPLOYING].
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (6fbf4fcf1880be48c237ccc6b5de427b) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (4/6).
2020-01-15 09:49:46 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) [DEPLOYING]
2020-01-15 09:49:46 [Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) [DEPLOYING].
2020-01-15 09:49:46 [Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) [DEPLOYING].
2020-01-15 09:49:46 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (5/6).
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (d543253381da887e83b26fa7b7904a83) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) [DEPLOYING].
2020-01-15 09:49:46 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (6/6).
2020-01-15 09:49:46 [Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (8076bb70a44d696319ce3a80e60d9020) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) [DEPLOYING]
2020-01-15 09:49:46 [Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) [DEPLOYING].
2020-01-15 09:49:46 [Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) [DEPLOYING].
2020-01-15 09:49:46 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (bb6b977d717a455f257b16c344a0d920) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) switched from CREATED to DEPLOYING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) [DEPLOYING]
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:46 [Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:46 [Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) [DEPLOYING].
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:46 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (ed1cca7aa44d64d9dcf51337571da126) switched from DEPLOYING to RUNNING.
2020-01-15 09:49:46 [Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:46 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  HeapKeyedStateBackend:140 - Initializing heap keyed state backend with stream factory.
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:46 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:47 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:49:47 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:49:47 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:49:47 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:49:47 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:49:47 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:49:47 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-11, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: iUMHdJfXT1qRuSYq4kW-zg
2020-01-15 09:49:47 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-11, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:49:56 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:49:56 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:49:56 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:49:56 [IOManagerAsync shutdown hook] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-11dacd15-e421-48b8-b012-339ddc274c68
2020-01-15 09:49:56 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-e99be699-0279-42b2-b1d1-e7fa688eeb07
2020-01-15 09:51:45 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:51:45 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:51:45 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:51:45 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:51:45 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:51:45 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:51:46 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:51:46 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:51:46 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:51:46 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:51:46 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:51:46 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:51:47 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:43831]
2020-01-15 09:51:47 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:43831
2020-01-15 09:51:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:51:47 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:51:47 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-000df35d-ce92-4bd7-a7e8-649a665c3475
2020-01-15 09:51:47 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:42051 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:51:47 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-0b9dedba-6e16-44d0-8b56-88a804e0ec79
2020-01-15 09:51:47 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-9427905f-d35d-4532-8f67-5230f2f8afa5
2020-01-15 09:51:47 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:51:47 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: 134b6ca4-3ffa-4173-86ed-2bc59cbceb27
2020-01-15 09:51:47 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:51:47 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-8b95fea0-bf0f-485c-8d03-75059e97c1f1 for spill files.
2020-01-15 09:51:47 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-335f1317-46f1-448e-bc4b-043bda8deee0 for spill files.
2020-01-15 09:51:47 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:51:47 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:51:47 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:51:47 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:51:47 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:51:47 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:51:47 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:51:47 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-58cc533f-80f8-4fab-9c92-1e4ed345311c
2020-01-15 09:51:47 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:51:48 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:51:48 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:51:48 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:51:48 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:40543
2020-01-15 09:51:48 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@9e54c59 @ http://localhost:40543
2020-01-15 09:51:48 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:40543 was granted leadership with leaderSessionID=37a5ee9d-482a-4f1c-a263-364d4bc13516
2020-01-15 09:51:48 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:40543 , session=37a5ee9d-482a-4f1c-a263-364d4bc13516
2020-01-15 09:51:48 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:51:48 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@4a7b81b6 @ akka://flink/user/resourcemanager
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@aa3f4a3 @ akka://flink/user/dispatcher
2020-01-15 09:51:48 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 0ae1a578-6883-4873-81b9-c6621085c00f
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 85aabd6a55eeeb1aaad885ff8dd44b51
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=0ae1a578-6883-4873-81b9-c6621085c00f
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=aad885ff-8dd4-4b51-85aa-bd6a55eeeb1a
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(85aabd6a55eeeb1aaad885ff8dd44b51).
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:264 - Received JobGraph submission 236c95f957978458bbbf8dd881ffb69a (Flink Streaming Job).
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:321 - Submitting job 236c95f957978458bbbf8dd881ffb69a (Flink Streaming Job).
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 53942d8d4f2edab4d90eb1ce90fa64a8.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:241 - Initializing job Flink Streaming Job (236c95f957978458bbbf8dd881ffb69a).
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (236c95f957978458bbbf8dd881ffb69a).
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (236c95f957978458bbbf8dd881ffb69a).
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:222 - Successfully ran initialization on master in 2 ms.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@65a6a69d @ akka://flink/user/jobmanager_1
2020-01-15 09:51:48 [mini-cluster-io-thread-2] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (236c95f957978458bbbf8dd881ffb69a) was granted leadership with session id 3568c006-f17d-4962-afad-8e2effec1cea at akka://flink/user/jobmanager_1.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (236c95f957978458bbbf8dd881ffb69a) under job master id afad8e2effec1cea3568c006f17d4962.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (236c95f957978458bbbf8dd881ffb69a) switched from state CREATED to RUNNING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{cdcbdb958236fae941642eb7a4d408a3}]
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b3d2dfbfcc5dd06092aa7aee794a14b8}]
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{109d379169dbbf3ea11688cfe8b826f7}]
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{846fbbe4dc8e6b38679c720d9707fee9}]
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{203f03e0f94a7fda6a6c24116b1bf178}]
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{86d2f64cc1693cb4e4b596b7d1d71ef8}]
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) switched from CREATED to SCHEDULED.
2020-01-15 09:51:48 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=3568c006-f17d-4962-afad-8e2effec1cea
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(85aabd6a55eeeb1aaad885ff8dd44b51)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:302 - Registering job manager afad8e2effec1cea3568c006f17d4962@akka://flink/user/jobmanager_1 for job 236c95f957978458bbbf8dd881ffb69a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:657 - Registered job manager afad8e2effec1cea3568c006f17d4962@akka://flink/user/jobmanager_1 for job 236c95f957978458bbbf8dd881ffb69a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 85aabd6a55eeeb1aaad885ff8dd44b51.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{cdcbdb958236fae941642eb7a4d408a3}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b3d2dfbfcc5dd06092aa7aee794a14b8}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 236c95f957978458bbbf8dd881ffb69a with allocation id 9c1baa1f45f292d79f7bb67bc1a005c5.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 9c1baa1f45f292d79f7bb67bc1a005c5 for job 236c95f957978458bbbf8dd881ffb69a from resource manager with leader id 85aabd6a55eeeb1aaad885ff8dd44b51.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 236c95f957978458bbbf8dd881ffb69a with allocation id 1f33a2a21e144d69b545ed58e226c8f9.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{109d379169dbbf3ea11688cfe8b826f7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{846fbbe4dc8e6b38679c720d9707fee9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 236c95f957978458bbbf8dd881ffb69a with allocation id aa4d9ae8cfa721290606eb68100f7e9a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{203f03e0f94a7fda6a6c24116b1bf178}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 236c95f957978458bbbf8dd881ffb69a with allocation id aead38701a79444bbb2fed3e6361f876.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-4] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{86d2f64cc1693cb4e4b596b7d1d71ef8}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 236c95f957978458bbbf8dd881ffb69a with allocation id 938997883003507979ea2c91dac348b9.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 9c1baa1f45f292d79f7bb67bc1a005c5.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 236c95f957978458bbbf8dd881ffb69a for job leader monitoring.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 236c95f957978458bbbf8dd881ffb69a with allocation id cd6c1d45fc58dfaef8ae8557d1c7036c.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 1f33a2a21e144d69b545ed58e226c8f9 for job 236c95f957978458bbbf8dd881ffb69a from resource manager with leader id 85aabd6a55eeeb1aaad885ff8dd44b51.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 1f33a2a21e144d69b545ed58e226c8f9.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 236c95f957978458bbbf8dd881ffb69a for job leader monitoring.
2020-01-15 09:51:48 [mini-cluster-io-thread-6] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3568c006-f17d-4962-afad-8e2effec1cea.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request aa4d9ae8cfa721290606eb68100f7e9a for job 236c95f957978458bbbf8dd881ffb69a from resource manager with leader id 85aabd6a55eeeb1aaad885ff8dd44b51.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for aa4d9ae8cfa721290606eb68100f7e9a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 236c95f957978458bbbf8dd881ffb69a for job leader monitoring.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request aead38701a79444bbb2fed3e6361f876 for job 236c95f957978458bbbf8dd881ffb69a from resource manager with leader id 85aabd6a55eeeb1aaad885ff8dd44b51.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for aead38701a79444bbb2fed3e6361f876.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 236c95f957978458bbbf8dd881ffb69a for job leader monitoring.
2020-01-15 09:51:48 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3568c006-f17d-4962-afad-8e2effec1cea.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 938997883003507979ea2c91dac348b9 for job 236c95f957978458bbbf8dd881ffb69a from resource manager with leader id 85aabd6a55eeeb1aaad885ff8dd44b51.
2020-01-15 09:51:48 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3568c006-f17d-4962-afad-8e2effec1cea.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 938997883003507979ea2c91dac348b9.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 236c95f957978458bbbf8dd881ffb69a for job leader monitoring.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request cd6c1d45fc58dfaef8ae8557d1c7036c for job 236c95f957978458bbbf8dd881ffb69a from resource manager with leader id 85aabd6a55eeeb1aaad885ff8dd44b51.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for cd6c1d45fc58dfaef8ae8557d1c7036c.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 236c95f957978458bbbf8dd881ffb69a for job leader monitoring.
2020-01-15 09:51:48 [mini-cluster-io-thread-3] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3568c006-f17d-4962-afad-8e2effec1cea.
2020-01-15 09:51:48 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 3568c006-f17d-4962-afad-8e2effec1cea.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 236c95f957978458bbbf8dd881ffb69a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1241 - Establish JobManager connection for job 236c95f957978458bbbf8dd881ffb69a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 236c95f957978458bbbf8dd881ffb69a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 236c95f957978458bbbf8dd881ffb69a.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [mini-cluster-io-thread-3] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-15 09:51:48 [mini-cluster-io-thread-6] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (1/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (2/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (3/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (4/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (5/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (6/6) (attempt #0) to 134b6ca4-3ffa-4173-86ed-2bc59cbceb27 @ localhost (dataPort=-1)
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:51:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) switched from CREATED to DEPLOYING.
2020-01-15 09:51:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) [DEPLOYING]
2020-01-15 09:51:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) [DEPLOYING].
2020-01-15 09:51:48 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:51:48 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) [DEPLOYING].
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) [DEPLOYING]
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) [DEPLOYING]
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (434f5e098eadc8410e88c5da12497236) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (fae820be48d0a36bb93ffbbd4ca49cca) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) [DEPLOYING].
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) [DEPLOYING]
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) [DEPLOYING]
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) [DEPLOYING].
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) [DEPLOYING]
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (1083e971d0d29910680b7fb133bbd188) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (b203cfeeb07656361ba7fe1313f64533) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (093335765b26d4d13b10a53295512f32) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (e0dbdeb5630d9687ed12b712b17a95d3) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1).
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (1/6).
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) [DEPLOYING]
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:593 - Loading JAR files for task TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) [DEPLOYING].
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (2/6).
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:51:49 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:51:49 [Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) [DEPLOYING]
2020-01-15 09:51:49 [Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:619 - Registering task at network: TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) [DEPLOYING].
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (3/6).
2020-01-15 09:51:49 [Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) [DEPLOYING].
2020-01-15 09:51:49 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) [DEPLOYING]
2020-01-15 09:51:49 [Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) [DEPLOYING].
2020-01-15 09:51:49 [Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) [DEPLOYING].
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (eef5fb98a1108b878a03f3cc61bebf5f) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (4/6).
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] WARN  MetricGroup:143 - The operator name TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) exceeded the 80 characters length limit and was truncated.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (5/6).
2020-01-15 09:51:49 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) [DEPLOYING]
2020-01-15 09:51:49 [Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) [DEPLOYING]
2020-01-15 09:51:49 [Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) [DEPLOYING].
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) [DEPLOYING].
2020-01-15 09:51:49 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot aa4d9ae8cfa721290606eb68100f7e9a.
2020-01-15 09:51:49 [Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) [DEPLOYING]
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot aead38701a79444bbb2fed3e6361f876.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 938997883003507979ea2c91dac348b9.
2020-01-15 09:51:49 [Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) [DEPLOYING].
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 9c1baa1f45f292d79f7bb67bc1a005c5.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot cd6c1d45fc58dfaef8ae8557d1c7036c.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskSlotTable:237 - Activate slot 1f33a2a21e144d69b545ed58e226c8f9.
2020-01-15 09:51:49 [Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) [DEPLOYING].
2020-01-15 09:51:49 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (5740845da9c9d30d8f56cebbb0ca58c4) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (6/6).
2020-01-15 09:51:49 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (00048239909c3e404c5023b12901d8c6) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (ef4322b79954053f9389c58836c8bb2f) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (439e73f3c6dfc111ede2089fe837978e) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) switched from CREATED to DEPLOYING.
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (37dff9218489bd32789a4ae89c15f2b7) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) [DEPLOYING]
2020-01-15 09:51:49 [Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) [DEPLOYING].
2020-01-15 09:51:49 [Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) [DEPLOYING].
2020-01-15 09:51:49 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:51:49 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (619b8c5a54294fc0e62528c1199d35d3) switched from DEPLOYING to RUNNING.
2020-01-15 09:51:49 [TriggerWindow(SlidingProcessingTimeWindows(15000, 1000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  HeapKeyedStateBackend:140 - Initializing heap keyed state backend with stream factory.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:51:49 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:51:49 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:51:49 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:51:49 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:51:49 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:51:49 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-12, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:51:49 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:51:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:51:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:727 - [Consumer clientId=consumer-12, groupId=flink_consumer] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 09:51:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:51:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:727 - [Consumer clientId=consumer-12, groupId=flink_consumer] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 09:51:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-12, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:51:50 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Fetcher:584 - [Consumer clientId=consumer-12, groupId=flink_consumer] Resetting offset for partition source-topic-0 to offset 754.
2020-01-15 09:51:58 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:51:58 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:42051
2020-01-15 09:51:58 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-58cc533f-80f8-4fab-9c92-1e4ed345311c
2020-01-15 09:51:58 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:51:58 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:54:05 [main] INFO  TypeExtractor:1815 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
2020-01-15 09:54:05 [main] INFO  TypeExtractor:1818 - class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
2020-01-15 09:54:05 [main] INFO  TypeExtractor:1857 - Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:54:05 [main] INFO  LocalStreamEnvironment:108 - Running job on local embedded Flink mini cluster
2020-01-15 09:54:06 [main] INFO  MiniCluster:253 - Starting Flink Mini Cluster
2020-01-15 09:54:06 [main] INFO  MiniCluster:262 - Starting Metrics Registry
2020-01-15 09:54:06 [main] INFO  MetricRegistryImpl:114 - No metrics reporter configured, no metrics will be exposed/reported.
2020-01-15 09:54:06 [main] INFO  MiniCluster:266 - Starting RPC Service(s)
2020-01-15 09:54:06 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:54:06 [main] INFO  AkkaRpcServiceUtils:244 - Trying to start actor system at :0
2020-01-15 09:54:06 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2020-01-15 09:54:07 [flink-metrics-2] INFO  Remoting:83 - Starting remoting
2020-01-15 09:54:07 [flink-metrics-2] INFO  Remoting:83 - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:42485]
2020-01-15 09:54:07 [main] INFO  AkkaRpcServiceUtils:256 - Actor system started at akka.tcp://flink-metrics@127.0.1.1:42485
2020-01-15 09:54:07 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-01-15 09:54:07 [main] INFO  MiniCluster:397 - Starting high-availability services
2020-01-15 09:54:07 [main] INFO  BlobServer:141 - Created BLOB server storage directory /tmp/blobStore-f5ab70c0-05b1-4ffa-9749-cff14b45f010
2020-01-15 09:54:07 [main] INFO  BlobServer:203 - Started BLOB server at 0.0.0.0:39813 - max concurrent requests: 50 - max backlog: 1000
2020-01-15 09:54:07 [main] INFO  PermanentBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-21181589-ade1-4a36-a350-063d0b1d8bdd
2020-01-15 09:54:07 [main] INFO  TransientBlobCache:107 - Created BLOB cache storage directory /tmp/blobStore-807035da-ad41-403d-96b4-3af13aea1bb3
2020-01-15 09:54:07 [main] INFO  MiniCluster:479 - Starting 1 TaskManger(s)
2020-01-15 09:54:07 [main] INFO  TaskManagerRunner:351 - Starting TaskManager with ResourceID: b35d3625-2ff2-4547-97eb-e96d595d1e85
2020-01-15 09:54:07 [main] INFO  TaskManagerServices:519 - Temporary file directory '/tmp': total 96 GB, usable 65 GB (67.71% usable)
2020-01-15 09:54:07 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-io-205de482-4b53-437a-a6b3-d2d5fab10a4b for spill files.
2020-01-15 09:54:07 [main] INFO  FileChannelManagerImpl:76 - FileChannelManager uses directory /tmp/flink-netty-shuffle-7c2c8862-78b7-42de-8b46-af462e25c2b6 for spill files.
2020-01-15 09:54:07 [main] INFO  NetworkBufferPool:140 - Allocated 829 MB for network buffer pool (number of memory segments: 26552, bytes per segment: 32768).
2020-01-15 09:54:07 [main] INFO  NettyShuffleEnvironment:283 - Starting the network environment and its components.
2020-01-15 09:54:07 [main] INFO  KvStateService:89 - Starting the kvState service and its components.
2020-01-15 09:54:07 [main] INFO  TaskManagerServices:364 - Limiting managed memory to 0.7 of the currently free heap space (5219 MB), memory will be allocated lazily.
2020-01-15 09:54:07 [main] INFO  TaskManagerConfiguration:197 - Messages have a max timeout of 10000 ms
2020-01-15 09:54:07 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-01-15 09:54:07 [flink-akka.actor.default-dispatcher-4] INFO  JobLeaderService:125 - Start job leader service.
2020-01-15 09:54:07 [flink-akka.actor.default-dispatcher-4] INFO  FileCache:107 - User file cache uses directory /tmp/flink-dist-cache-f1ac9a0d-df49-4b1f-ad03-387bce93903c
2020-01-15 09:54:07 [main] INFO  DispatcherRestEndpoint:136 - Starting rest endpoint.
2020-01-15 09:54:08 [main] WARN  WebMonitorUtils:87 - Log file environment variable 'log.file' is not set.
2020-01-15 09:54:08 [main] WARN  WebMonitorUtils:93 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-01-15 09:54:08 [main] INFO  DispatcherRestEndpoint:114 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-01-15 09:54:08 [main] INFO  DispatcherRestEndpoint:233 - Rest endpoint listening at localhost:46411
2020-01-15 09:54:08 [main] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@d535a3d @ http://localhost:46411
2020-01-15 09:54:08 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:711 - http://localhost:46411 was granted leadership with leaderSessionID=aa85f43b-cf59-401f-9b44-6e09c8c78ec0
2020-01-15 09:54:08 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-01-15 09:54:08 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader http://localhost:46411 , session=aa85f43b-cf59-401f-9b44-6e09c8c78ec0
2020-01-15 09:54:08 [main] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6b8ee8cb @ akka://flink/user/resourcemanager
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@200a39e2 @ akka://flink/user/dispatcher
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:921 - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 854a05baf59056f1d7207c5cd2834247
2020-01-15 09:54:08 [main] INFO  MiniCluster:362 - Flink Mini Cluster started successfully
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-4] INFO  SlotManagerImpl:215 - Starting the SlotManager.
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=d7207c5c-d283-4247-854a-05baf59056f1
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-5] INFO  StandaloneDispatcher:885 - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 66a9118a-0424-42bb-b4e3-412f8a4cb328
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:717 - Recovering all persisted jobs.
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-5] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=66a9118a-0424-42bb-b4e3-412f8a4cb328
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:1005 - Connecting to ResourceManager akka://flink/user/resourcemanager(854a05baf59056f1d7207c5cd2834247).
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:264 - Received JobGraph submission 0d3ff66110396e290448202a019acaf5 (Flink Streaming Job).
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:321 - Submitting job 0d3ff66110396e290448202a019acaf5 (Flink Streaming Job).
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:713 - Registering TaskManager with ResourceID b35d3625-2ff2-4547-97eb-e96d595d1e85 (akka://flink/user/taskmanager_0) at ResourceManager
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-2] INFO  AkkaRpcService:223 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:100 - Successful registration at resource manager akka://flink/user/resourcemanager under registration id ac822e0dbe78c2da8d397fda4b67c16e.
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:241 - Initializing job Flink Streaming Job (0d3ff66110396e290448202a019acaf5).
2020-01-15 09:54:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:171 - Using restart strategy NoRestartStrategy for Flink Streaming Job (0d3ff66110396e290448202a019acaf5).
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:516 - Job recovers via failover strategy: full graph restart
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Running initialization on master for job Flink Streaming Job (0d3ff66110396e290448202a019acaf5).
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:222 - Successfully ran initialization on master in 3 ms.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:300 - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@680edff1 @ akka://flink/user/jobmanager_1
2020-01-15 09:54:09 [mini-cluster-io-thread-3] INFO  JobManagerRunner:313 - JobManager runner for job Flink Streaming Job (0d3ff66110396e290448202a019acaf5) was granted leadership with session id f2573d65-d542-4209-8d48-90144742d170 at akka://flink/user/jobmanager_1.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:709 - Starting execution of job Flink Streaming Job (0d3ff66110396e290448202a019acaf5) under job master id 8d4890144742d170f2573d65d5424209.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1324 - Job Flink Streaming Job (0d3ff66110396e290448202a019acaf5) switched from state CREATED to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f5a8886ce91648cab2fcf2ae1543536e}]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d3c392e2c3991716a95e200ffdd49a92}]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ed5767572d6c50abdef4105f1dad5b55}]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bebd9e4847d9d6cc7311c053ef641615}]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{77ce4cabac48ad039a7fe20e9431187f}]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:369 - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b8ce3e4c7aea7a4bfdfa64da00a4309e}]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) switched from CREATED to SCHEDULED.
2020-01-15 09:54:09 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:250 - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=f2573d65-d542-4209-8d48-90144742d170
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:940 - Connecting to ResourceManager akka://flink/user/resourcemanager(854a05baf59056f1d7207c5cd2834247)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:155 - Resolved ResourceManager address, beginning registration
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:204 - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:302 - Registering job manager 8d4890144742d170f2573d65d5424209@akka://flink/user/jobmanager_1 for job 0d3ff66110396e290448202a019acaf5.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:657 - Registered job manager 8d4890144742d170f2573d65d5424209@akka://flink/user/jobmanager_1 for job 0d3ff66110396e290448202a019acaf5.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:962 - JobManager successfully registered at ResourceManager, leader id: 854a05baf59056f1d7207c5cd2834247.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{f5a8886ce91648cab2fcf2ae1543536e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{d3c392e2c3991716a95e200ffdd49a92}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d3ff66110396e290448202a019acaf5 with allocation id 6f479f58bdeb25a57fcffef6f844dc00.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{ed5767572d6c50abdef4105f1dad5b55}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{bebd9e4847d9d6cc7311c053ef641615}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{77ce4cabac48ad039a7fe20e9431187f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  SlotPoolImpl:319 - Requesting new slot [SlotRequestId{b8ce3e4c7aea7a4bfdfa64da00a4309e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request 6f479f58bdeb25a57fcffef6f844dc00 for job 0d3ff66110396e290448202a019acaf5 from resource manager with leader id 854a05baf59056f1d7207c5cd2834247.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for 6f479f58bdeb25a57fcffef6f844dc00.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 0d3ff66110396e290448202a019acaf5 for job leader monitoring.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d3ff66110396e290448202a019acaf5 with allocation id afb4e8a36cbf0f415895402c5435e962.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:836 - Receive slot request afb4e8a36cbf0f415895402c5435e962 for job 0d3ff66110396e290448202a019acaf5 from resource manager with leader id 854a05baf59056f1d7207c5cd2834247.
2020-01-15 09:54:09 [mini-cluster-io-thread-2] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id f2573d65-d542-4209-8d48-90144742d170.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:848 - Allocated slot for afb4e8a36cbf0f415895402c5435e962.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:193 - Add job 0d3ff66110396e290448202a019acaf5 for job leader monitoring.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d3ff66110396e290448202a019acaf5 with allocation id 79d7b401efffbfbc963ae7c068d61558.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request 79d7b401efffbfbc963ae7c068d61558 for job 0d3ff66110396e290448202a019acaf5 from resource manager with leader id 854a05baf59056f1d7207c5cd2834247.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for 79d7b401efffbfbc963ae7c068d61558.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 0d3ff66110396e290448202a019acaf5 for job leader monitoring.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d3ff66110396e290448202a019acaf5 with allocation id 2acc2cd6423a60f2645bfa62a6a3a730.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request 2acc2cd6423a60f2645bfa62a6a3a730 for job 0d3ff66110396e290448202a019acaf5 from resource manager with leader id 854a05baf59056f1d7207c5cd2834247.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for 2acc2cd6423a60f2645bfa62a6a3a730.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 0d3ff66110396e290448202a019acaf5 for job leader monitoring.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d3ff66110396e290448202a019acaf5 with allocation id b4dd9081d9b4b3a2ffce00971c8f9f83.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:836 - Receive slot request b4dd9081d9b4b3a2ffce00971c8f9f83 for job 0d3ff66110396e290448202a019acaf5 from resource manager with leader id 854a05baf59056f1d7207c5cd2834247.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:848 - Allocated slot for b4dd9081d9b4b3a2ffce00971c8f9f83.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:193 - Add job 0d3ff66110396e290448202a019acaf5 for job leader monitoring.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:437 - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 0d3ff66110396e290448202a019acaf5 with allocation id c575835dbe9773510a9c66c9fcc798ba.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:836 - Receive slot request c575835dbe9773510a9c66c9fcc798ba for job 0d3ff66110396e290448202a019acaf5 from resource manager with leader id 854a05baf59056f1d7207c5cd2834247.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  TaskExecutor:848 - Allocated slot for c575835dbe9773510a9c66c9fcc798ba.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  JobLeaderService:193 - Add job 0d3ff66110396e290448202a019acaf5 for job leader monitoring.
2020-01-15 09:54:09 [mini-cluster-io-thread-5] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id f2573d65-d542-4209-8d48-90144742d170.
2020-01-15 09:54:09 [mini-cluster-io-thread-4] INFO  JobLeaderService:333 - Try to register at job manager akka://flink/user/jobmanager_1 with leader id f2573d65-d542-4209-8d48-90144742d170.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:155 - Resolved JobManager address, beginning registration
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-2] INFO  JobLeaderService:204 - Registration at JobManager attempt 1 (timeout=100ms)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  JobLeaderService:382 - Successful registration at job manager akka://flink/user/jobmanager_1 for job 0d3ff66110396e290448202a019acaf5.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1241 - Establish JobManager connection for job 0d3ff66110396e290448202a019acaf5.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1142 - Offer reserved slots to the leader of job 0d3ff66110396e290448202a019acaf5.
2020-01-15 09:54:09 [mini-cluster-io-thread-4] WARN  EmbeddedLeaderService:516 - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.12-1.9.1.jar:1.9.1]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) [flink-runtime_2.12-1.9.1.jar:1.9.1]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1736) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (1/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (2/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (3/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (1/6).
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (4/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (5/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Source: Custom Source -> Flat Map (6/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (1/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (2/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (3/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (2/6).
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (4/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (5/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) switched from SCHEDULED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:712 - Deploying Sink: Print to Std. Out (6/6) (attempt #0) to b35d3625-2ff2-4547-97eb-e96d595d1e85 @ localhost (dataPort=-1)
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) [DEPLOYING]
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) [DEPLOYING]
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (3/6).
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) [DEPLOYING]
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) [DEPLOYING].
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (4/6).
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) [DEPLOYING]
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) [DEPLOYING].
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (5/6).
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) [DEPLOYING].
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Source: Custom Source -> Flat Map (6/6).
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) [DEPLOYING]
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) [DEPLOYING]
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:593 - Loading JAR files for task Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:619 - Registering task at network: Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) [DEPLOYING].
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (3/6) (fafe116f03289bb43d493b13ab50def4) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (5/6) (54ece1d435282a40c9802931da507418) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (1/6) (e017d9086b8b50b84a8414dd4d581989) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (4/6) (f41b25ecfc895aac8465dedd374a8078) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1).
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (2/6) (01705182cc195437cea2e19050116b4e) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (1/6).
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  Task:958 - Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:586 - Creating FileSystem stream leak safety net for task TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) [DEPLOYING]
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Source: Custom Source -> Flat Map (6/6) (ff1b602f0e6f99b8c8159badbb7c3ad7) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:593 - Loading JAR files for task TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) [DEPLOYING].
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:619 - Registering task at network: TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) [DEPLOYING].
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (2/6).
2020-01-15 09:54:09 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (1/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) [DEPLOYING]
2020-01-15 09:54:09 [Sink: Print to Std. Out (1/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (1/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (1/6)] INFO  Task:958 - Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (1/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (1/6) (8a588fe93c3ae3d1c318ab08a9f3886c) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (2/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) [DEPLOYING]
2020-01-15 09:54:09 [Sink: Print to Std. Out (2/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) [DEPLOYING].
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  Task:958 - TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (3/6).
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1) (f406d6bc891b4efc02b1b3c2528c06fd) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (4/6).
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] WARN  MetricGroup:143 - The operator name TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) exceeded the 80 characters length limit and was truncated.
2020-01-15 09:54:09 [Sink: Print to Std. Out (2/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (3/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) [DEPLOYING]
2020-01-15 09:54:09 [Sink: Print to Std. Out (3/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (3/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) [DEPLOYING].
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (5/6).
2020-01-15 09:54:09 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (5/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) [DEPLOYING]
2020-01-15 09:54:09 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (4/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) [DEPLOYING]
2020-01-15 09:54:09 [Sink: Print to Std. Out (4/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) [DEPLOYING].
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:606 - Received task Sink: Print to Std. Out (6/6).
2020-01-15 09:54:09 [Sink: Print to Std. Out (4/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (5/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (5/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) switched from CREATED to DEPLOYING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (6/6)] INFO  Task:586 - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) [DEPLOYING]
2020-01-15 09:54:09 [Sink: Print to Std. Out (6/6)] INFO  Task:593 - Loading JAR files for task Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) [DEPLOYING].
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 2acc2cd6423a60f2645bfa62a6a3a730.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 79d7b401efffbfbc963ae7c068d61558.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot 6f479f58bdeb25a57fcffef6f844dc00.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot c575835dbe9773510a9c66c9fcc798ba.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot afb4e8a36cbf0f415895402c5435e962.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTable:237 - Activate slot b4dd9081d9b4b3a2ffce00971c8f9f83.
2020-01-15 09:54:09 [Sink: Print to Std. Out (6/6)] INFO  Task:619 - Registering task at network: Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) [DEPLOYING].
2020-01-15 09:54:09 [Sink: Print to Std. Out (2/6)] INFO  Task:958 - Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (2/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [Sink: Print to Std. Out (5/6)] INFO  Task:958 - Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (4/6)] INFO  Task:958 - Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (3/6)] INFO  Task:958 - Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (5/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [Sink: Print to Std. Out (4/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [Sink: Print to Std. Out (3/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (2/6) (4c64b86fae1eb71d65ba112fa1662094) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (5/6) (f43ca6d2d4c151e0876b906c115f460f) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (6/6)] INFO  Task:958 - Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Sink: Print to Std. Out (6/6)] INFO  StreamTask:227 - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (4/6) (386ea7ee5e8146ca2028ec913ff459ec) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [TriggerWindow(TumblingProcessingTimeWindows(15000), ReducingStateDescriptor{name=window-contents, defaultValue=null, serializer=org.apache.flink.api.common.typeutils.base.StringSerializer@72bc6553}, ProcessingTimeTrigger(), AllWindowedStream.reduce(AllWindowedStream.java:240)) (1/1)] INFO  HeapKeyedStateBackend:140 - Initializing heap keyed state backend with stream factory.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1818 - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 3 has no restore state.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 1 has no restore state.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 2 has no restore state.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (3/6) (22151a896eb6a4b37dbb817ee6d0c579) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 5 has no restore state.
2020-01-15 09:54:09 [flink-akka.actor.default-dispatcher-5] INFO  ExecutionGraph:1491 - Sink: Print to Std. Out (6/6) (bb0d3a12bd524adb03afddd087499417) switched from DEPLOYING to RUNNING.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 0 has no restore state.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  TypeExtractor:1857 - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:886 - Consumer subtask 4 has no restore state.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 2 initially has no partitions to read from.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 0 initially has no partitions to read from.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 4 initially has no partitions to read from.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:645 - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='source-topic', partition=0}]
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 5 initially has no partitions to read from.
2020-01-15 09:54:09 [Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:651 - Consumer subtask 3 initially has no partitions to read from.
2020-01-15 09:54:09 [Legacy Source Thread - Source: Custom Source -> Flat Map (5/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 4 creating fetcher with offsets {}.
2020-01-15 09:54:09 [Legacy Source Thread - Source: Custom Source -> Flat Map (3/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 2 creating fetcher with offsets {}.
2020-01-15 09:54:09 [Legacy Source Thread - Source: Custom Source -> Flat Map (6/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 5 creating fetcher with offsets {}.
2020-01-15 09:54:09 [Legacy Source Thread - Source: Custom Source -> Flat Map (2/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='source-topic', partition=0}=-915623761773}.
2020-01-15 09:54:09 [Legacy Source Thread - Source: Custom Source -> Flat Map (1/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 0 creating fetcher with offsets {}.
2020-01-15 09:54:10 [Legacy Source Thread - Source: Custom Source -> Flat Map (4/6)] INFO  FlinkKafkaConsumerBase:688 - Consumer subtask 3 creating fetcher with offsets {}.
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (6/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (4/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink_consumer
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  KafkaConsumer:1090 - [Consumer clientId=consumer-7, groupId=flink_consumer] Subscribed to partition(s): source-topic-0
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (5/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (1/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:109 - Kafka version: 2.2.0
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (3/6)] INFO  AppInfoParser:110 - Kafka commitId: 05fcfde8f69b0349
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  Metadata:365 - Cluster ID: ppZ2swkoRX2dZvcOSO-Skg
2020-01-15 09:54:10 [Kafka Fetcher for Source: Custom Source -> Flat Map (2/6)] INFO  AbstractCoordinator:675 - [Consumer clientId=consumer-7, groupId=flink_consumer] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2020-01-15 09:54:51 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  TaskExecutorLocalStateStoresManager:213 - Shutting down TaskExecutorLocalStateStoresManager.
2020-01-15 09:54:51 [PermanentBlobCache shutdown hook] INFO  PermanentBlobCache:247 - Shutting down BLOB cache
2020-01-15 09:54:51 [BlobServer shutdown hook] INFO  BlobServer:340 - Stopped BLOB server at 0.0.0.0:39813
2020-01-15 09:54:51 [IOManagerAsync shutdown hook] INFO  FileChannelManagerImpl:112 - FileChannelManager removed spill file directory /tmp/flink-io-205de482-4b53-437a-a6b3-d2d5fab10a4b
2020-01-15 09:54:51 [FileCache shutdown hook] INFO  FileCache:153 - removed file cache directory /tmp/flink-dist-cache-f1ac9a0d-df49-4b1f-ad03-387bce93903c
2020-01-15 09:54:51 [TransientBlobCache shutdown hook] INFO  TransientBlobCache:247 - Shutting down BLOB cache
